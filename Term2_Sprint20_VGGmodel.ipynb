{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "Term2_Sprint20_VGGmodel.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shXzoemWRPwn",
        "colab_type": "text"
      },
      "source": [
        "# Term2 Sprint20\n",
        "\n",
        "前回に引き続きTGS Salt Identification Challengのデータセットの学習・推定を行う。\n",
        "\n",
        "今回は、転移学習を利用し、精度の向上を図る。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXVWAQglQGfY",
        "colab_type": "text"
      },
      "source": [
        "## Model architecture tuning & score optimization\n",
        "\n",
        "\n",
        "Some ideas and code taken from ealier [kernel](https://www.kaggle.com/wrosinski/clean-workflow-in-keras) and last prepared notebook.\n",
        "\n",
        "Having dealt with data processing & engineering of channel features, next step of modeling is preparation and tuning of model architecture. Earlier notebooks provided a way to create images with three channels, which will facilitate usage of pretrained models.\n",
        "\n",
        "For segmentation tasks, a pretrained model can be used as encoder part of the final architecture. \n",
        "In order to use pretrained models, we will have to extract features from a few intermediate layers, which will then serve as a basis for layers coming afterwards and for skip connections between encoder and decoder part.\n",
        "\n",
        "ResNet50 is a good starting point, because it consists of 4 blocks, where each one of them can serve as feature extractor with first layer serving as the 5th extractor to achieve consistency with standard UNet architecture."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-09-25T07:08:26.011539Z",
          "start_time": "2019-09-25T07:08:20.644512Z"
        },
        "id": "bPBjzNl8QGfc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        },
        "outputId": "6d047b33-5239-406d-c044-cb3ef0f7b75a"
      },
      "source": [
        "import gc\n",
        "import glob\n",
        "import os\n",
        "\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from tqdm import tqdm\n",
        "\n",
        "from keras import optimizers\n",
        "from keras.callbacks import *\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras.layers import *\n",
        "from keras.models import Model, load_model, save_model\n",
        "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
        "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "from keras.applications.vgg16 import VGG16\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Ac2oMQbQKLa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "126bf043-8d63-4ac8-dcfc-1bfa1fa01c61"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-mC4ceKQY72",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !mkdir train\n",
        "# !unzip /content/drive/'My Drive'/'Colab Notebooks'/kaggle_salt/train.zip\n",
        "# !mv images train/images\n",
        "# !mv masks train/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5azmlYTg5i2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!unzip /content/drive/'My Drive'/'Colab Notebooks'/kaggle_salt/test.zip -d test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Ya6IxxdfE3H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !cp /content/drive/'My Drive'/'Colab Notebooks'/kaggle_salt/sample_submission.csv /content/sample_submission.csv\n",
        "# !cp /content/drive/'My Drive'/'Colab Notebooks'/kaggle_salt/train.csv /content/train.csv\n",
        "# !cp /content/drive/'My Drive'/'Colab Notebooks'/kaggle_salt/depths.csv /content/depths.csv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1c2vbu3QGfn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.rcParams['figure.figsize'] = (12, 9)\n",
        "# plt.style.use('ggplot')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ew4H04bQGfv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.set_option('display.max_columns', 100)\n",
        "def compute_coverage(df, masks):\n",
        "    \n",
        "    df = df.copy()  #trainのid,mask,depth情報\n",
        "    \n",
        "    #maskの含有率を整数クラスに置き換え\n",
        "    def cov_to_class(val):\n",
        "        for i in range(0, 11):\n",
        "            if val * 10 <= i:\n",
        "                return i\n",
        "\n",
        "    # Output percentage of area covered by class\n",
        "    df['coverage'] = np.mean(masks, axis=(1, 2)) #y画像のマスク面積の比率を算出してクラス分け\n",
        "    # Coverage must be split into bins, otherwise stratified split will not be possible,\n",
        "    # because each coverage will occur only once.\n",
        "    df['coverage_class'] = df.coverage.map(\n",
        "        cov_to_class)\n",
        "    print(df)\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def create_depth_abs_channels(image_tensor):   #image_tensor= X_train_ch(4000,101,101,3)\n",
        "    image_tensor = image_tensor.astype(np.float32)\n",
        "    h, w, c = image_tensor.shape\n",
        "    for row, const in enumerate(np.linspace(0, 1, h)):  #0.01刻みのデータを生成\n",
        "        image_tensor[row, :, 1] = const                         #1chの各行に0.01刻みのデータを代入\n",
        "    image_tensor[:, :, 2] = (\n",
        "        image_tensor[:, :, 0] * image_tensor[:, :, 1])   #2chに0ch*1chのデータを代入\n",
        "\n",
        "    x_dx = np.diff(image_tensor[:, :, 0], axis=0)   #行方向の隣り合う要素同士の差分を計算\n",
        "    x_dy = np.diff(image_tensor[:, :, 0], axis=1)   #列方向の隣り合う要素同士の差分を計算\n",
        "    x_dx = cv2.copyMakeBorder(x_dx, 1, 0, 0, 0, cv2.BORDER_CONSTANT, 0) #単一色の境界を追加\n",
        "    x_dy = cv2.copyMakeBorder(x_dy, 0, 0, 1, 0, cv2.BORDER_CONSTANT, 0) #単一色の境界を追加\n",
        "    image_tensor[:, :, 1] = np.abs(x_dx + x_dy)\n",
        "\n",
        "    return image_tensor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5LTWanXQGf0",
        "colab_type": "text"
      },
      "source": [
        "### Data loading & depth merge:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R357vRWsQGf0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "dfaf935c-b07e-4c4b-df15-d5b7875b072f"
      },
      "source": [
        "train = pd.read_csv(\"/content/train.csv\")\n",
        "test = pd.read_csv(\"/content/sample_submission.csv\")\n",
        "depth = pd.read_csv(\"/content/depths.csv\")\n",
        "\n",
        "train_src = '/content/train/'\n",
        "\n",
        "print('train:\\n{}'.format(train.head(20)))\n",
        "print('\\ntest:\\n{}'.format(test.head(20)))\n",
        "print('depths:\\n{}'.format(depth.head(20)))\n",
        "\n",
        "train = train.merge(depth, how='left', on='id')\n",
        "test = test.merge(depth, how='left', on='id')\n",
        "\n",
        "print('\\n{}'.format(train.head(20)))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train:\n",
            "            id                                           rle_mask\n",
            "0   575d24d81d                                                NaN\n",
            "1   a266a2a9df                                          5051 5151\n",
            "2   75efad62c1  9 93 109 94 210 94 310 95 411 95 511 96 612 96...\n",
            "3   34e51dba6a  48 54 149 54 251 53 353 52 455 51 557 50 659 4...\n",
            "4   4875705fb0  1111 1 1212 1 1313 1 1414 1 1514 2 1615 2 1716...\n",
            "5   782ae9b7e7  1 1815 1819 90 1920 81 2021 73 2122 64 2223 55...\n",
            "6   9842f69f8d                                                NaN\n",
            "7   aa94cfb806  1 28 102 28 203 29 304 30 405 32 506 33 607 34...\n",
            "8   50d3073821                                    1 2121 9293 909\n",
            "9   28f865caaa                                                NaN\n",
            "10  b5e1371b3b  75 27 175 28 275 29 374 31 474 32 574 33 674 3...\n",
            "11  57e394bc67                                                NaN\n",
            "12  b45ad3932e  49 11 149 11 249 11 351 10 452 9 553 9 654 8 7...\n",
            "13  ef51bbcde7                                                NaN\n",
            "14  d4d34af4f7                                          8788 1414\n",
            "15  302ea1ac81  6 96 108 95 210 94 311 94 413 93 515 92 615 93...\n",
            "16  40dcff68b3  3536 4 3637 20 3738 36 3839 53 3940 70 4041 86...\n",
            "17  7845115d01                                          7677 2525\n",
            "18  3da729cae9  1 54 102 54 203 53 304 53 405 53 506 53 607 53...\n",
            "19  d67e3a11d8                                                NaN\n",
            "\n",
            "test:\n",
            "            id rle_mask\n",
            "0   155410d6fa      1 1\n",
            "1   78b32781d1      1 1\n",
            "2   63db2a476a      1 1\n",
            "3   17bfcdb967      1 1\n",
            "4   7ea0fd3c88      1 1\n",
            "5   8a14fa3b33      1 1\n",
            "6   1b4836f485      1 1\n",
            "7   04013dfaae      1 1\n",
            "8   5a005e1b95      1 1\n",
            "9   fe53259bf6      1 1\n",
            "10  03dee840bf      1 1\n",
            "11  5be0000be2      1 1\n",
            "12  6e166d6284      1 1\n",
            "13  b07015747f      1 1\n",
            "14  aac410c5d3      1 1\n",
            "15  2230bca035      1 1\n",
            "16  575d4ae82a      1 1\n",
            "17  e9531eada5      1 1\n",
            "18  894f6a1da6      1 1\n",
            "19  fda5468e31      1 1\n",
            "depths:\n",
            "            id    z\n",
            "0   4ac19fb269  306\n",
            "1   1825fadf99  157\n",
            "2   f59821d067  305\n",
            "3   5b435fad9d  503\n",
            "4   e340e7bfca  783\n",
            "5   2ffea0c397  429\n",
            "6   6cf284fb9e  600\n",
            "7   d0244d6c38   51\n",
            "8   cffbfab33b  755\n",
            "9   e82421363e   68\n",
            "10  9090f8f97b  253\n",
            "11  778a92f420  476\n",
            "12  57e394bc67  765\n",
            "13  1efe1909ed  143\n",
            "14  8d89d465fc  529\n",
            "15  211fc910da  336\n",
            "16  b12a5a2b61  475\n",
            "17  28948eeb9c  306\n",
            "18  28f6f52c8f  317\n",
            "19  211eb21702  188\n",
            "\n",
            "            id                                           rle_mask    z\n",
            "0   575d24d81d                                                NaN  843\n",
            "1   a266a2a9df                                          5051 5151  794\n",
            "2   75efad62c1  9 93 109 94 210 94 310 95 411 95 511 96 612 96...  468\n",
            "3   34e51dba6a  48 54 149 54 251 53 353 52 455 51 557 50 659 4...  727\n",
            "4   4875705fb0  1111 1 1212 1 1313 1 1414 1 1514 2 1615 2 1716...  797\n",
            "5   782ae9b7e7  1 1815 1819 90 1920 81 2021 73 2122 64 2223 55...  677\n",
            "6   9842f69f8d                                                NaN  907\n",
            "7   aa94cfb806  1 28 102 28 203 29 304 30 405 32 506 33 607 34...  754\n",
            "8   50d3073821                                    1 2121 9293 909  810\n",
            "9   28f865caaa                                                NaN  147\n",
            "10  b5e1371b3b  75 27 175 28 275 29 374 31 474 32 574 33 674 3...  325\n",
            "11  57e394bc67                                                NaN  765\n",
            "12  b45ad3932e  49 11 149 11 249 11 351 10 452 9 553 9 654 8 7...  613\n",
            "13  ef51bbcde7                                                NaN  712\n",
            "14  d4d34af4f7                                          8788 1414  114\n",
            "15  302ea1ac81  6 96 108 95 210 94 311 94 413 93 515 92 615 93...  470\n",
            "16  40dcff68b3  3536 4 3637 20 3738 36 3839 53 3940 70 4041 86...  707\n",
            "17  7845115d01                                          7677 2525  343\n",
            "18  3da729cae9  1 54 102 54 203 53 304 53 405 53 506 53 607 53...  707\n",
            "19  d67e3a11d8                                                NaN  585\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAFM-MraQGf3",
        "colab_type": "text"
      },
      "source": [
        "### Load images and masks, examine random sample:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_nroVs9QGf4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6a23dc3e-40e7-4c21-cfd8-60a854f4cecc"
      },
      "source": [
        "#画像をグレースケールで読み込んでndarray配列に参照コピーし、０〜１のデータにならす。\n",
        "X_train = np.asarray(\n",
        "    [cv2.imread('/content/train/images/{}.png'.format(x), 0) for x in train.id.tolist()], \n",
        "    dtype=np.uint8) / 255.\n",
        "y_train = np.asarray(\n",
        "    [cv2.imread('/content/train/masks/{}.png'.format(x), 0) for x in train.id.tolist()],\n",
        "    dtype=np.uint8) / 255.\n",
        "\n",
        "print(X_train.shape, y_train.shape) #101x101x1チャンネルの画像4000枚"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4000, 101, 101) (4000, 101, 101)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "afbqIJO8QGf7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "outputId": "38f19a04-bdcb-4c16-e0fc-6445c6262891"
      },
      "source": [
        "#変換した画像をランダムに表示してみる\n",
        "random_index = np.random.randint(0, X_train.shape[0])\n",
        "\n",
        "fig, ax = plt.subplots(1, 2)\n",
        "\n",
        "ax[0].imshow(X_train[random_index], cmap='gray')\n",
        "ax[1].imshow(y_train[random_index], cmap='gray')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f0ee246c7b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAs0AAAFSCAYAAAAJl+KKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 864x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqxBCcN1QGf-",
        "colab_type": "text"
      },
      "source": [
        "### Compute salt coverage (this will serve as a basis for stratified split):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEZ2jXlsQGf-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "outputId": "1b8fe71e-7e44-4bdb-d3e0-5b5c12c93515"
      },
      "source": [
        "train = compute_coverage(train, y_train)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              id                                           rle_mask    z  \\\n",
            "0     575d24d81d                                                NaN  843   \n",
            "1     a266a2a9df                                          5051 5151  794   \n",
            "2     75efad62c1  9 93 109 94 210 94 310 95 411 95 511 96 612 96...  468   \n",
            "3     34e51dba6a  48 54 149 54 251 53 353 52 455 51 557 50 659 4...  727   \n",
            "4     4875705fb0  1111 1 1212 1 1313 1 1414 1 1514 2 1615 2 1716...  797   \n",
            "...          ...                                                ...  ...   \n",
            "3995  9cbd5ddba4                                                NaN  218   \n",
            "3996  caa039b231  2398 7 2499 11 2600 16 2700 22 2801 26 2901 29...  602   \n",
            "3997  1306fcee4c                                                NaN  177   \n",
            "3998  48d81e93d9  2828 1 2927 3 3026 5 3126 6 3225 8 3324 10 342...  221   \n",
            "3999  edf1e6ac00                                                NaN  460   \n",
            "\n",
            "      coverage  coverage_class  \n",
            "0     0.000000               0  \n",
            "1     0.504950               6  \n",
            "2     0.993334              10  \n",
            "3     0.149201               2  \n",
            "4     0.042839               1  \n",
            "...        ...             ...  \n",
            "3995  0.000000               0  \n",
            "3996  0.376924               4  \n",
            "3997  0.000000               0  \n",
            "3998  0.482796               5  \n",
            "3999  0.000000               0  \n",
            "\n",
            "[4000 rows x 5 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivQ8hmWZ_YSf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "31100879-7237-4a30-fc4c-48d6129d5daa"
      },
      "source": [
        "train.id.values"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['575d24d81d', 'a266a2a9df', '75efad62c1', ..., '1306fcee4c',\n",
              "       '48d81e93d9', 'edf1e6ac00'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IY-oZ_gIBjXi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "713eebaf-9a83-419b-b4c9-1f5315f1ad70"
      },
      "source": [
        "train.coverage_class.values.shape"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKw2_PKoQGgA",
        "colab_type": "text"
      },
      "source": [
        "### Prepare data for training:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhYiB6VtQGgB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "b9df048d-ee24-4916-aecb-238cd9eed35d"
      },
      "source": [
        "kfold = StratifiedKFold(n_splits=5, random_state=1337) #データセットを５つに分割\n",
        "\n",
        "# Add channel features\n",
        "X_train_ch = np.repeat(np.expand_dims(X_train, axis=-1), 3, -1) #(4000,101,101,1)>(4000,101,101,3)\n",
        "X_train_ch = np.asarray(list(map(lambda x: create_depth_abs_channels(x), X_train_ch)))  #2chを特徴量エンジニアリング\n",
        "\n",
        "# Resize to 224x224, default ResNet50 image size\n",
        "X_resized = np.asarray(list(map(lambda x: cv2.resize(x, (224, 224)), X_train_ch)))\n",
        "y_resized = np.asarray(list(map(lambda x: cv2.resize(x, (224, 224)), y_train)))\n",
        "#print(X_resized[0:3])\n",
        "\n",
        "for train_index, valid_index in kfold.split(train.id.values, train.coverage_class.values):  #split(X, y)\n",
        "    #train_index: trainデータのインデックス情報\n",
        "    #y画像を数値化したもの（coverage_class）をyラベルとして代用している（0~10の多クラスとして擬似的に扱う）\n",
        "    X_tr, X_val = X_resized[train_index], X_resized[valid_index]\n",
        "    y_tr, y_val = y_resized[train_index], y_resized[valid_index]\n",
        "\n",
        "    break\n",
        "    \n",
        "\n",
        "y_tr = np.expand_dims(y_tr, axis=-1)\n",
        "y_val = np.expand_dims(y_val, axis=-1)\n",
        "\n",
        "print(X_tr.shape, y_tr.shape)\n",
        "print(X_val.shape, y_val.shape)\n",
        "\n",
        "\n",
        "del X_train_ch, y_resized\n",
        "del X_resized\n",
        "gc.collect()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3196, 224, 224, 3) (3196, 224, 224, 1)\n",
            "(804, 224, 224, 3) (804, 224, 224, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fNdhJUeQGgC",
        "colab_type": "text"
      },
      "source": [
        "### Loss functions & metric:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vMpedqDQGgD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.losses import binary_crossentropy\n",
        "\n",
        "\n",
        "# Dice & combined\n",
        "def dice_coef(y_true, y_pred):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred = K.cast(y_pred, 'float32')\n",
        "    y_pred_f = K.cast(K.greater(K.flatten(y_pred), 0.5), 'float32')\n",
        "    intersection = y_true_f * y_pred_f\n",
        "    score = 2. * K.sum(intersection) / (K.sum(y_true_f) + K.sum(y_pred_f))\n",
        "    return score\n",
        "\n",
        "\n",
        "def dice_loss(y_true, y_pred):\n",
        "    smooth = 1.\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = y_true_f * y_pred_f\n",
        "    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "    return 1. - score\n",
        "\n",
        "\n",
        "def bce_dice_loss(y_true, y_pred):\n",
        "    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
        "\n",
        "\n",
        "def bce_logdice_loss(y_true, y_pred):\n",
        "    return binary_crossentropy(y_true, y_pred) - K.log(1. - dice_loss(y_true, y_pred))\n",
        "\n",
        "\n",
        "\n",
        "# Lovash loss: https://github.com/bermanmaxim/LovaszSoftmax\n",
        "def lovasz_grad(gt_sorted):\n",
        "    \"\"\"\n",
        "    Computes gradient of the Lovasz extension w.r.t sorted errors\n",
        "    See Alg. 1 in paper\n",
        "    \"\"\"\n",
        "    gts = tf.reduce_sum(gt_sorted)\n",
        "    intersection = gts - tf.cumsum(gt_sorted)\n",
        "    union = gts + tf.cumsum(1. - gt_sorted)\n",
        "    jaccard = 1. - intersection / union\n",
        "    jaccard = tf.concat((jaccard[0:1], jaccard[1:] - jaccard[:-1]), 0)\n",
        "    return jaccard\n",
        "\n",
        "\n",
        "# --------------------------- BINARY LOSSES ---------------------------\n",
        "\n",
        "def lovasz_hinge(logits, labels, per_image=True, ignore=None):\n",
        "    \"\"\"\n",
        "    Binary Lovasz hinge loss\n",
        "      logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\n",
        "      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\n",
        "      per_image: compute the loss per image instead of per batch\n",
        "      ignore: void class id\n",
        "    \"\"\"\n",
        "    if per_image:\n",
        "        def treat_image(log_lab):\n",
        "            log, lab = log_lab\n",
        "            log, lab = tf.expand_dims(log, 0), tf.expand_dims(lab, 0)\n",
        "            log, lab = flatten_binary_scores(log, lab, ignore)\n",
        "            return lovasz_hinge_flat(log, lab)\n",
        "        losses = tf.map_fn(treat_image, (logits, labels), dtype=tf.float32)\n",
        "        loss = tf.reduce_mean(losses)\n",
        "    else:\n",
        "        loss = lovasz_hinge_flat(*flatten_binary_scores(logits, labels, ignore))\n",
        "    return loss\n",
        "\n",
        "\n",
        "def lovasz_hinge_flat(logits, labels):\n",
        "    \"\"\"\n",
        "    Binary Lovasz hinge loss\n",
        "      logits: [P] Variable, logits at each prediction (between -\\infty and +\\infty)\n",
        "      labels: [P] Tensor, binary ground truth labels (0 or 1)\n",
        "      ignore: label to ignore\n",
        "    \"\"\"\n",
        "\n",
        "    def compute_loss():\n",
        "        labelsf = tf.cast(labels, logits.dtype)\n",
        "        signs = 2. * labelsf - 1.\n",
        "        errors = 1. - logits * tf.stop_gradient(signs)\n",
        "        errors_sorted, perm = tf.nn.top_k(errors, k=tf.shape(errors)[0], name=\"descending_sort\")\n",
        "        gt_sorted = tf.gather(labelsf, perm)\n",
        "        grad = lovasz_grad(gt_sorted)\n",
        "        loss = tf.tensordot(tf.nn.relu(errors_sorted), tf.stop_gradient(grad), 1, name=\"loss_non_void\")\n",
        "        return loss\n",
        "\n",
        "    # deal with the void prediction case (only void pixels)\n",
        "    loss = tf.cond(tf.equal(tf.shape(logits)[0], 0),\n",
        "                   lambda: tf.reduce_sum(logits) * 0.,\n",
        "                   compute_loss,\n",
        "                   strict=True,\n",
        "                   name=\"loss\"\n",
        "                   )\n",
        "    return loss\n",
        "\n",
        "\n",
        "def flatten_binary_scores(scores, labels, ignore=None):\n",
        "    \"\"\"\n",
        "    Flattens predictions in the batch (binary case)\n",
        "    Remove labels equal to 'ignore'\n",
        "    \"\"\"\n",
        "    scores = tf.reshape(scores, (-1,))\n",
        "    labels = tf.reshape(labels, (-1,))\n",
        "    if ignore is None:\n",
        "        return scores, labels\n",
        "    valid = tf.not_equal(labels, ignore)\n",
        "    vscores = tf.boolean_mask(scores, valid, name='valid_scores')\n",
        "    vlabels = tf.boolean_mask(labels, valid, name='valid_labels')\n",
        "    return vscores, vlabels\n",
        "\n",
        "\n",
        "def lovasz_loss(y_true, y_pred):\n",
        "    y_true, y_pred = K.cast(K.squeeze(y_true, -1), 'int32'), K.cast(K.squeeze(y_pred, -1), 'float32')\n",
        "    #logits = K.log(y_pred / (1. - y_pred))\n",
        "    logits = y_pred #Jiaxin\n",
        "    loss = lovasz_hinge(logits, y_true, per_image = True, ignore = None)\n",
        "    return loss\n",
        "\n",
        "\n",
        "# IoU metric for observation during training\n",
        "# https://www.kaggle.com/cpmpml/fast-iou-metric-in-numpy-and-tensorflow\n",
        "def get_iou_vector(A, B):\n",
        "    # Numpy version    \n",
        "    batch_size = A.shape[0]\n",
        "    metric = 0.0\n",
        "    for batch in range(batch_size):\n",
        "        t, p = A[batch], B[batch]\n",
        "        true = np.sum(t)\n",
        "        pred = np.sum(p)\n",
        "        \n",
        "        # deal with empty mask first\n",
        "        if true == 0:\n",
        "            metric += (pred == 0)\n",
        "            continue\n",
        "        \n",
        "        # non empty mask case.  Union is never empty \n",
        "        # hence it is safe to divide by its number of pixels\n",
        "        intersection = np.sum(t * p)\n",
        "        union = true + pred - intersection\n",
        "        iou = intersection / union\n",
        "        \n",
        "        # iou metrric is a stepwise approximation of the real iou over 0.5\n",
        "        iou = np.floor(max(0, (iou - 0.45)*20)) / 10\n",
        "        \n",
        "        metric += iou\n",
        "        \n",
        "    # teake the average over all images in batch\n",
        "    metric /= batch_size\n",
        "    return metric\n",
        "\n",
        "\n",
        "def my_iou_metric(label, pred):\n",
        "    return tf.py_func(get_iou_vector, [label, pred>0.5], tf.float64)\n",
        "\n",
        "\n",
        "# For Lovash loss\n",
        "def my_iou_metric_2(label, pred):\n",
        "    return tf.py_func(get_iou_vector, [label, pred >0], tf.float64)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-nGnSoYQGgE",
        "colab_type": "text"
      },
      "source": [
        "## ResNet50で学習・推定\n",
        "### Encoder features - ResNet50:\n",
        "\n",
        "In ResNet50, each block finishes with a pooling layer, so we can extract features from intermediate layers just before the pooling. This way, when first layer is added as additional extractor, we will have features extracted from 5 layers.\n",
        "Default input size will be assumed, which is (224, 224, 3).\n",
        "Layers will be as follows:\n",
        "\n",
        "- 'activation_1', shape: (None, 112, 112, 64)\n",
        "- 'activation_10', shape: (None, 56, 56, 256)\n",
        "- 'activation_22', shape: (None, 28, 28, 512)\n",
        "- 'activation_40', shape: (None, 14, 14, 1024)\n",
        "- 'activation_49', shape: (None, 7, 7, 2048)\n",
        "\n",
        "One thing to keep in mind is that every time a model will be created in the same TF session in the notebook, layer names will change, so above layer names correspond to first creation of the model. In order to reset session, call `K.clear_session()`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-09-25T07:09:31.695684Z",
          "start_time": "2019-09-25T07:09:24.147636Z"
        },
        "scrolled": true,
        "id": "Z3xuA-LcQGgF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c5551edf-e6f2-4797-db51-f361629fb2bb"
      },
      "source": [
        "input_size = (224, 224, 3)\n",
        "\n",
        "base_model = ResNet50(input_shape=input_size, include_top=False)\n",
        "base_model.summary()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4479: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
            "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94658560/94653016 [==============================] - 3s 0us/step\n",
            "Model: \"resnet50\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n",
            "                                                                 bn2a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 56, 56, 256)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n",
            "                                                                 activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 56, 56, 256)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n",
            "                                                                 activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 56, 56, 256)  0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
            "                                                                 bn3a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
            "                                                                 activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
            "                                                                 activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
            "                                                                 activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 28, 28, 512)  0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
            "                                                                 bn4a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
            "                                                                 activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
            "                                                                 activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
            "                                                                 activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
            "                                                                 activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
            "                                                                 bn5a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n",
            "                                                                 activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 2048)   0           add_16[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 23,587,712\n",
            "Trainable params: 23,534,592\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5yNqBJPQGgG",
        "colab_type": "raw"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpgWBSKQQGgH",
        "colab_type": "text"
      },
      "source": [
        "### Decoder blocks:\n",
        "\n",
        "Features from ResNet50 will serve as a basis for encoder part of the segmentation model, now a decoder part is needed.\n",
        "For this part, we will have to create our own blocks. Let's create a very basic block and a second one, which structure will have a more complicated structure."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6aZJ9WzQGgH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Basic decoder block with Conv, BN and PReLU activation.\n",
        "def decoder_block_simple(\n",
        "        layer_name, block_name,\n",
        "        num_filters=32,\n",
        "        conv_dim=(3, 3)):\n",
        "\n",
        "    x_dec = Conv2D(\n",
        "        num_filters, conv_dim,\n",
        "        padding='same',\n",
        "        name='{}_conv'.format(block_name))(layer_name)\n",
        "    x_dec = BatchNormalization(\n",
        "        name='{}_bn'.format(block_name))(x_dec)\n",
        "    x_dec = PReLU(\n",
        "        name='{}_activation'.format(block_name))(x_dec)\n",
        "\n",
        "    return x_dec\n",
        "\n",
        "# Decoder block with bottleneck architecture, where middle conv layer\n",
        "# is half the size of first and last, in order to compress representation.\n",
        "# This type of architecture is supposed to retain most useful information.\n",
        "def decoder_block_bottleneck(\n",
        "        layer_name, block_name,\n",
        "        num_filters=32,\n",
        "        conv_dim=(3, 3),\n",
        "        dropout_frac=0.2):\n",
        "\n",
        "    x_dec = Conv2D(\n",
        "        num_filters, conv_dim,\n",
        "        padding='same',\n",
        "        name='{}_conv1'.format(block_name))(layer_name)\n",
        "    x_dec = BatchNormalization(\n",
        "        name='{}_bn1'.format(block_name))(x_dec)\n",
        "    x_dec = PReLU(\n",
        "        name='{}_activation1'.format(block_name))(x_dec)\n",
        "    x_dec = Dropout(dropout_frac)(x_dec)\n",
        "\n",
        "    x_dec2 = Conv2D(\n",
        "        num_filters // 2, conv_dim,\n",
        "        padding='same',\n",
        "        name='{}_conv2'.format(block_name))(x_dec)\n",
        "    x_dec2 = BatchNormalization(\n",
        "        name='{}_bn2'.format(block_name))(x_dec2)\n",
        "    x_dec2 = PReLU(\n",
        "        name='{}_activation2'.format(block_name))(x_dec2)\n",
        "    x_dec2 = Dropout(dropout_frac)(x_dec2)\n",
        "\n",
        "    x_dec2 = Conv2D(\n",
        "        num_filters, conv_dim,\n",
        "        padding='same',\n",
        "        name='{}_conv3'.format(block_name))(x_dec2)\n",
        "    x_dec2 = BatchNormalization(\n",
        "        name='{}_bn3'.format(block_name))(x_dec2)\n",
        "    x_dec2 = PReLU(\n",
        "        name='{}_activation3'.format(block_name))(x_dec2)\n",
        "    x_dec2 = Dropout(dropout_frac)(x_dec2)\n",
        "\n",
        "    x_dec2 = Add()([x_dec, x_dec2])   #入力のリスト同士を足し合わせる\n",
        "\n",
        "    return x_dec2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2E5AnIbQGgI",
        "colab_type": "text"
      },
      "source": [
        "### Model definition:\n",
        "\n",
        "Combine encoder and decoder blocks to create final segmentation model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DY_A13yQGgJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Model is parametrized in a way to enable easy change of decoder_block type,\n",
        "# as this is an argument that can be given a function, like decoder_block_simple.\n",
        "def unet_resnet(input_size, decoder_block,\n",
        "                weights='imagenet',\n",
        "                loss_func='binary_crossentropy',\n",
        "                metrics_list=[my_iou_metric],\n",
        "                use_lovash=False):\n",
        "\n",
        "    # Base model - encoder\n",
        "    base_model = ResNet50(\n",
        "        input_shape=input_size, \n",
        "        include_top=False,\n",
        "        weights=weights)\n",
        "    \n",
        "    # Layers for feature extraction in the encoder part\n",
        "    encoder1 = base_model.get_layer('activation_1').output   #(None, 112, 112, 64)\n",
        "    encoder2 = base_model.get_layer('activation_10').output #(None, 56, 56, 256)\n",
        "    encoder3 = base_model.get_layer('activation_22').output #(None, 28, 28, 512) \n",
        "    encoder4 = base_model.get_layer('activation_40').output #(None, 14, 14, 1024)\n",
        "    encoder5 = base_model.get_layer('activation_49').output #(None, 7, 7, 2048)\n",
        "\n",
        "    # Center block\n",
        "    center = decoder_block(\n",
        "        encoder5, 'center', num_filters=512)\n",
        "    concat5 = concatenate([center, encoder5], axis=-1)  #(None, 7, 7, 512)\n",
        "\n",
        "    # Decoder part.\n",
        "    # Every decoder block processed concatenated output from encoder and decoder part.\n",
        "    # This creates skip connections.\n",
        "    # Afterwards, decoder output is upsampled to dimensions equal to encoder output part.\n",
        "    decoder4 = decoder_block(\n",
        "        concat5, 'decoder4', num_filters=256) #(None, 7, 7, 256)\n",
        "    concat4 = concatenate([UpSampling2D()(decoder4), encoder4], axis=-1) #(None, 14, 14, 1280)\n",
        "\n",
        "    decoder3 = decoder_block(\n",
        "        concat4, 'decoder3', num_filters=128) #(None, 14, 14, 128)\n",
        "    concat3 = concatenate([UpSampling2D()(decoder3), encoder3], axis=-1) #(None, 28, 28, 640)\n",
        "\n",
        "    decoder2 = decoder_block(\n",
        "        concat3, 'decoder2', num_filters=64) #(None, 28, 28, 64)\n",
        "    concat2 = concatenate([UpSampling2D()(decoder2), encoder2], axis=-1) #(None, 56, 56, 320)\n",
        "\n",
        "    decoder1 = decoder_block(\n",
        "        concat2, 'decoder1', num_filters=64) #(None, 56, 56, 64)\n",
        "    concat1 = concatenate([UpSampling2D()(decoder1), encoder1], axis=-1) #(None, 112, 112, 128)\n",
        "\n",
        "    # Final upsampling and decoder block for segmentation.\n",
        "    output = UpSampling2D()(concat1) #(None, 224, 224, 128)\n",
        "    output = decoder_block(\n",
        "        output, 'decoder_output', num_filters=32) #(None, 224, 224, 32)\n",
        "    output = Conv2D(\n",
        "        1, (1, 1), activation=None, name='prediction')(output)  #(None, 224, 224, 1)\n",
        "    if not use_lovash:\n",
        "        output = Activation('sigmoid')(output)\n",
        "        \n",
        "    model = Model(base_model.input, output)\n",
        "    model.compile(loss=loss_func, optimizer='adam', metrics=metrics_list)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBdyEp7BQGgK",
        "colab_type": "text"
      },
      "source": [
        "### Inspect created model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "9BJ8Q0hWQGgL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "76d96114-779e-48b6-a40f-ef3d20817298"
      },
      "source": [
        "input_size = (224, 224, 3)\n",
        "\n",
        "\n",
        "K.clear_session()\n",
        "model = unet_resnet(\n",
        "    input_size, decoder_block_simple, weights='imagenet')\n",
        "model.summary()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
            "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n",
            "                                                                 bn2a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 56, 56, 256)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n",
            "                                                                 activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 56, 56, 256)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n",
            "                                                                 activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 56, 56, 256)  0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
            "                                                                 bn3a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
            "                                                                 activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
            "                                                                 activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
            "                                                                 activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 28, 28, 512)  0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
            "                                                                 bn4a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
            "                                                                 activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
            "                                                                 activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
            "                                                                 activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
            "                                                                 activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
            "                                                                 bn5a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n",
            "                                                                 activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 2048)   0           add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "center_conv (Conv2D)            (None, 7, 7, 512)    9437696     activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "center_bn (BatchNormalization)  (None, 7, 7, 512)    2048        center_conv[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "center_activation (PReLU)       (None, 7, 7, 512)    25088       center_bn[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 7, 7, 2560)   0           center_activation[0][0]          \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_conv (Conv2D)          (None, 7, 7, 256)    5898496     concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_bn (BatchNormalization (None, 7, 7, 256)    1024        decoder4_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_activation (PReLU)     (None, 7, 7, 256)    12544       decoder4_bn[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2D)  (None, 14, 14, 256)  0           decoder4_activation[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 14, 14, 1280) 0           up_sampling2d_1[0][0]            \n",
            "                                                                 activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_conv (Conv2D)          (None, 14, 14, 128)  1474688     concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_bn (BatchNormalization (None, 14, 14, 128)  512         decoder3_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_activation (PReLU)     (None, 14, 14, 128)  25088       decoder3_bn[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2D)  (None, 28, 28, 128)  0           decoder3_activation[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 28, 28, 640)  0           up_sampling2d_2[0][0]            \n",
            "                                                                 activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_conv (Conv2D)          (None, 28, 28, 64)   368704      concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_bn (BatchNormalization (None, 28, 28, 64)   256         decoder2_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_activation (PReLU)     (None, 28, 28, 64)   50176       decoder2_bn[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_3 (UpSampling2D)  (None, 56, 56, 64)   0           decoder2_activation[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 56, 56, 320)  0           up_sampling2d_3[0][0]            \n",
            "                                                                 activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_conv (Conv2D)          (None, 56, 56, 64)   184384      concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_bn (BatchNormalization (None, 56, 56, 64)   256         decoder1_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_activation (PReLU)     (None, 56, 56, 64)   200704      decoder1_bn[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_4 (UpSampling2D)  (None, 112, 112, 64) 0           decoder1_activation[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 112, 112, 128 0           up_sampling2d_4[0][0]            \n",
            "                                                                 activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_5 (UpSampling2D)  (None, 224, 224, 128 0           concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_conv (Conv2D)    (None, 224, 224, 32) 36896       up_sampling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_bn (BatchNormali (None, 224, 224, 32) 128         decoder_output_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_activation (PReL (None, 224, 224, 32) 1605632     decoder_output_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "prediction (Conv2D)             (None, 224, 224, 1)  33          decoder_output_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 224, 224, 1)  0           prediction[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 42,912,065\n",
            "Trainable params: 42,856,833\n",
            "Non-trainable params: 55,232\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avLSSfxqQGgM",
        "colab_type": "text"
      },
      "source": [
        "### Train model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "_e-pCIisQGgN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5dd32e02-85b7-4b7e-bdec-b12868873632"
      },
      "source": [
        "K.clear_session()\n",
        "\n",
        "# Build model:\n",
        "# Here, you can experiment with various losses.\n",
        "# For dice and BCE (binary_crossentropy), my_iou_metric should be used,\n",
        "# whereas for lovash_loss my_iou_metric2 should be used, because range of values\n",
        "# for lovash loss is between -inf and +inf, not between 0 and 1, as for BCE and dice.\n",
        "# What is more, when lovash loss is used, last layer (sigmoid) should be deleted.\n",
        "# This is controlled by use_lovash parameter.\n",
        "model_depth = unet_resnet(\n",
        "    input_size, decoder_block_bottleneck, weights='imagenet',\n",
        "    loss_func=bce_dice_loss, metrics_list=[my_iou_metric],\n",
        "    use_lovash=False)\n",
        "print(model_depth.summary())\n",
        "\n",
        "\n",
        "model_checkpoint = ModelCheckpoint(\n",
        "    'unet_resnet.h5' ,monitor='val_my_iou_metric', mode='max',\n",
        "    save_best_only=True, save_weights_only=True, verbose=1)\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_my_iou_metric',\n",
        "    mode='max',\n",
        "    factor=0.5, \n",
        "    patience=5, \n",
        "    min_lr=0.0001, \n",
        "    verbose=1)\n",
        "\n",
        "\n",
        "epochs = 50  # 25\n",
        "batch_size = 16\n",
        "\n",
        "history = model_depth.fit(X_tr, y_tr,\n",
        "                    validation_data=[X_val, y_val], \n",
        "                    epochs=epochs,\n",
        "                    batch_size=batch_size,\n",
        "                    callbacks=[model_checkpoint,reduce_lr], \n",
        "                    verbose=1)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
            "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n",
            "                                                                 bn2a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 56, 56, 256)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n",
            "                                                                 activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 56, 56, 256)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n",
            "                                                                 activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 56, 56, 256)  0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
            "                                                                 bn3a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
            "                                                                 activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
            "                                                                 activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
            "                                                                 activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 28, 28, 512)  0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
            "                                                                 bn4a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
            "                                                                 activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
            "                                                                 activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
            "                                                                 activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
            "                                                                 activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
            "                                                                 bn5a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n",
            "                                                                 activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 2048)   0           add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "center_conv1 (Conv2D)           (None, 7, 7, 512)    9437696     activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "center_bn1 (BatchNormalization) (None, 7, 7, 512)    2048        center_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "center_activation1 (PReLU)      (None, 7, 7, 512)    25088       center_bn1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 7, 7, 512)    0           center_activation1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "center_conv2 (Conv2D)           (None, 7, 7, 256)    1179904     dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "center_bn2 (BatchNormalization) (None, 7, 7, 256)    1024        center_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "center_activation2 (PReLU)      (None, 7, 7, 256)    12544       center_bn2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 7, 7, 256)    0           center_activation2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "center_conv3 (Conv2D)           (None, 7, 7, 512)    1180160     dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "center_bn3 (BatchNormalization) (None, 7, 7, 512)    2048        center_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "center_activation3 (PReLU)      (None, 7, 7, 512)    25088       center_bn3[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 7, 7, 512)    0           center_activation3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "add_17 (Add)                    (None, 7, 7, 512)    0           dropout_1[0][0]                  \n",
            "                                                                 dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 7, 7, 2560)   0           add_17[0][0]                     \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_conv1 (Conv2D)         (None, 7, 7, 256)    5898496     concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_bn1 (BatchNormalizatio (None, 7, 7, 256)    1024        decoder4_conv1[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_activation1 (PReLU)    (None, 7, 7, 256)    12544       decoder4_bn1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 7, 7, 256)    0           decoder4_activation1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_conv2 (Conv2D)         (None, 7, 7, 128)    295040      dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_bn2 (BatchNormalizatio (None, 7, 7, 128)    512         decoder4_conv2[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_activation2 (PReLU)    (None, 7, 7, 128)    6272        decoder4_bn2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 7, 7, 128)    0           decoder4_activation2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_conv3 (Conv2D)         (None, 7, 7, 256)    295168      dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_bn3 (BatchNormalizatio (None, 7, 7, 256)    1024        decoder4_conv3[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_activation3 (PReLU)    (None, 7, 7, 256)    12544       decoder4_bn3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 7, 7, 256)    0           decoder4_activation3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_18 (Add)                    (None, 7, 7, 256)    0           dropout_4[0][0]                  \n",
            "                                                                 dropout_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2D)  (None, 14, 14, 256)  0           add_18[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 14, 14, 1280) 0           up_sampling2d_1[0][0]            \n",
            "                                                                 activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_conv1 (Conv2D)         (None, 14, 14, 128)  1474688     concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_bn1 (BatchNormalizatio (None, 14, 14, 128)  512         decoder3_conv1[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_activation1 (PReLU)    (None, 14, 14, 128)  25088       decoder3_bn1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 14, 14, 128)  0           decoder3_activation1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_conv2 (Conv2D)         (None, 14, 14, 64)   73792       dropout_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_bn2 (BatchNormalizatio (None, 14, 14, 64)   256         decoder3_conv2[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_activation2 (PReLU)    (None, 14, 14, 64)   12544       decoder3_bn2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_8 (Dropout)             (None, 14, 14, 64)   0           decoder3_activation2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_conv3 (Conv2D)         (None, 14, 14, 128)  73856       dropout_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_bn3 (BatchNormalizatio (None, 14, 14, 128)  512         decoder3_conv3[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_activation3 (PReLU)    (None, 14, 14, 128)  25088       decoder3_bn3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_9 (Dropout)             (None, 14, 14, 128)  0           decoder3_activation3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_19 (Add)                    (None, 14, 14, 128)  0           dropout_7[0][0]                  \n",
            "                                                                 dropout_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2D)  (None, 28, 28, 128)  0           add_19[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 28, 28, 640)  0           up_sampling2d_2[0][0]            \n",
            "                                                                 activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_conv1 (Conv2D)         (None, 28, 28, 64)   368704      concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_bn1 (BatchNormalizatio (None, 28, 28, 64)   256         decoder2_conv1[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_activation1 (PReLU)    (None, 28, 28, 64)   50176       decoder2_bn1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_10 (Dropout)            (None, 28, 28, 64)   0           decoder2_activation1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_conv2 (Conv2D)         (None, 28, 28, 32)   18464       dropout_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_bn2 (BatchNormalizatio (None, 28, 28, 32)   128         decoder2_conv2[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_activation2 (PReLU)    (None, 28, 28, 32)   25088       decoder2_bn2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_11 (Dropout)            (None, 28, 28, 32)   0           decoder2_activation2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_conv3 (Conv2D)         (None, 28, 28, 64)   18496       dropout_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_bn3 (BatchNormalizatio (None, 28, 28, 64)   256         decoder2_conv3[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_activation3 (PReLU)    (None, 28, 28, 64)   50176       decoder2_bn3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_12 (Dropout)            (None, 28, 28, 64)   0           decoder2_activation3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_20 (Add)                    (None, 28, 28, 64)   0           dropout_10[0][0]                 \n",
            "                                                                 dropout_12[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_3 (UpSampling2D)  (None, 56, 56, 64)   0           add_20[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 56, 56, 320)  0           up_sampling2d_3[0][0]            \n",
            "                                                                 activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_conv1 (Conv2D)         (None, 56, 56, 64)   184384      concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_bn1 (BatchNormalizatio (None, 56, 56, 64)   256         decoder1_conv1[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_activation1 (PReLU)    (None, 56, 56, 64)   200704      decoder1_bn1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_13 (Dropout)            (None, 56, 56, 64)   0           decoder1_activation1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_conv2 (Conv2D)         (None, 56, 56, 32)   18464       dropout_13[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_bn2 (BatchNormalizatio (None, 56, 56, 32)   128         decoder1_conv2[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_activation2 (PReLU)    (None, 56, 56, 32)   100352      decoder1_bn2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_14 (Dropout)            (None, 56, 56, 32)   0           decoder1_activation2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_conv3 (Conv2D)         (None, 56, 56, 64)   18496       dropout_14[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_bn3 (BatchNormalizatio (None, 56, 56, 64)   256         decoder1_conv3[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_activation3 (PReLU)    (None, 56, 56, 64)   200704      decoder1_bn3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_15 (Dropout)            (None, 56, 56, 64)   0           decoder1_activation3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_21 (Add)                    (None, 56, 56, 64)   0           dropout_13[0][0]                 \n",
            "                                                                 dropout_15[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_4 (UpSampling2D)  (None, 112, 112, 64) 0           add_21[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 112, 112, 128 0           up_sampling2d_4[0][0]            \n",
            "                                                                 activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_5 (UpSampling2D)  (None, 224, 224, 128 0           concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_conv1 (Conv2D)   (None, 224, 224, 32) 36896       up_sampling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_bn1 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_activation1 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "dropout_16 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_conv2 (Conv2D)   (None, 224, 224, 16) 4624        dropout_16[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_bn2 (BatchNormal (None, 224, 224, 16) 64          decoder_output_conv2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_activation2 (PRe (None, 224, 224, 16) 802816      decoder_output_bn2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "dropout_17 (Dropout)            (None, 224, 224, 16) 0           decoder_output_activation2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_conv3 (Conv2D)   (None, 224, 224, 32) 4640        dropout_17[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_bn3 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_activation3 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "dropout_18 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation3[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "add_22 (Add)                    (None, 224, 224, 32) 0           dropout_16[0][0]                 \n",
            "                                                                 dropout_18[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "prediction (Conv2D)             (None, 224, 224, 1)  33          add_22[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 224, 224, 1)  0           prediction[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 48,978,353\n",
            "Trainable params: 48,919,953\n",
            "Non-trainable params: 58,400\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Train on 3196 samples, validate on 804 samples\n",
            "Epoch 1/50\n",
            "3196/3196 [==============================] - 86s 27ms/step - loss: 0.7144 - my_iou_metric: 0.3418 - val_loss: 4.5807 - val_my_iou_metric: 0.1160\n",
            "\n",
            "Epoch 00001: val_my_iou_metric improved from -inf to 0.11604, saving model to unet_resnet.h5\n",
            "Epoch 2/50\n",
            "3196/3196 [==============================] - 63s 20ms/step - loss: 0.5450 - my_iou_metric: 0.5079 - val_loss: 1.3075 - val_my_iou_metric: 0.2413\n",
            "\n",
            "Epoch 00002: val_my_iou_metric improved from 0.11604 to 0.24129, saving model to unet_resnet.h5\n",
            "Epoch 3/50\n",
            "3196/3196 [==============================] - 63s 20ms/step - loss: 0.4951 - my_iou_metric: 0.5518 - val_loss: 0.6864 - val_my_iou_metric: 0.4705\n",
            "\n",
            "Epoch 00003: val_my_iou_metric improved from 0.24129 to 0.47052, saving model to unet_resnet.h5\n",
            "Epoch 4/50\n",
            "3196/3196 [==============================] - 63s 20ms/step - loss: 0.4879 - my_iou_metric: 0.5838 - val_loss: 0.4970 - val_my_iou_metric: 0.6037\n",
            "\n",
            "Epoch 00004: val_my_iou_metric improved from 0.47052 to 0.60373, saving model to unet_resnet.h5\n",
            "Epoch 5/50\n",
            "3196/3196 [==============================] - 63s 20ms/step - loss: 0.4475 - my_iou_metric: 0.6012 - val_loss: 0.7233 - val_my_iou_metric: 0.4511\n",
            "\n",
            "Epoch 00005: val_my_iou_metric did not improve from 0.60373\n",
            "Epoch 6/50\n",
            "3196/3196 [==============================] - 63s 20ms/step - loss: 0.4379 - my_iou_metric: 0.6056 - val_loss: 0.5135 - val_my_iou_metric: 0.4052\n",
            "\n",
            "Epoch 00006: val_my_iou_metric did not improve from 0.60373\n",
            "Epoch 7/50\n",
            "3196/3196 [==============================] - 63s 20ms/step - loss: 0.4044 - my_iou_metric: 0.6336 - val_loss: 0.3701 - val_my_iou_metric: 0.6364\n",
            "\n",
            "Epoch 00007: val_my_iou_metric improved from 0.60373 to 0.63644, saving model to unet_resnet.h5\n",
            "Epoch 8/50\n",
            "3196/3196 [==============================] - 63s 20ms/step - loss: 0.3833 - my_iou_metric: 0.6385 - val_loss: 0.4734 - val_my_iou_metric: 0.6438\n",
            "\n",
            "Epoch 00008: val_my_iou_metric improved from 0.63644 to 0.64378, saving model to unet_resnet.h5\n",
            "Epoch 9/50\n",
            "3196/3196 [==============================] - 63s 20ms/step - loss: 0.3715 - my_iou_metric: 0.6608 - val_loss: 0.5081 - val_my_iou_metric: 0.5643\n",
            "\n",
            "Epoch 00009: val_my_iou_metric did not improve from 0.64378\n",
            "Epoch 10/50\n",
            "3196/3196 [==============================] - 63s 20ms/step - loss: 0.3608 - my_iou_metric: 0.6497 - val_loss: 0.4081 - val_my_iou_metric: 0.6566\n",
            "\n",
            "Epoch 00010: val_my_iou_metric improved from 0.64378 to 0.65659, saving model to unet_resnet.h5\n",
            "Epoch 11/50\n",
            "3196/3196 [==============================] - 63s 20ms/step - loss: 0.3295 - my_iou_metric: 0.6741 - val_loss: 0.4153 - val_my_iou_metric: 0.6042\n",
            "\n",
            "Epoch 00011: val_my_iou_metric did not improve from 0.65659\n",
            "Epoch 12/50\n",
            "3196/3196 [==============================] - 63s 20ms/step - loss: 0.3529 - my_iou_metric: 0.6581 - val_loss: 0.3650 - val_my_iou_metric: 0.6340\n",
            "\n",
            "Epoch 00012: val_my_iou_metric did not improve from 0.65659\n",
            "Epoch 13/50\n",
            "3196/3196 [==============================] - 63s 20ms/step - loss: 0.3463 - my_iou_metric: 0.6614 - val_loss: 0.4224 - val_my_iou_metric: 0.6326\n",
            "\n",
            "Epoch 00013: val_my_iou_metric did not improve from 0.65659\n",
            "Epoch 14/50\n",
            "3196/3196 [==============================] - 63s 20ms/step - loss: 0.3238 - my_iou_metric: 0.6739 - val_loss: 0.3494 - val_my_iou_metric: 0.6744\n",
            "\n",
            "Epoch 00014: val_my_iou_metric improved from 0.65659 to 0.67438, saving model to unet_resnet.h5\n",
            "Epoch 15/50\n",
            "3196/3196 [==============================] - 63s 20ms/step - loss: 0.2971 - my_iou_metric: 0.6829 - val_loss: 0.4509 - val_my_iou_metric: 0.6118\n",
            "\n",
            "Epoch 00015: val_my_iou_metric did not improve from 0.67438\n",
            "Epoch 16/50\n",
            "3196/3196 [==============================] - 63s 20ms/step - loss: 0.2902 - my_iou_metric: 0.6882 - val_loss: 0.4532 - val_my_iou_metric: 0.6100\n",
            "\n",
            "Epoch 00016: val_my_iou_metric did not improve from 0.67438\n",
            "Epoch 17/50\n",
            "3196/3196 [==============================] - 63s 20ms/step - loss: 0.2827 - my_iou_metric: 0.6933 - val_loss: 0.4428 - val_my_iou_metric: 0.6636\n",
            "\n",
            "Epoch 00017: val_my_iou_metric did not improve from 0.67438\n",
            "Epoch 18/50\n",
            "3196/3196 [==============================] - 63s 20ms/step - loss: 0.2869 - my_iou_metric: 0.6835 - val_loss: 0.4128 - val_my_iou_metric: 0.5818\n",
            "\n",
            "Epoch 00018: val_my_iou_metric did not improve from 0.67438\n",
            "Epoch 19/50\n",
            "3196/3196 [==============================] - 63s 20ms/step - loss: 0.2795 - my_iou_metric: 0.6906 - val_loss: 0.4079 - val_my_iou_metric: 0.6506\n",
            "\n",
            "Epoch 00019: val_my_iou_metric did not improve from 0.67438\n",
            "\n",
            "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "Epoch 20/50\n",
            "3196/3196 [==============================] - 63s 20ms/step - loss: 0.2195 - my_iou_metric: 0.7262 - val_loss: 0.3706 - val_my_iou_metric: 0.7252\n",
            "\n",
            "Epoch 00020: val_my_iou_metric improved from 0.67438 to 0.72525, saving model to unet_resnet.h5\n",
            "Epoch 21/50\n",
            "3196/3196 [==============================] - 63s 20ms/step - loss: 0.2012 - my_iou_metric: 0.7239 - val_loss: 0.3458 - val_my_iou_metric: 0.6857\n",
            "\n",
            "Epoch 00021: val_my_iou_metric did not improve from 0.72525\n",
            "Epoch 22/50\n",
            "3196/3196 [==============================] - 63s 20ms/step - loss: 0.1585 - my_iou_metric: 0.7528 - val_loss: 0.3485 - val_my_iou_metric: 0.7235\n",
            "\n",
            "Epoch 00022: val_my_iou_metric did not improve from 0.72525\n",
            "Epoch 23/50\n",
            "3196/3196 [==============================] - 63s 20ms/step - loss: 0.1614 - my_iou_metric: 0.7579 - val_loss: 0.4019 - val_my_iou_metric: 0.7073\n",
            "\n",
            "Epoch 00023: val_my_iou_metric did not improve from 0.72525\n",
            "Epoch 24/50\n",
            "3196/3196 [==============================] - 63s 20ms/step - loss: 0.1523 - my_iou_metric: 0.7625 - val_loss: 0.4019 - val_my_iou_metric: 0.7149\n",
            "\n",
            "Epoch 00024: val_my_iou_metric did not improve from 0.72525\n",
            "Epoch 25/50\n",
            "3196/3196 [==============================] - 63s 20ms/step - loss: 0.1356 - my_iou_metric: 0.7715 - val_loss: 0.3971 - val_my_iou_metric: 0.7082\n",
            "\n",
            "Epoch 00025: val_my_iou_metric did not improve from 0.72525\n",
            "\n",
            "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "Epoch 26/50\n",
            "3196/3196 [==============================] - 63s 20ms/step - loss: 0.1199 - my_iou_metric: 0.7873 - val_loss: 0.3586 - val_my_iou_metric: 0.7342\n",
            "\n",
            "Epoch 00026: val_my_iou_metric improved from 0.72525 to 0.73420, saving model to unet_resnet.h5\n",
            "Epoch 27/50\n",
            "3196/3196 [==============================] - 63s 20ms/step - loss: 0.1058 - my_iou_metric: 0.7983 - val_loss: 0.3453 - val_my_iou_metric: 0.7148\n",
            "\n",
            "Epoch 00027: val_my_iou_metric did not improve from 0.73420\n",
            "Epoch 28/50\n",
            "3196/3196 [==============================] - 63s 20ms/step - loss: 0.0990 - my_iou_metric: 0.7999 - val_loss: 0.3689 - val_my_iou_metric: 0.7264\n",
            "\n",
            "Epoch 00028: val_my_iou_metric did not improve from 0.73420\n",
            "Epoch 29/50\n",
            "3196/3196 [==============================] - 63s 20ms/step - loss: 0.0997 - my_iou_metric: 0.8071 - val_loss: 0.3761 - val_my_iou_metric: 0.7444\n",
            "\n",
            "Epoch 00029: val_my_iou_metric improved from 0.73420 to 0.74440, saving model to unet_resnet.h5\n",
            "Epoch 30/50\n",
            "3196/3196 [==============================] - 63s 20ms/step - loss: 0.0959 - my_iou_metric: 0.7997 - val_loss: 0.3681 - val_my_iou_metric: 0.7284\n",
            "\n",
            "Epoch 00030: val_my_iou_metric did not improve from 0.74440\n",
            "Epoch 31/50\n",
            "3196/3196 [==============================] - 63s 20ms/step - loss: 0.0916 - my_iou_metric: 0.8051 - val_loss: 0.3604 - val_my_iou_metric: 0.7428\n",
            "\n",
            "Epoch 00031: val_my_iou_metric did not improve from 0.74440\n",
            "Epoch 32/50\n",
            "3196/3196 [==============================] - 62s 20ms/step - loss: 0.0861 - my_iou_metric: 0.8145 - val_loss: 0.3718 - val_my_iou_metric: 0.7251\n",
            "\n",
            "Epoch 00032: val_my_iou_metric did not improve from 0.74440\n",
            "Epoch 33/50\n",
            "3196/3196 [==============================] - 62s 20ms/step - loss: 0.0855 - my_iou_metric: 0.8149 - val_loss: 0.3783 - val_my_iou_metric: 0.7332\n",
            "\n",
            "Epoch 00033: val_my_iou_metric did not improve from 0.74440\n",
            "Epoch 34/50\n",
            "3196/3196 [==============================] - 63s 20ms/step - loss: 0.0824 - my_iou_metric: 0.8170 - val_loss: 0.3727 - val_my_iou_metric: 0.7126\n",
            "\n",
            "Epoch 00034: val_my_iou_metric did not improve from 0.74440\n",
            "\n",
            "Epoch 00034: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "Epoch 35/50\n",
            "3196/3196 [==============================] - 63s 20ms/step - loss: 0.0744 - my_iou_metric: 0.8312 - val_loss: 0.3659 - val_my_iou_metric: 0.7275\n",
            "\n",
            "Epoch 00035: val_my_iou_metric did not improve from 0.74440\n",
            "Epoch 36/50\n",
            "3196/3196 [==============================] - 63s 20ms/step - loss: 0.0724 - my_iou_metric: 0.8254 - val_loss: 0.3722 - val_my_iou_metric: 0.7443\n",
            "\n",
            "Epoch 00036: val_my_iou_metric did not improve from 0.74440\n",
            "Epoch 37/50\n",
            "3196/3196 [==============================] - 63s 20ms/step - loss: 0.0685 - my_iou_metric: 0.8322 - val_loss: 0.3918 - val_my_iou_metric: 0.7450\n",
            "\n",
            "Epoch 00037: val_my_iou_metric improved from 0.74440 to 0.74502, saving model to unet_resnet.h5\n",
            "Epoch 38/50\n",
            "3196/3196 [==============================] - 63s 20ms/step - loss: 0.0672 - my_iou_metric: 0.8301 - val_loss: 0.3636 - val_my_iou_metric: 0.7371\n",
            "\n",
            "Epoch 00038: val_my_iou_metric did not improve from 0.74502\n",
            "Epoch 39/50\n",
            "3196/3196 [==============================] - 63s 20ms/step - loss: 0.0706 - my_iou_metric: 0.8402 - val_loss: 0.3834 - val_my_iou_metric: 0.7328\n",
            "\n",
            "Epoch 00039: val_my_iou_metric did not improve from 0.74502\n",
            "Epoch 40/50\n",
            "3196/3196 [==============================] - 63s 20ms/step - loss: 0.0653 - my_iou_metric: 0.8426 - val_loss: 0.3702 - val_my_iou_metric: 0.7359\n",
            "\n",
            "Epoch 00040: val_my_iou_metric did not improve from 0.74502\n",
            "Epoch 41/50\n",
            "3196/3196 [==============================] - 63s 20ms/step - loss: 0.0674 - my_iou_metric: 0.8367 - val_loss: 0.3818 - val_my_iou_metric: 0.7323\n",
            "\n",
            "Epoch 00041: val_my_iou_metric did not improve from 0.74502\n",
            "Epoch 42/50\n",
            "3196/3196 [==============================] - 63s 20ms/step - loss: 0.0609 - my_iou_metric: 0.8391 - val_loss: 0.3871 - val_my_iou_metric: 0.7285\n",
            "\n",
            "Epoch 00042: val_my_iou_metric did not improve from 0.74502\n",
            "\n",
            "Epoch 00042: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
            "Epoch 43/50\n",
            "3196/3196 [==============================] - 63s 20ms/step - loss: 0.0612 - my_iou_metric: 0.8446 - val_loss: 0.3883 - val_my_iou_metric: 0.7392\n",
            "\n",
            "Epoch 00043: val_my_iou_metric did not improve from 0.74502\n",
            "Epoch 44/50\n",
            "3196/3196 [==============================] - 63s 20ms/step - loss: 0.0593 - my_iou_metric: 0.8503 - val_loss: 0.3687 - val_my_iou_metric: 0.7302\n",
            "\n",
            "Epoch 00044: val_my_iou_metric did not improve from 0.74502\n",
            "Epoch 45/50\n",
            "3196/3196 [==============================] - 63s 20ms/step - loss: 0.0602 - my_iou_metric: 0.8515 - val_loss: 0.3799 - val_my_iou_metric: 0.7299\n",
            "\n",
            "Epoch 00045: val_my_iou_metric did not improve from 0.74502\n",
            "Epoch 46/50\n",
            "3196/3196 [==============================] - 63s 20ms/step - loss: 0.0578 - my_iou_metric: 0.8553 - val_loss: 0.3949 - val_my_iou_metric: 0.7404\n",
            "\n",
            "Epoch 00046: val_my_iou_metric did not improve from 0.74502\n",
            "Epoch 47/50\n",
            "3196/3196 [==============================] - 63s 20ms/step - loss: 0.0555 - my_iou_metric: 0.8603 - val_loss: 0.4135 - val_my_iou_metric: 0.7382\n",
            "\n",
            "Epoch 00047: val_my_iou_metric did not improve from 0.74502\n",
            "Epoch 48/50\n",
            "3196/3196 [==============================] - 63s 20ms/step - loss: 0.0557 - my_iou_metric: 0.8531 - val_loss: 0.4055 - val_my_iou_metric: 0.7423\n",
            "\n",
            "Epoch 00048: val_my_iou_metric did not improve from 0.74502\n",
            "Epoch 49/50\n",
            "3196/3196 [==============================] - 63s 20ms/step - loss: 0.0560 - my_iou_metric: 0.8586 - val_loss: 0.4306 - val_my_iou_metric: 0.7362\n",
            "\n",
            "Epoch 00049: val_my_iou_metric did not improve from 0.74502\n",
            "Epoch 50/50\n",
            "3196/3196 [==============================] - 63s 20ms/step - loss: 0.0548 - my_iou_metric: 0.8559 - val_loss: 0.4040 - val_my_iou_metric: 0.7405\n",
            "\n",
            "Epoch 00050: val_my_iou_metric did not improve from 0.74502\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kx3WQi3HQGgO",
        "colab_type": "text"
      },
      "source": [
        "### Validation set prediction and resizing to original size:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGHWgDGTQGgP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_preds = model_depth.predict(X_val, batch_size=16)\n",
        "\n",
        "y_val_pred = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), val_preds)))\n",
        "y_val_true = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), y_val)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TAdI4IlAQGgQ",
        "colab_type": "text"
      },
      "source": [
        "### Threshold optimization: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9pFgvcvQGgQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# src: https://www.kaggle.com/aglotero/another-iou-metric\n",
        "def iou_metric(y_true_in, y_pred_in, print_table=False):\n",
        "    labels = y_true_in\n",
        "    y_pred = y_pred_in\n",
        "    \n",
        "    true_objects = 2\n",
        "    pred_objects = 2\n",
        "\n",
        "    intersection = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=(true_objects, pred_objects))[0]\n",
        "\n",
        "    # Compute areas (needed for finding the union between all objects)\n",
        "    area_true = np.histogram(labels, bins = true_objects)[0]\n",
        "    area_pred = np.histogram(y_pred, bins = pred_objects)[0]\n",
        "    area_true = np.expand_dims(area_true, -1)\n",
        "    area_pred = np.expand_dims(area_pred, 0)\n",
        "\n",
        "    # Compute union\n",
        "    union = area_true + area_pred - intersection\n",
        "\n",
        "    # Exclude background from the analysis\n",
        "    intersection = intersection[1:,1:]\n",
        "    union = union[1:,1:]\n",
        "    union[union == 0] = 1e-9\n",
        "\n",
        "    # Compute the intersection over union\n",
        "    iou = intersection / union\n",
        "\n",
        "    # Precision helper function\n",
        "    def precision_at(threshold, iou):\n",
        "        matches = iou > threshold\n",
        "        true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n",
        "        false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n",
        "        false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n",
        "        tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n",
        "        return tp, fp, fn\n",
        "\n",
        "    # Loop over IoU thresholds\n",
        "    prec = []\n",
        "    if print_table:\n",
        "        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n",
        "    for t in np.arange(0.5, 1.0, 0.05):\n",
        "        tp, fp, fn = precision_at(t, iou)\n",
        "        if (tp + fp + fn) > 0:\n",
        "            p = tp / (tp + fp + fn)\n",
        "        else:\n",
        "            p = 0\n",
        "        if print_table:\n",
        "            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tp, fp, fn, p))\n",
        "        prec.append(p)\n",
        "    \n",
        "    if print_table:\n",
        "        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n",
        "    return np.mean(prec)\n",
        "\n",
        "def iou_metric_batch(y_true_in, y_pred_in):\n",
        "    batch_size = y_true_in.shape[0]\n",
        "    metric = []\n",
        "    for batch in range(batch_size):\n",
        "        value = iou_metric(y_true_in[batch], y_pred_in[batch])\n",
        "        metric.append(value)\n",
        "    return np.mean(metric)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNLqbcK1QGgS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "679d5eda-3f07-4768-e622-877ac8bb02c2"
      },
      "source": [
        "# Threshold range, over which optimization is performed\n",
        "thresholds = np.arange(0.2, 0.9, 0.02)\n",
        "\n",
        "# For every threshold, set predictions to binary arrays, \n",
        "# where values above threshold are treated as 1 and the rest as 0.\n",
        "# Loop over thresholds and compute IoU for them based on IoU function above.\n",
        "ious = np.array(\n",
        "    [iou_metric_batch(y_val_true,\n",
        "                      np.int32(y_val_pred > threshold)) for threshold in tqdm(thresholds)])"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 35/35 [00:36<00:00,  1.04s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTQthcNGQGgT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "outputId": "8449eb4b-834c-40cb-b692-fcd790b9c8aa"
      },
      "source": [
        "df_iou = pd.DataFrame(thresholds, columns=['threshold'])\n",
        "df_iou['iou'] = ious\n",
        "\n",
        "# Get index of best IoU\n",
        "best_index = df_iou['iou'].idxmax()\n",
        "print('Best IoU: {:.4f} at threshold: {:.3f}'.format(\n",
        "    df_iou.iou[best_index], df_iou.threshold[best_index]))\n",
        "\n",
        "# Describe IoU DF\n",
        "df_iou.describe()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best IoU: 0.7578 at threshold: 0.840\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>threshold</th>\n",
              "      <th>iou</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>35.000000</td>\n",
              "      <td>35.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.540000</td>\n",
              "      <td>0.752164</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.204939</td>\n",
              "      <td>0.004597</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.742413</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.370000</td>\n",
              "      <td>0.749565</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.540000</td>\n",
              "      <td>0.752612</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.710000</td>\n",
              "      <td>0.756032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>0.880000</td>\n",
              "      <td>0.757836</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       threshold        iou\n",
              "count  35.000000  35.000000\n",
              "mean    0.540000   0.752164\n",
              "std     0.204939   0.004597\n",
              "min     0.200000   0.742413\n",
              "25%     0.370000   0.749565\n",
              "50%     0.540000   0.752612\n",
              "75%     0.710000   0.756032\n",
              "max     0.880000   0.757836"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwVlpyIRQGgV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 588
        },
        "outputId": "cb13b4d2-8a84-4656-b16a-7f31e6ec88f7"
      },
      "source": [
        "# Plot IoU values over threshold range.\n",
        "df_iou.plot(x='threshold', y='iou')"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f0c525093c8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAs8AAAIWCAYAAACoQ2BQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 864x648 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANuyQsx0nRGy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Dg-avrzRx7i",
        "colab_type": "text"
      },
      "source": [
        "## コードリーディング\n",
        "\n",
        "- 画像についての特徴量エンジニアリングを行なっている。具体的には、深度情報を擬似的に付加して学習させることで、スコアを若干改善している\n",
        "- trainデータ分割のところで、yラベルを擬似的にクラス分けして、データが適切に分割されるよう調整している。\n",
        "- 転移学習では、重みの固定は行わず、初期値として利用している。ImageNETの画像と地震探査画像が大きく異なる点がその理由と考えられる。\n",
        "- UnetのDeConvolutionでは、プーリング前のデータを使用することで、特徴量情報をlossさせない工夫をしている。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "padALNDvnRqY",
        "colab_type": "text"
      },
      "source": [
        "## VGGで学習・推定"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8o7jDRFnVPQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        },
        "outputId": "663ec814-f0e1-45b1-e302-848f98d7da55"
      },
      "source": [
        "input_size = (224, 224, 3)\n",
        "\n",
        "K.clear_session()\n",
        "base_model = VGG16(input_shape=input_size, include_top=False)\n",
        "for layer in base_model.layers[:10]:\n",
        "    layer.trainable = False\n",
        "base_model.summary()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 12,979,200\n",
            "Non-trainable params: 1,735,488\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXASf3kasab3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Model is parametrized in a way to enable easy change of decoder_block type,\n",
        "# as this is an argument that can be given a function, like decoder_block_simple.\n",
        "def unet_vgg(input_size, decoder_block,\n",
        "                weights='imagenet',\n",
        "                loss_func='binary_crossentropy',\n",
        "                metrics_list=[my_iou_metric],\n",
        "                use_lovash=False):\n",
        "\n",
        "    # Base model - encoder\n",
        "    base_model = VGG16(\n",
        "        input_shape=input_size, \n",
        "        include_top=False,\n",
        "        weights=weights)\n",
        "    \n",
        "    # Layers for feature extraction in the encoder part\n",
        "    encoder1 = base_model.get_layer('block1_conv2').output #(None, 224, 224, 64)\n",
        "    encoder2 = base_model.get_layer('block2_conv2').output #(None, 112, 112, 128) \n",
        "    encoder3 = base_model.get_layer('block3_conv3').output  #(None, 56, 56, 256)\n",
        "    encoder4 = base_model.get_layer('block4_conv3').output  #(None, 28, 28, 512) \n",
        "    encoder5 = base_model.get_layer('block5_conv3').output  #(None, 14, 14, 512)\n",
        "    encoder6 = base_model.get_layer('block5_pool').output #(None, 7, 7, 512)\n",
        "\n",
        "    # Center block\n",
        "    center = decoder_block(\n",
        "        encoder6, 'center', num_filters=128)\n",
        "    concat6 = concatenate([center, encoder6], axis=-1) #(None, 7, 7, 640)\n",
        "\n",
        "    # Decoder part.\n",
        "    # Every decoder block processed concatenated output from encoder and decoder part.\n",
        "    # This creates skip connections.\n",
        "    # Afterwards, decoder output is upsampled to dimensions equal to encoder output part.\n",
        "    decoder5 = decoder_block(\n",
        "        concat6, 'decoder5', num_filters=64) #(None, 7, 7, 256)\n",
        "    concat5 = concatenate([UpSampling2D()(decoder5), encoder5], axis=-1) #(None, 14, 14, 576)\n",
        "\n",
        "    decoder4 = decoder_block(\n",
        "        concat5, 'decoder4', num_filters=64) #(None, 14, 14, 64) \n",
        "    concat4 = concatenate([UpSampling2D()(decoder4), encoder4], axis=-1) #(None, 28, 28, 576)\n",
        "\n",
        "    decoder3 = decoder_block(\n",
        "        concat4, 'decoder3', num_filters=32) #(None, 28, 28, 32)\n",
        "    concat3 = concatenate([UpSampling2D()(decoder3), encoder3], axis=-1) #(None, 56, 56, 288)\n",
        "\n",
        "    decoder2 = decoder_block(\n",
        "        concat3, 'decoder2', num_filters=16) #(None, 56, 56, 16)\n",
        "    concat2 = concatenate([UpSampling2D()(decoder2), encoder2], axis=-1) #(None, 112, 112, 144)\n",
        "\n",
        "    decoder1 = decoder_block(\n",
        "        concat2, 'decoder1', num_filters=8) # (None, 112, 112, 8)\n",
        "    concat1 = concatenate([UpSampling2D()(decoder1), encoder1], axis=-1) #(None, 224, 224, 72)\n",
        "\n",
        "    # Final upsampling and decoder block for segmentation.\n",
        "    #output = UpSampling2D()(concat1)\n",
        "    output = decoder_block(\n",
        "        concat1, 'decoder_output', num_filters=32)\n",
        "    output = Conv2D(\n",
        "        1, (1, 1), activation=None, name='prediction')(output)\n",
        "    if not use_lovash:\n",
        "        output = Activation('sigmoid')(output)\n",
        "        \n",
        "    model = Model(base_model.input, output)\n",
        "\n",
        "    model.compile(loss=loss_func, optimizer='adam', metrics=metrics_list)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkO_Nk3W32qh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "71def6dc-25b4-45d8-a541-86d2718f531f"
      },
      "source": [
        "#inspect created model\n",
        "input_size = (224, 224, 3)\n",
        "\n",
        "K.clear_session()\n",
        "model = unet_vgg(\n",
        "    input_size, decoder_block_simple, weights='imagenet')\n",
        "for layer in base_model.layers[:10]:\n",
        "    layer.trainable = False\n",
        "model.summary()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:107: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:111: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2239: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From <ipython-input-22-910567864b2d>:153: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1 (Conv2D)           (None, 224, 224, 64) 1792        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2 (Conv2D)           (None, 224, 224, 64) 36928       block1_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block1_pool (MaxPooling2D)      (None, 112, 112, 64) 0           block1_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block2_conv1 (Conv2D)           (None, 112, 112, 128 73856       block1_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block2_conv2 (Conv2D)           (None, 112, 112, 128 147584      block2_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block2_pool (MaxPooling2D)      (None, 56, 56, 128)  0           block2_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv1 (Conv2D)           (None, 56, 56, 256)  295168      block2_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv2 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv3 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block3_pool (MaxPooling2D)      (None, 28, 28, 256)  0           block3_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv1 (Conv2D)           (None, 28, 28, 512)  1180160     block3_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv2 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv3 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block4_pool (MaxPooling2D)      (None, 14, 14, 512)  0           block4_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block5_conv1 (Conv2D)           (None, 14, 14, 512)  2359808     block4_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block5_conv2 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block5_conv3 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block5_pool (MaxPooling2D)      (None, 7, 7, 512)    0           block5_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "center_conv (Conv2D)            (None, 7, 7, 128)    589952      block5_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "center_bn (BatchNormalization)  (None, 7, 7, 128)    512         center_conv[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "center_activation (PReLU)       (None, 7, 7, 128)    6272        center_bn[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 7, 7, 640)    0           center_activation[0][0]          \n",
            "                                                                 block5_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "decoder5_conv (Conv2D)          (None, 7, 7, 64)     368704      concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder5_bn (BatchNormalization (None, 7, 7, 64)     256         decoder5_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder5_activation (PReLU)     (None, 7, 7, 64)     3136        decoder5_bn[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2D)  (None, 14, 14, 64)   0           decoder5_activation[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 14, 14, 576)  0           up_sampling2d_1[0][0]            \n",
            "                                                                 block5_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_conv (Conv2D)          (None, 14, 14, 64)   331840      concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_bn (BatchNormalization (None, 14, 14, 64)   256         decoder4_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_activation (PReLU)     (None, 14, 14, 64)   12544       decoder4_bn[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2D)  (None, 28, 28, 64)   0           decoder4_activation[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 28, 28, 576)  0           up_sampling2d_2[0][0]            \n",
            "                                                                 block4_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_conv (Conv2D)          (None, 28, 28, 32)   165920      concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_bn (BatchNormalization (None, 28, 28, 32)   128         decoder3_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_activation (PReLU)     (None, 28, 28, 32)   25088       decoder3_bn[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_3 (UpSampling2D)  (None, 56, 56, 32)   0           decoder3_activation[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 56, 56, 288)  0           up_sampling2d_3[0][0]            \n",
            "                                                                 block3_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_conv (Conv2D)          (None, 56, 56, 16)   41488       concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_bn (BatchNormalization (None, 56, 56, 16)   64          decoder2_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_activation (PReLU)     (None, 56, 56, 16)   50176       decoder2_bn[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_4 (UpSampling2D)  (None, 112, 112, 16) 0           decoder2_activation[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 112, 112, 144 0           up_sampling2d_4[0][0]            \n",
            "                                                                 block2_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_conv (Conv2D)          (None, 112, 112, 8)  10376       concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_bn (BatchNormalization (None, 112, 112, 8)  32          decoder1_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_activation (PReLU)     (None, 112, 112, 8)  100352      decoder1_bn[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_5 (UpSampling2D)  (None, 224, 224, 8)  0           decoder1_activation[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 224, 224, 72) 0           up_sampling2d_5[0][0]            \n",
            "                                                                 block1_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_conv (Conv2D)    (None, 224, 224, 32) 20768       concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_bn (BatchNormali (None, 224, 224, 32) 128         decoder_output_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_activation (PReL (None, 224, 224, 32) 1605632     decoder_output_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "prediction (Conv2D)             (None, 224, 224, 1)  33          decoder_output_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 224, 224, 1)  0           prediction[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 18,048,345\n",
            "Trainable params: 18,047,657\n",
            "Non-trainable params: 688\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LRqzi_i4KTz",
        "colab_type": "text"
      },
      "source": [
        "### Train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kf88U18W4OJZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1a045b8f-541d-4e31-c76f-ef7874207c99"
      },
      "source": [
        "K.clear_session()\n",
        "\n",
        "# Build model:\n",
        "# Here, you can experiment with various losses.\n",
        "# For dice and BCE (binary_crossentropy), my_iou_metric should be used,\n",
        "# whereas for lovash_loss my_iou_metric2 should be used, because range of values\n",
        "# for lovash loss is between -inf and +inf, not between 0 and 1, as for BCE and dice.\n",
        "# What is more, when lovash loss is used, last layer (sigmoid) should be deleted.\n",
        "# This is controlled by use_lovash parameter.\n",
        "model_depth = unet_vgg(\n",
        "    input_size, decoder_block_bottleneck, weights='imagenet',\n",
        "    loss_func=bce_dice_loss, metrics_list=[my_iou_metric],\n",
        "    use_lovash=False)\n",
        "print(model_depth.summary())\n",
        "\n",
        "\n",
        "model_checkpoint = ModelCheckpoint(\n",
        "    'unet_vgg.h5' ,monitor='val_my_iou_metric', mode='max',\n",
        "    save_best_only=True, save_weights_only=True, verbose=1)\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_my_iou_metric',\n",
        "    mode='max',\n",
        "    factor=0.5, \n",
        "    patience=5, \n",
        "    min_lr=0.0001, \n",
        "    verbose=1)\n",
        "\n",
        "\n",
        "epochs = 50  # 25\n",
        "batch_size = 16\n",
        "\n",
        "history = model_depth.fit(X_tr, y_tr,\n",
        "                    validation_data=[X_val, y_val], \n",
        "                    epochs=epochs,\n",
        "                    batch_size=batch_size,\n",
        "                    callbacks=[model_checkpoint,reduce_lr], \n",
        "                    verbose=1)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1 (Conv2D)           (None, 224, 224, 64) 1792        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2 (Conv2D)           (None, 224, 224, 64) 36928       block1_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block1_pool (MaxPooling2D)      (None, 112, 112, 64) 0           block1_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block2_conv1 (Conv2D)           (None, 112, 112, 128 73856       block1_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block2_conv2 (Conv2D)           (None, 112, 112, 128 147584      block2_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block2_pool (MaxPooling2D)      (None, 56, 56, 128)  0           block2_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv1 (Conv2D)           (None, 56, 56, 256)  295168      block2_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv2 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv3 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block3_pool (MaxPooling2D)      (None, 28, 28, 256)  0           block3_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv1 (Conv2D)           (None, 28, 28, 512)  1180160     block3_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv2 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv3 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block4_pool (MaxPooling2D)      (None, 14, 14, 512)  0           block4_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block5_conv1 (Conv2D)           (None, 14, 14, 512)  2359808     block4_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block5_conv2 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block5_conv3 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block5_pool (MaxPooling2D)      (None, 7, 7, 512)    0           block5_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "center_conv1 (Conv2D)           (None, 7, 7, 128)    589952      block5_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "center_bn1 (BatchNormalization) (None, 7, 7, 128)    512         center_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "center_activation1 (PReLU)      (None, 7, 7, 128)    6272        center_bn1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 7, 7, 128)    0           center_activation1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "center_conv2 (Conv2D)           (None, 7, 7, 64)     73792       dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "center_bn2 (BatchNormalization) (None, 7, 7, 64)     256         center_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "center_activation2 (PReLU)      (None, 7, 7, 64)     3136        center_bn2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 7, 7, 64)     0           center_activation2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "center_conv3 (Conv2D)           (None, 7, 7, 128)    73856       dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "center_bn3 (BatchNormalization) (None, 7, 7, 128)    512         center_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "center_activation3 (PReLU)      (None, 7, 7, 128)    6272        center_bn3[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 7, 7, 128)    0           center_activation3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 7, 7, 128)    0           dropout_1[0][0]                  \n",
            "                                                                 dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 7, 7, 640)    0           add_1[0][0]                      \n",
            "                                                                 block5_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "decoder5_conv1 (Conv2D)         (None, 7, 7, 64)     368704      concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder5_bn1 (BatchNormalizatio (None, 7, 7, 64)     256         decoder5_conv1[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder5_activation1 (PReLU)    (None, 7, 7, 64)     3136        decoder5_bn1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 7, 7, 64)     0           decoder5_activation1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder5_conv2 (Conv2D)         (None, 7, 7, 32)     18464       dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "decoder5_bn2 (BatchNormalizatio (None, 7, 7, 32)     128         decoder5_conv2[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder5_activation2 (PReLU)    (None, 7, 7, 32)     1568        decoder5_bn2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 7, 7, 32)     0           decoder5_activation2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder5_conv3 (Conv2D)         (None, 7, 7, 64)     18496       dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "decoder5_bn3 (BatchNormalizatio (None, 7, 7, 64)     256         decoder5_conv3[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder5_activation3 (PReLU)    (None, 7, 7, 64)     3136        decoder5_bn3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 7, 7, 64)     0           decoder5_activation3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 7, 7, 64)     0           dropout_4[0][0]                  \n",
            "                                                                 dropout_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2D)  (None, 14, 14, 64)   0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 14, 14, 576)  0           up_sampling2d_1[0][0]            \n",
            "                                                                 block5_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_conv1 (Conv2D)         (None, 14, 14, 64)   331840      concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_bn1 (BatchNormalizatio (None, 14, 14, 64)   256         decoder4_conv1[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_activation1 (PReLU)    (None, 14, 14, 64)   12544       decoder4_bn1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 14, 14, 64)   0           decoder4_activation1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_conv2 (Conv2D)         (None, 14, 14, 32)   18464       dropout_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_bn2 (BatchNormalizatio (None, 14, 14, 32)   128         decoder4_conv2[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_activation2 (PReLU)    (None, 14, 14, 32)   6272        decoder4_bn2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_8 (Dropout)             (None, 14, 14, 32)   0           decoder4_activation2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_conv3 (Conv2D)         (None, 14, 14, 64)   18496       dropout_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_bn3 (BatchNormalizatio (None, 14, 14, 64)   256         decoder4_conv3[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_activation3 (PReLU)    (None, 14, 14, 64)   12544       decoder4_bn3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_9 (Dropout)             (None, 14, 14, 64)   0           decoder4_activation3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 14, 14, 64)   0           dropout_7[0][0]                  \n",
            "                                                                 dropout_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2D)  (None, 28, 28, 64)   0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 28, 28, 576)  0           up_sampling2d_2[0][0]            \n",
            "                                                                 block4_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_conv1 (Conv2D)         (None, 28, 28, 32)   165920      concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_bn1 (BatchNormalizatio (None, 28, 28, 32)   128         decoder3_conv1[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_activation1 (PReLU)    (None, 28, 28, 32)   25088       decoder3_bn1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_10 (Dropout)            (None, 28, 28, 32)   0           decoder3_activation1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_conv2 (Conv2D)         (None, 28, 28, 16)   4624        dropout_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_bn2 (BatchNormalizatio (None, 28, 28, 16)   64          decoder3_conv2[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_activation2 (PReLU)    (None, 28, 28, 16)   12544       decoder3_bn2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_11 (Dropout)            (None, 28, 28, 16)   0           decoder3_activation2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_conv3 (Conv2D)         (None, 28, 28, 32)   4640        dropout_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_bn3 (BatchNormalizatio (None, 28, 28, 32)   128         decoder3_conv3[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_activation3 (PReLU)    (None, 28, 28, 32)   25088       decoder3_bn3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_12 (Dropout)            (None, 28, 28, 32)   0           decoder3_activation3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 28, 28, 32)   0           dropout_10[0][0]                 \n",
            "                                                                 dropout_12[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_3 (UpSampling2D)  (None, 56, 56, 32)   0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 56, 56, 288)  0           up_sampling2d_3[0][0]            \n",
            "                                                                 block3_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_conv1 (Conv2D)         (None, 56, 56, 16)   41488       concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_bn1 (BatchNormalizatio (None, 56, 56, 16)   64          decoder2_conv1[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_activation1 (PReLU)    (None, 56, 56, 16)   50176       decoder2_bn1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_13 (Dropout)            (None, 56, 56, 16)   0           decoder2_activation1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_conv2 (Conv2D)         (None, 56, 56, 8)    1160        dropout_13[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_bn2 (BatchNormalizatio (None, 56, 56, 8)    32          decoder2_conv2[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_activation2 (PReLU)    (None, 56, 56, 8)    25088       decoder2_bn2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_14 (Dropout)            (None, 56, 56, 8)    0           decoder2_activation2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_conv3 (Conv2D)         (None, 56, 56, 16)   1168        dropout_14[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_bn3 (BatchNormalizatio (None, 56, 56, 16)   64          decoder2_conv3[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_activation3 (PReLU)    (None, 56, 56, 16)   50176       decoder2_bn3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_15 (Dropout)            (None, 56, 56, 16)   0           decoder2_activation3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 56, 56, 16)   0           dropout_13[0][0]                 \n",
            "                                                                 dropout_15[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_4 (UpSampling2D)  (None, 112, 112, 16) 0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 112, 112, 144 0           up_sampling2d_4[0][0]            \n",
            "                                                                 block2_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_conv1 (Conv2D)         (None, 112, 112, 8)  10376       concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_bn1 (BatchNormalizatio (None, 112, 112, 8)  32          decoder1_conv1[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_activation1 (PReLU)    (None, 112, 112, 8)  100352      decoder1_bn1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_16 (Dropout)            (None, 112, 112, 8)  0           decoder1_activation1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_conv2 (Conv2D)         (None, 112, 112, 4)  292         dropout_16[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_bn2 (BatchNormalizatio (None, 112, 112, 4)  16          decoder1_conv2[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_activation2 (PReLU)    (None, 112, 112, 4)  50176       decoder1_bn2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_17 (Dropout)            (None, 112, 112, 4)  0           decoder1_activation2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_conv3 (Conv2D)         (None, 112, 112, 8)  296         dropout_17[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_bn3 (BatchNormalizatio (None, 112, 112, 8)  32          decoder1_conv3[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_activation3 (PReLU)    (None, 112, 112, 8)  100352      decoder1_bn3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_18 (Dropout)            (None, 112, 112, 8)  0           decoder1_activation3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 112, 112, 8)  0           dropout_16[0][0]                 \n",
            "                                                                 dropout_18[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_5 (UpSampling2D)  (None, 224, 224, 8)  0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 224, 224, 72) 0           up_sampling2d_5[0][0]            \n",
            "                                                                 block1_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_conv1 (Conv2D)   (None, 224, 224, 32) 20768       concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_bn1 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_activation1 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "dropout_19 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_conv2 (Conv2D)   (None, 224, 224, 16) 4624        dropout_19[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_bn2 (BatchNormal (None, 224, 224, 16) 64          decoder_output_conv2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_activation2 (PRe (None, 224, 224, 16) 802816      decoder_output_bn2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "dropout_20 (Dropout)            (None, 224, 224, 16) 0           decoder_output_activation2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_conv3 (Conv2D)   (None, 224, 224, 32) 4640        dropout_20[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_bn3 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_activation3 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "dropout_21 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation3[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 224, 224, 32) 0           dropout_19[0][0]                 \n",
            "                                                                 dropout_21[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "prediction (Conv2D)             (None, 224, 224, 1)  33          add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 224, 224, 1)  0           prediction[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 20,998,221\n",
            "Trainable params: 20,996,501\n",
            "Non-trainable params: 1,720\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 3196 samples, validate on 804 samples\n",
            "Epoch 1/50\n",
            "3196/3196 [==============================] - 73s 23ms/step - loss: 0.9789 - my_iou_metric: 0.1199 - val_loss: 0.9526 - val_my_iou_metric: 0.2012\n",
            "\n",
            "Epoch 00001: val_my_iou_metric improved from -inf to 0.20124, saving model to unet_vgg.h5\n",
            "Epoch 2/50\n",
            "3196/3196 [==============================] - 55s 17ms/step - loss: 0.8100 - my_iou_metric: 0.1694 - val_loss: 1.7713 - val_my_iou_metric: 0.1626\n",
            "\n",
            "Epoch 00002: val_my_iou_metric did not improve from 0.20124\n",
            "Epoch 3/50\n",
            "3196/3196 [==============================] - 55s 17ms/step - loss: 0.7322 - my_iou_metric: 0.2207 - val_loss: 0.9337 - val_my_iou_metric: 0.2316\n",
            "\n",
            "Epoch 00003: val_my_iou_metric improved from 0.20124 to 0.23159, saving model to unet_vgg.h5\n",
            "Epoch 4/50\n",
            "3196/3196 [==============================] - 55s 17ms/step - loss: 0.7062 - my_iou_metric: 0.2574 - val_loss: 0.8502 - val_my_iou_metric: 0.2463\n",
            "\n",
            "Epoch 00004: val_my_iou_metric improved from 0.23159 to 0.24627, saving model to unet_vgg.h5\n",
            "Epoch 5/50\n",
            "3196/3196 [==============================] - 55s 17ms/step - loss: 0.6607 - my_iou_metric: 0.2865 - val_loss: 0.8000 - val_my_iou_metric: 0.3338\n",
            "\n",
            "Epoch 00005: val_my_iou_metric improved from 0.24627 to 0.33383, saving model to unet_vgg.h5\n",
            "Epoch 6/50\n",
            "3196/3196 [==============================] - 55s 17ms/step - loss: 0.6373 - my_iou_metric: 0.3156 - val_loss: 0.6532 - val_my_iou_metric: 0.4272\n",
            "\n",
            "Epoch 00006: val_my_iou_metric improved from 0.33383 to 0.42724, saving model to unet_vgg.h5\n",
            "Epoch 7/50\n",
            "3196/3196 [==============================] - 55s 17ms/step - loss: 0.6288 - my_iou_metric: 0.3348 - val_loss: 0.8349 - val_my_iou_metric: 0.4718\n",
            "\n",
            "Epoch 00007: val_my_iou_metric improved from 0.42724 to 0.47177, saving model to unet_vgg.h5\n",
            "Epoch 8/50\n",
            "3196/3196 [==============================] - 55s 17ms/step - loss: 0.6121 - my_iou_metric: 0.3463 - val_loss: 0.6237 - val_my_iou_metric: 0.5624\n",
            "\n",
            "Epoch 00008: val_my_iou_metric improved from 0.47177 to 0.56244, saving model to unet_vgg.h5\n",
            "Epoch 9/50\n",
            "3196/3196 [==============================] - 55s 17ms/step - loss: 0.5807 - my_iou_metric: 0.3679 - val_loss: 0.5976 - val_my_iou_metric: 0.5255\n",
            "\n",
            "Epoch 00009: val_my_iou_metric did not improve from 0.56244\n",
            "Epoch 10/50\n",
            "3196/3196 [==============================] - 55s 17ms/step - loss: 0.5566 - my_iou_metric: 0.3908 - val_loss: 0.6258 - val_my_iou_metric: 0.3816\n",
            "\n",
            "Epoch 00010: val_my_iou_metric did not improve from 0.56244\n",
            "Epoch 11/50\n",
            "3196/3196 [==============================] - 55s 17ms/step - loss: 0.5446 - my_iou_metric: 0.4056 - val_loss: 0.6435 - val_my_iou_metric: 0.4479\n",
            "\n",
            "Epoch 00011: val_my_iou_metric did not improve from 0.56244\n",
            "Epoch 12/50\n",
            "3196/3196 [==============================] - 55s 17ms/step - loss: 0.5175 - my_iou_metric: 0.4310 - val_loss: 0.6057 - val_my_iou_metric: 0.5307\n",
            "\n",
            "Epoch 00012: val_my_iou_metric did not improve from 0.56244\n",
            "Epoch 13/50\n",
            "3196/3196 [==============================] - 55s 17ms/step - loss: 0.5005 - my_iou_metric: 0.4576 - val_loss: 0.7293 - val_my_iou_metric: 0.4828\n",
            "\n",
            "Epoch 00013: val_my_iou_metric did not improve from 0.56244\n",
            "\n",
            "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "Epoch 14/50\n",
            "3196/3196 [==============================] - 55s 17ms/step - loss: 0.4775 - my_iou_metric: 0.4706 - val_loss: 0.4989 - val_my_iou_metric: 0.5689\n",
            "\n",
            "Epoch 00014: val_my_iou_metric improved from 0.56244 to 0.56891, saving model to unet_vgg.h5\n",
            "Epoch 15/50\n",
            "3196/3196 [==============================] - 55s 17ms/step - loss: 0.4599 - my_iou_metric: 0.4877 - val_loss: 0.4990 - val_my_iou_metric: 0.6114\n",
            "\n",
            "Epoch 00015: val_my_iou_metric improved from 0.56891 to 0.61144, saving model to unet_vgg.h5\n",
            "Epoch 16/50\n",
            "3196/3196 [==============================] - 55s 17ms/step - loss: 0.4335 - my_iou_metric: 0.5096 - val_loss: 0.4633 - val_my_iou_metric: 0.5418\n",
            "\n",
            "Epoch 00016: val_my_iou_metric did not improve from 0.61144\n",
            "Epoch 17/50\n",
            "3196/3196 [==============================] - 55s 17ms/step - loss: 0.4328 - my_iou_metric: 0.5125 - val_loss: 0.5095 - val_my_iou_metric: 0.5338\n",
            "\n",
            "Epoch 00017: val_my_iou_metric did not improve from 0.61144\n",
            "Epoch 18/50\n",
            "3196/3196 [==============================] - 55s 17ms/step - loss: 0.4147 - my_iou_metric: 0.5244 - val_loss: 0.4225 - val_my_iou_metric: 0.6170\n",
            "\n",
            "Epoch 00018: val_my_iou_metric improved from 0.61144 to 0.61704, saving model to unet_vgg.h5\n",
            "Epoch 19/50\n",
            "3196/3196 [==============================] - 55s 17ms/step - loss: 0.4211 - my_iou_metric: 0.5245 - val_loss: 0.4468 - val_my_iou_metric: 0.6157\n",
            "\n",
            "Epoch 00019: val_my_iou_metric did not improve from 0.61704\n",
            "Epoch 20/50\n",
            "3196/3196 [==============================] - 55s 17ms/step - loss: 0.4049 - my_iou_metric: 0.5248 - val_loss: 0.4743 - val_my_iou_metric: 0.4815\n",
            "\n",
            "Epoch 00020: val_my_iou_metric did not improve from 0.61704\n",
            "Epoch 21/50\n",
            "3196/3196 [==============================] - 55s 17ms/step - loss: 0.3960 - my_iou_metric: 0.5392 - val_loss: 0.4098 - val_my_iou_metric: 0.6506\n",
            "\n",
            "Epoch 00021: val_my_iou_metric improved from 0.61704 to 0.65062, saving model to unet_vgg.h5\n",
            "Epoch 22/50\n",
            "3196/3196 [==============================] - 55s 17ms/step - loss: 0.3878 - my_iou_metric: 0.5469 - val_loss: 0.4002 - val_my_iou_metric: 0.5765\n",
            "\n",
            "Epoch 00022: val_my_iou_metric did not improve from 0.65062\n",
            "Epoch 23/50\n",
            "3196/3196 [==============================] - 55s 17ms/step - loss: 0.3921 - my_iou_metric: 0.5548 - val_loss: 0.4497 - val_my_iou_metric: 0.5245\n",
            "\n",
            "Epoch 00023: val_my_iou_metric did not improve from 0.65062\n",
            "Epoch 24/50\n",
            "3196/3196 [==============================] - 55s 17ms/step - loss: 0.3687 - my_iou_metric: 0.5631 - val_loss: 0.4011 - val_my_iou_metric: 0.6445\n",
            "\n",
            "Epoch 00024: val_my_iou_metric did not improve from 0.65062\n",
            "Epoch 25/50\n",
            "3196/3196 [==============================] - 55s 17ms/step - loss: 0.3530 - my_iou_metric: 0.5708 - val_loss: 0.3641 - val_my_iou_metric: 0.6470\n",
            "\n",
            "Epoch 00025: val_my_iou_metric did not improve from 0.65062\n",
            "Epoch 26/50\n",
            "3196/3196 [==============================] - 55s 17ms/step - loss: 0.3531 - my_iou_metric: 0.5819 - val_loss: 0.3837 - val_my_iou_metric: 0.6126\n",
            "\n",
            "Epoch 00026: val_my_iou_metric did not improve from 0.65062\n",
            "\n",
            "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "Epoch 27/50\n",
            "3196/3196 [==============================] - 55s 17ms/step - loss: 0.3221 - my_iou_metric: 0.5920 - val_loss: 0.3762 - val_my_iou_metric: 0.5832\n",
            "\n",
            "Epoch 00027: val_my_iou_metric did not improve from 0.65062\n",
            "Epoch 28/50\n",
            "3196/3196 [==============================] - 55s 17ms/step - loss: 0.3004 - my_iou_metric: 0.6004 - val_loss: 0.3456 - val_my_iou_metric: 0.5958\n",
            "\n",
            "Epoch 00028: val_my_iou_metric did not improve from 0.65062\n",
            "Epoch 29/50\n",
            "3196/3196 [==============================] - 55s 17ms/step - loss: 0.2941 - my_iou_metric: 0.6010 - val_loss: 0.3729 - val_my_iou_metric: 0.6305\n",
            "\n",
            "Epoch 00029: val_my_iou_metric did not improve from 0.65062\n",
            "Epoch 30/50\n",
            "3196/3196 [==============================] - 55s 17ms/step - loss: 0.2781 - my_iou_metric: 0.6016 - val_loss: 0.3472 - val_my_iou_metric: 0.6157\n",
            "\n",
            "Epoch 00030: val_my_iou_metric did not improve from 0.65062\n",
            "Epoch 31/50\n",
            "3196/3196 [==============================] - 55s 17ms/step - loss: 0.2708 - my_iou_metric: 0.6069 - val_loss: 0.3330 - val_my_iou_metric: 0.6568\n",
            "\n",
            "Epoch 00031: val_my_iou_metric improved from 0.65062 to 0.65684, saving model to unet_vgg.h5\n",
            "Epoch 32/50\n",
            "3196/3196 [==============================] - 55s 17ms/step - loss: 0.2733 - my_iou_metric: 0.6046 - val_loss: 0.3389 - val_my_iou_metric: 0.6749\n",
            "\n",
            "Epoch 00032: val_my_iou_metric improved from 0.65684 to 0.67488, saving model to unet_vgg.h5\n",
            "Epoch 33/50\n",
            "3196/3196 [==============================] - 55s 17ms/step - loss: 0.2540 - my_iou_metric: 0.6117 - val_loss: 0.3375 - val_my_iou_metric: 0.6052\n",
            "\n",
            "Epoch 00033: val_my_iou_metric did not improve from 0.67488\n",
            "Epoch 34/50\n",
            "3196/3196 [==============================] - 55s 17ms/step - loss: 0.2286 - my_iou_metric: 0.6262 - val_loss: 0.3426 - val_my_iou_metric: 0.6580\n",
            "\n",
            "Epoch 00034: val_my_iou_metric did not improve from 0.67488\n",
            "Epoch 35/50\n",
            "3196/3196 [==============================] - 55s 17ms/step - loss: 0.2203 - my_iou_metric: 0.6327 - val_loss: 0.3753 - val_my_iou_metric: 0.5947\n",
            "\n",
            "Epoch 00035: val_my_iou_metric did not improve from 0.67488\n",
            "Epoch 36/50\n",
            "3196/3196 [==============================] - 55s 17ms/step - loss: 0.2115 - my_iou_metric: 0.6288 - val_loss: 0.3683 - val_my_iou_metric: 0.5985\n",
            "\n",
            "Epoch 00036: val_my_iou_metric did not improve from 0.67488\n",
            "Epoch 37/50\n",
            "3196/3196 [==============================] - 55s 17ms/step - loss: 0.2008 - my_iou_metric: 0.6344 - val_loss: 0.3634 - val_my_iou_metric: 0.6331\n",
            "\n",
            "Epoch 00037: val_my_iou_metric did not improve from 0.67488\n",
            "\n",
            "Epoch 00037: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "Epoch 38/50\n",
            "3196/3196 [==============================] - 55s 17ms/step - loss: 0.1637 - my_iou_metric: 0.6536 - val_loss: 0.3700 - val_my_iou_metric: 0.6050\n",
            "\n",
            "Epoch 00038: val_my_iou_metric did not improve from 0.67488\n",
            "Epoch 39/50\n",
            "3196/3196 [==============================] - 55s 17ms/step - loss: 0.1495 - my_iou_metric: 0.6643 - val_loss: 0.3656 - val_my_iou_metric: 0.6465\n",
            "\n",
            "Epoch 00039: val_my_iou_metric did not improve from 0.67488\n",
            "Epoch 40/50\n",
            "3196/3196 [==============================] - 55s 17ms/step - loss: 0.1403 - my_iou_metric: 0.6662 - val_loss: 0.3761 - val_my_iou_metric: 0.6204\n",
            "\n",
            "Epoch 00040: val_my_iou_metric did not improve from 0.67488\n",
            "Epoch 41/50\n",
            "3196/3196 [==============================] - 55s 17ms/step - loss: 0.1302 - my_iou_metric: 0.6829 - val_loss: 0.3757 - val_my_iou_metric: 0.6209\n",
            "\n",
            "Epoch 00041: val_my_iou_metric did not improve from 0.67488\n",
            "Epoch 42/50\n",
            "3196/3196 [==============================] - 55s 17ms/step - loss: 0.1223 - my_iou_metric: 0.6958 - val_loss: 0.3818 - val_my_iou_metric: 0.6405\n",
            "\n",
            "Epoch 00042: val_my_iou_metric did not improve from 0.67488\n",
            "\n",
            "Epoch 00042: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
            "Epoch 43/50\n",
            "3196/3196 [==============================] - 55s 17ms/step - loss: 0.1134 - my_iou_metric: 0.6989 - val_loss: 0.3836 - val_my_iou_metric: 0.6322\n",
            "\n",
            "Epoch 00043: val_my_iou_metric did not improve from 0.67488\n",
            "Epoch 44/50\n",
            "3196/3196 [==============================] - 55s 17ms/step - loss: 0.1115 - my_iou_metric: 0.6972 - val_loss: 0.3831 - val_my_iou_metric: 0.6347\n",
            "\n",
            "Epoch 00044: val_my_iou_metric did not improve from 0.67488\n",
            "Epoch 45/50\n",
            "3196/3196 [==============================] - 55s 17ms/step - loss: 0.1119 - my_iou_metric: 0.7017 - val_loss: 0.3963 - val_my_iou_metric: 0.6424\n",
            "\n",
            "Epoch 00045: val_my_iou_metric did not improve from 0.67488\n",
            "Epoch 46/50\n",
            "3196/3196 [==============================] - 55s 17ms/step - loss: 0.1021 - my_iou_metric: 0.7134 - val_loss: 0.3921 - val_my_iou_metric: 0.6335\n",
            "\n",
            "Epoch 00046: val_my_iou_metric did not improve from 0.67488\n",
            "Epoch 47/50\n",
            "3196/3196 [==============================] - 55s 17ms/step - loss: 0.0993 - my_iou_metric: 0.7085 - val_loss: 0.4021 - val_my_iou_metric: 0.6560\n",
            "\n",
            "Epoch 00047: val_my_iou_metric did not improve from 0.67488\n",
            "Epoch 48/50\n",
            "3196/3196 [==============================] - 55s 17ms/step - loss: 0.1069 - my_iou_metric: 0.7137 - val_loss: 0.3883 - val_my_iou_metric: 0.6352\n",
            "\n",
            "Epoch 00048: val_my_iou_metric did not improve from 0.67488\n",
            "Epoch 49/50\n",
            "3196/3196 [==============================] - 55s 17ms/step - loss: 0.0957 - my_iou_metric: 0.7193 - val_loss: 0.4129 - val_my_iou_metric: 0.6300\n",
            "\n",
            "Epoch 00049: val_my_iou_metric did not improve from 0.67488\n",
            "Epoch 50/50\n",
            "3196/3196 [==============================] - 55s 17ms/step - loss: 0.1005 - my_iou_metric: 0.7218 - val_loss: 0.4072 - val_my_iou_metric: 0.6337\n",
            "\n",
            "Epoch 00050: val_my_iou_metric did not improve from 0.67488\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t94SPRsC8U1u",
        "colab_type": "text"
      },
      "source": [
        "### Validation set prediction and resizing to original size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUbsqNrr8sGs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_preds = model_depth.predict(X_val, batch_size=16)\n",
        "\n",
        "y_val_pred = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), val_preds)))\n",
        "y_val_true = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), y_val)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3RUR3avJ83om",
        "colab_type": "text"
      },
      "source": [
        "### Threshold optimization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfDJBU2F80B9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# src: https://www.kaggle.com/aglotero/another-iou-metric\n",
        "def iou_metric(y_true_in, y_pred_in, print_table=False):\n",
        "    labels = y_true_in\n",
        "    y_pred = y_pred_in\n",
        "    \n",
        "    true_objects = 2\n",
        "    pred_objects = 2\n",
        "\n",
        "    intersection = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=(true_objects, pred_objects))[0]\n",
        "\n",
        "    # Compute areas (needed for finding the union between all objects)\n",
        "    area_true = np.histogram(labels, bins = true_objects)[0]\n",
        "    area_pred = np.histogram(y_pred, bins = pred_objects)[0]\n",
        "    area_true = np.expand_dims(area_true, -1)\n",
        "    area_pred = np.expand_dims(area_pred, 0)\n",
        "\n",
        "    # Compute union\n",
        "    union = area_true + area_pred - intersection\n",
        "\n",
        "    # Exclude background from the analysis\n",
        "    intersection = intersection[1:,1:]\n",
        "    union = union[1:,1:]\n",
        "    union[union == 0] = 1e-9\n",
        "\n",
        "    # Compute the intersection over union\n",
        "    iou = intersection / union\n",
        "\n",
        "    # Precision helper function\n",
        "    def precision_at(threshold, iou):\n",
        "        matches = iou > threshold\n",
        "        true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n",
        "        false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n",
        "        false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n",
        "        tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n",
        "        return tp, fp, fn\n",
        "\n",
        "    # Loop over IoU thresholds\n",
        "    prec = []\n",
        "    if print_table:\n",
        "        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n",
        "    for t in np.arange(0.5, 1.0, 0.05):\n",
        "        tp, fp, fn = precision_at(t, iou)\n",
        "        if (tp + fp + fn) > 0:\n",
        "            p = tp / (tp + fp + fn)\n",
        "        else:\n",
        "            p = 0\n",
        "        if print_table:\n",
        "            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tp, fp, fn, p))\n",
        "        prec.append(p)\n",
        "    \n",
        "    if print_table:\n",
        "        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n",
        "    return np.mean(prec)\n",
        "\n",
        "def iou_metric_batch(y_true_in, y_pred_in):\n",
        "    batch_size = y_true_in.shape[0]\n",
        "    metric = []\n",
        "    for batch in range(batch_size):\n",
        "        value = iou_metric(y_true_in[batch], y_pred_in[batch])\n",
        "        metric.append(value)\n",
        "    return np.mean(metric)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8PDw4DkD84B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c0bcf1b4-49aa-421e-8a27-b54986dbdea0"
      },
      "source": [
        "# Threshold range, over which optimization is performed\n",
        "thresholds = np.arange(0.2, 0.9, 0.02)\n",
        "\n",
        "# For every threshold, set predictions to binary arrays, \n",
        "# where values above threshold are treated as 1 and the rest as 0.\n",
        "# Loop over thresholds and compute IoU for them based on IoU function above.\n",
        "ious = np.array(\n",
        "    [iou_metric_batch(y_val_true,\n",
        "                      np.int32(y_val_pred > threshold)) for threshold in tqdm(thresholds)])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 35/35 [00:36<00:00,  1.03s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "weKGfnozEHjO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "outputId": "30c12974-4c71-4527-8bab-b8cf598e5ebd"
      },
      "source": [
        "df_iou = pd.DataFrame(thresholds, columns=['threshold'])\n",
        "df_iou['iou'] = ious\n",
        "\n",
        "# Get index of best IoU\n",
        "best_index = df_iou['iou'].idxmax()\n",
        "print('Best IoU: {:.4f} at threshold: {:.3f}'.format(\n",
        "    df_iou.iou[best_index], df_iou.threshold[best_index]))\n",
        "\n",
        "# Describe IoU DF\n",
        "df_iou.describe()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best IoU: 0.6679 at threshold: 0.860\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>threshold</th>\n",
              "      <th>iou</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>35.000000</td>\n",
              "      <td>35.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.540000</td>\n",
              "      <td>0.644350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.204939</td>\n",
              "      <td>0.018035</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.608831</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.370000</td>\n",
              "      <td>0.633396</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.540000</td>\n",
              "      <td>0.646891</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.710000</td>\n",
              "      <td>0.659266</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>0.880000</td>\n",
              "      <td>0.667910</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       threshold        iou\n",
              "count  35.000000  35.000000\n",
              "mean    0.540000   0.644350\n",
              "std     0.204939   0.018035\n",
              "min     0.200000   0.608831\n",
              "25%     0.370000   0.633396\n",
              "50%     0.540000   0.646891\n",
              "75%     0.710000   0.659266\n",
              "max     0.880000   0.667910"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cs9uBkFQEPMA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 588
        },
        "outputId": "cf8ab58b-5037-47bb-fd72-5dc93c983af3"
      },
      "source": [
        "# Plot IoU values over threshold range.\n",
        "df_iou.plot(x='threshold', y='iou')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f0e5db84128>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAAIWCAYAAAClXRAXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nOzdeXiU5d328fPKHsgG2YAkkAAJEHYI\nIKACdaO4L3VX3LXq81h9a61La2trW2tbq09t6waKiktdsaKoKKKAQEDWQEJIAgRCEsKSkD0z1/tH\nIo2UJcAk98zk+zkODpx77pk5J43J2cvfXLex1goAAADAfwQ4HQAAAADwNpRkAAAA4CCUZAAAAOAg\nlGQAAADgIJRkAAAA4CCUZAAAAOAgQU4HOFhcXJxNTU11OgYAAAD83IoVK3ZZa+MPdZ/XleTU1FRl\nZ2c7HQMAAAB+zhiz5XD3MW4BAAAAHKRNJdkYM9UYk2uMyTfG/Pww51xqjMkxxqw3xsxuOTbFGLOq\n1Z86Y8wFnnwDAAAAgKcdddzCGBMo6WlJZ0gqlrTcGDPHWpvT6px0SfdLmmit3WOMSZAka+0Xkka0\nnNNdUr6kTzz+LgAAAAAPastM8lhJ+dbaAkkyxrwu6XxJOa3OuVnS09baPZJkrS07xPNcIukja23N\nsYZsbGxUcXGx6urqjvWhXicsLEzJyckKDg52OgoAAAAOoy0lOUnStla3iyWNO+icDEkyxiySFCjp\nV9bajw8653JJfznUCxhjbpF0iyT17t37v+4vLi5WZGSkUlNTZYxpQ2TvZK1VRUWFiouLlZaW5nQc\nAAAAHIanPrgXJCld0mRJV0h6zhgT892dxpiekoZKmneoB1trn7XWZllrs+Lj/3sXjrq6OsXGxvp0\nQZYkY4xiY2P9YkUcAADAn7WlJG+XlNLqdnLLsdaKJc2x1jZaawsl5am5NH/nUknvWmsbjzeorxfk\n7/jL+wAAAPBnbSnJyyWlG2PSjDEhah6bmHPQOe+peRVZxpg4NY9fFLS6/wpJr51wWgdNmDDB6QgA\nAADoIEctydbaJkl3qnlUYoOkN621640xjxhjzms5bZ6kCmNMjqQvJN1rra2QJGNMqppXor/0fPyO\ns3jxYqcjAAAAoIO0aSbZWjvXWpthre1nrX205dgvrbVzWv7ZWmvvsdZmWmuHWmtfb/XYImttkrXW\n3T5voWNERERIav7w3b333qshQ4Zo6NCheuONNyRJCxYs0DnnnHPg/DvvvFMvvviiE1EBAABwgrzu\nstRH8+sP1itnR6VHnzOzV5QePndwm8595513tGrVKq1evVq7du3SmDFjdOqpp3o0DwAAAJzFZamP\n0ddff60rrrhCgYGBSkxM1KRJk7R8+XKnYwEAAMCDfG4lua0rvh0tKChIbvd/JkrY5g0AAMB3sZJ8\njE455RS98cYbcrlcKi8v18KFCzV27Fj16dNHOTk5qq+v1969ezV//nynowIAAOA4+dxKstMuvPBC\nLVmyRMOHD5cxRn/84x/Vo0cPSdKll16qIUOGKC0tTSNHjnQ4KQAAAI6XsdY6neF7srKybHZ29veO\nbdiwQYMGDXIokef52/sBAADwRcaYFdbarEPdx7gFAAAAcBBKMgAAAHAQSjIAAABwEJ8pyd42O328\n/OV9AAAAdJTd1Q365fvrdMZfvtTLS4rU5Gr/Czn7REkOCwtTRUWFzxdMa60qKioUFhbmdBQAAACv\n19Dk1gtfF2ry41/o1aVbFRhg9Iv312vaU19pYV55u762T2wBl5ycrOLiYpWXt+8XoyOEhYUpOTnZ\n6RgAAABey1qrzzeW6dEPN6hgV7VOzYjXL84epP4JEfokp1S/m7tB185YptMGJuiBswepX3yExzP4\nxBZwAAAA6Bxyd1bptx/m6KtNu9QvvqseOidTUwYkfO+c+iaXXlpcpP+bn6/aRpeuHZ+qu05LV3SX\n4GN6rSNtAUdJBgAAgOMq9tfric/yNHvpVkWGBesnp6fr6pP6KDjw8NPBu/bX6y+f5un1ZVsVFR6s\ne87I0JVjeyvoCI9pjZIMAAAAr9TQ5NasJUV6cv4m1TS4dM1JffST09MV0yWkzc+xoaRSj3yQoyUF\nFUpPiNBD52RqUkb8UR9HSQYAAIBXsdbqsw1levTDHBVV1GjygHg9dPYg9U+IPO7n+zSnVI/O3aAt\nFTWaMiBeD56dqf4Jh59XpiQDAADAa2woqdRvP8zRovwK9U+I0INnD/qvuePjVd/k0qzFW/TU/E2q\naTzyyjQlGQAAAI47eIb47tMzdOW43kecOz6R13ri0zy9tqx5xvnu09N11UEzzpRkAAAAOObg3Siu\nGd9Hd512bHPHx2vjzkr95t/Nq9YH75ZBSQYAAECHs9Ye2Nd4S0WNfjAwQQ9MG3TEOeH2yjF/Q5ke\nnbtBhbuqNSmjef45o0fUYUuyT1xMBAAAAL7DWqtvCnbryfl5+qZgt9ITIvTSDWPbtONEezDG6PTM\nRJ2aEX9gJ42pT351xMdQkgEAAOAR310p7+kv8rVy617FRYTqkfMHH9Pexe0pJChAN53SVxeOTNIT\nn+Xp0SOcy7gFAAAATkiTy60P15boHws2a+POKiXFhOu2SX31o6wUhQUHOh3vsI40k8xKMgAAAI5L\nfZNL76zcrn9+uVlbKmrUPyFCf7l0uM4d3qtddqzoSJRkAAAAHJPq+ia9tmyrnvuqQKWV9RqWHK1/\nXj1aZ2YmKiDAOB3PIyjJAAAAaJO9NQ16afEWzVxcqL01jRrfN1Z//tEITewfK2P8oxx/h5IMAACA\nIyqrrNPzXxfq1W+2qLrBpdMHJer2Kf00qnc3p6O1G0oyAAAADmlrRY2eWbhZ/1pRrCaXW+cO76Uf\nT+6ngT2inI7W7ijJAAAA+J680ir9Y8FmzVm9Q4HG6JKsZN16al/1ie3qdLQOQ0kGAACAGl1uLS/c\nrZmLi/RpTqm6hATqxpPTdOPJaUqMCnM6XoejJAMAAHRSJftqtSC3XAtyy7Qov0L765sUHR6sn5ye\nrunjU9Wta4jTER1DSQYAAOgkGprcyt6yW1/mlmtBbrlyS6skSUkx4TpvRC9NzojXyelx6hJCReQr\nAAAA4Md27G29WrxL1Q0uBQcajU3rrktGD9LkAfHqnxDhd1u4nShKMgAAgB9paHIru2i3FuQ1F+O8\n0v2SmleLLxiZpMkDEjShX6y6hlIDj4SvDgAAgI/bvrdWC3LLtCC3XItbVotDAgM0Nq27Ls1K0eQB\n8eoXz2rxsaAkAwAA+Jj6Jpeyi/YcKMabylgt9jS+cgAAAD6geE9Ny2xxuRZv3qWaVqvFl41htdjT\nKMkAAABeqL7JpeWFLavFeeXKb1ktTu4WrotGJWlyRoLGs1rcbviqAgAAeIltu2u0IK9cX+aWafHm\nigOrxeP6dtflY1I0eUCC+sV3ZbW4A1CSAQAAHFLf5NKywt0HtmjbXF4t6T+rxVMGNK8Ws29xx+Mr\nDgAA0IG2763V5xvLDrlafMXY3qwWewlKMgAAQAeZs3qH7n5jlVxuq5Tu4bp4VLImD4hntdgL8b8G\nAABAB/hk/U7d/cYqje7TTb+/aKj6xrFa7M0oyQAAAO1sYV657pz9rYYmRWvGdWMUwY4UXi/A6QAA\nAAD+bGlBhW55OVv9EiL00vVjKcg+gpIMAADQTlZt26sbXlyupJhwvXzjWEV3CXY6EtqIkgwAANAO\ncnZU6toXlio2IlSv3nSS4iJCnY6EY0BJBgAA8LD8sv265oWliggN0qs3jVOP6DCnI+EYUZIBAAA8\naGtFja56/hsZY/TKTeOU0r2L05FwHCjJAAAAHrJjb62ufP4b1Te59epN49Q3PsLpSDhOlGQAAAAP\nKK+q19XPL9W+mka9fMM4DegR6XQknAD2IAEAADhBe6obdPXzS1Wyr04v3zhWQ5OjnY6EE0RJBgAA\nOAGVdY26dsYyFVZUa+Z1Y5SV2t3pSPAAxi0AAACOU01Dk26YuVwbSir1z6tHaWL/OKcjwUMoyQAA\nAMehrtGlW2at0Mqte/Tk5SP1g4GJTkeCB1GSAQCAX3G5rarqGtv1NRqa3Lrj1ZX6On+XHr9kuM4e\n1rNdXw8dj5lkAADgF9xuqw/W7NBfPs3TlooaDUuO1uSMeE0akKARKTEKDDAeeZ0ml1t3v7FK8zeW\n6bcXDNHFo5M98rzwLpRkAADg06y1+mxDmf78Sa427qzSwB6RunNKfy0pqNDfvsjXU5/nK6ZLsE5J\nj9fkjHidmhGv+Mjju0S0221139tr9eHaEj109iBdfVIfD78beAtKMgAA8FmL83fpj/NytWrbXqXF\nddVTV4zUOUN7KqBl1XhvTYO+2rRLC3LL9WVeuT5YvUOSNDQpWpMHxGvygHiNSOnWplVma61+OWed\n3l5ZrHvOyNBNp/Rt1/cGZxlrrdMZvicrK8tmZ2c7HQMAAHixb7fu0Z8+ydWi/Ar1jA7TXael65LR\nyQoKPPzHrdxuq5ySSi3ILdOC3HKt3LpHbitFhwfrlPQ4TR6QoEmHWWW21ur3H23UswsLdOukvvr5\n1IEyxjPjG3COMWaFtTbrkPdRkgEAgK/YuLNSf5qXp882lCq2a4jumNJfV47rrbDgwGN+rn01jfoq\nv/zAKnN5Vb0kaUhSlCZnJLSsMscoKDBAT3yapyfnb9L08X30q/MGU5D9BCUZAAD4tKJd1XriszzN\nWb1DEaFBuvXUvrp+Ypq6hnpmcvS7VeYv88q1ILdMK7fulcttFRUWpCFJ0Vq8uUI/Gp2sxy4edmCU\nA76PkgwAAHxSyb5aPTU/X29mb1NwoNH1E9N066l9FdMlpF1fd19to77etEsLcsv01aZdmtA/Vo9f\nMtxjO2TAOxypJPPBPQAA4HUq9tfrHws2a9Y3W2St1dXjeuuOKf2VEBXWIa8fHR6ss4f1ZP/jToyS\nDAAAvEZlXaOeX1igF74uVG2jSxeNStZdp6UrpXsXp6Ohk6EkAwAAx9U2uPTSkiL9Y8Fm7att1LSh\nPXTPGRnqnxDpdDR0Um0qycaYqZKelBQo6Xlr7R8Occ6lkn4lyUpaba29suV4b0nPS0ppuW+atbbI\nE+EBAIDvW5S/S3e/sUplVfWaPCBePz1zgIYkRTsdC53cUUuyMSZQ0tOSzpBULGm5MWaOtTan1Tnp\nku6XNNFau8cYk9DqKWZJetRa+6kxJkKS26PvAAAA+CRrrWYsKtLv5m5Q37iu+tuVozQ2rbvTsQBJ\nbVtJHisp31pbIEnGmNclnS8pp9U5N0t62lq7R5KstWUt52ZKCrLWftpyfL8HswMAAB9V1+jSA++u\n1Tsrt+uswYn686UjFOGh7dwATzj8ZWn+I0nStla3i1uOtZYhKcMYs8gY803LeMZ3x/caY94xxnxr\njHm8ZWX6e4wxtxhjso0x2eXl5cfzPgAAgI8o2Very55ZondWbtfdp2foH1eNpiDD63jqOzJIUrqk\nyZKSJS00xgxtOX6KpJGStkp6Q9J1kl5o/WBr7bOSnpWa90n2UCYAAOBlsot267ZXVqq2oUnPXjNa\nZw7u4XQk4JDaspK8Xc0fuvtOcsux1oolzbHWNlprCyXlqbk0F0taZa0tsNY2SXpP0qgTjw0AAHzN\n7KVbdcVz3ygiNFDv3TGRggyv1paSvFxSujEmzRgTIulySXMOOuc9Na8iyxgTp+Yxi4KWx8YYY+Jb\nzvuBvj/LDAAA/FxDk1sPvrtWD7y7VhP6xen9O05WeiJbu8G7HXXcwlrbZIy5U9I8NW8BN8Nau94Y\n84ikbGvtnJb7zjTG5EhySbrXWlshScaYn0qab4wxklZIeq6d3gsAAPAy5VX1uuPVlVpWtFu3Tuqr\nn501kEs7wycYa71rBDgrK8tmZ2c7HQMAAJygtcX7dMvL2dpT06DHLh6m80cc/Ll/wFnGmBXW2qxD\n3cdHSQEAgMe99+123ff2GsVFhOqt2yZwcRD4HEoyAADwmCaXW499vFHPfVWocWnd9ferRik2ItTp\nWMAxoyQDAACP2FvToP957Vt9tWmXpo/vo4fOyVRwYFv2CAC8DyUZAACcsNydVbp5VrZ27qvTYxcP\n1WVjejsdCTghlGQAAHBCPl5XonveXK2I0CC9dstJGt2nm9ORgBNGSQYAAMfF7bb66/xNemr+Jo1I\nidEz14xWYlSY07EAj6AkAwCAY1ZV16i731itzzaU6kejk/WbC4YoLDjQ6ViAx1CSAQDAUVlrtbm8\nWtlFu7WsaLe+3rRLFdUN+tW5mZo+IVXN1wwD/AclGQAA/Jcml1s5JZVaVrhby4t2K7tojyqqGyRJ\nsV1DNCa1u66fmKpxfWMdTgq0D0oyAABQbYNL327bo+WFe7S8aLdWbt2jmgaXJKl39y6aPCBBY1K7\naUxad/WN68rKMfweJRkAgE5ob02Dlhc1F+LlRbu1bvs+NbqsjJEGJEbqktHJGpPaXWNSu6tHNB/G\nQ+dDSQYAwI+53Fa7qxtUXlWvTWVVB8Yn8kr3S5JCAgM0LDlaN53SV2NTu2tUn26KDg92ODXgPEoy\nAAA+qKahSeVV9Sqrqld5y5+yqrpW/9z8d0V1g1xue+BxEaFBGtWnm84b3ktjUrtreEoMu1IAh0BJ\nBgDAi1hrVVZVr8Jd1dq2u+Z7Jbi8ql7l++tVVlmn6pZ54dYCA4ziIkIUHxmqhMhQDekVrfjI0AO3\nU7p30aCeUQoMYJ4YOBpKMgAAHax1Ed5SUa3CXTUtf1drS0WNahu/X4AjQ4MOlN3BvaI0eUC8EiLD\nvleA4yND1a1LCAUY8BBKMgAA7cBaq9LKehVVVKtoV7WKKmpa/v7vIhwcaJTSvYtSY7tqQr84pcY1\n/3Pv7l2UGBWm8BDGIYCORkkGAOAEWWu1fkelPskpVd7OqiMW4bSWIpwW10V9YrsqLa6rekaHKSgw\nwMF3AOBglGQAAI7Dd8X4w7Ulmru2RFsqahQYYNQn9tBFuFdMOKMQgA+hJAMA0EaHK8YT+sXqx5P6\n6czBPdS9a4jTMQF4ACUZAIAj+K4Y/3tNczHeuptiDHQGlGQAAA5irdW67f9ZMW5djG+fTDEGOgNK\nMgAAOnwxntg/TndM6aczM3uoG8UY6DQoyQCATuu7YvzvtTv00dqd2rq7RkEBRhMoxkCnR0kGAHRK\nVXWNuvXlFVq8ueJAMb5zSn+dkZlIMQZASQYAdD57axo0fcYyrdtRqYfOHqRLRicrpgvFGMB/UJIB\nAJ1KeVW9rnlhqQrKq/XPq0frjMxEpyMB8EKUZABAp7Fjb62ufn6pSvbVacZ1Y3RyepzTkQB4KUoy\nAKBTKNpVraueX6rK2ka9fONYZaV2dzoSAC9GSQYA+L1NpVW66vmlanS5NfvmkzQ0OdrpSAC8HCUZ\nAODX1m3fp2teWKqgwAC9cet4ZSRGOh0JgA+gJAMA/NaKLbt13YzligoP1qs3jVNqXFenIwHwEZRk\nAIBfWpS/Sze9lK0e0WF69aZx6hUT7nQkAD6EkgwA8Duf5ZTq9tkrlRbbVS/fNFYJkWFORwLgYyjJ\nAAC/8sHqHbr7jVUa3CtKL90wlouEADgulGQAgN94c/k23ffOGo1J7a4XpmcpMizY6UgAfBQlGQDg\nF2YuKtSvP8jRqRnxeubq0QoPCXQ6EgAfRkkGAPi8p7/I1+PzcnXW4EQ9dcVIhQZRkAGcGEoyAMBn\nWWv1x3m5+seCzbpwZJIev2SYggIDnI4FwA9QkgEAPsnttvr1B+v10pItunJcb/32/CEKCDBOxwLg\nJyjJAACf43Jb3ff2Gr21olg3n5KmB6YNkjEUZACeQ0kGAPiUhia37n5zlT5cU6KfnJ6uu05LpyAD\n8DhKMgDAZ9Q1unTHqys1f2OZHpw2SDef2tfpSAD8FCUZAOAz/vDRRn2eW6ZHLxyiq8b1cToOAD/G\nR4ABAD5hbfE+zVpSpGtO6kNBBtDuKMkAAK/ncls9+N5axUaE6qdnDXA6DoBOgJIMAPB6r3yzRWuK\n9+mX52QqiktNA+gAlGQAgFcrrazT4/NydUp6nM4Z1tPpOAA6CUoyAMCrPfLvHDW43PrN+UPY6g1A\nh6EkAwC81oLcMn24pkT/M6W/UuO6Oh0HQCdCSQYAeKW6Rpd++f569Y3vqlsmsR8ygI7FPskAAK/0\nt8/ztXV3jWbfPE6hQYFOxwHQybCSDADwOvllVXpm4WZdNCpJE/rFOR0HQCdESQYAeBVrrR58d526\nhATpgWmDnI4DoJOiJAMAvMrbK7draeFu/fyHAxUXEep0HACdFCUZAOA19lQ36HdzN2h0n266LCvF\n6TgAOjFKMgDAazz28Ubtq23UoxcOUUAAeyIDcA4lGQDgFZYX7dbry7fpppPTNLBHlNNxAHRylGQA\ngOMaXW49+O5aJcWE667T052OAwDskwwAcN4LXxcqr3S/nr82S11C+NUEwHmsJAMAHLVtd43++lme\nzsxM1OmZiU7HAQBJlGQAgIOstXp4znoFGKNfnTfY6TgAcAAlGQDgmHnrd+rzjWW654wM9YoJdzoO\nABxASQYAOGJ/fZN+NSdHg3pG6boJqU7HAYDvoSQDABzxxKd5Kq2q0+8uHKKgQH4dAfAu/FQCAHS4\nddv3aeaiQl05trdG9u7mdBwA+C+UZABAh3K5rR58d626dw3Rz84a6HQcADikNpVkY8xUY0yuMSbf\nGPPzw5xzqTEmxxiz3hgzu9VxlzFmVcufOZ4KDgDwTbOXbdXq4n36xTmZiu4S7HQcADiko+7YbowJ\nlPS0pDMkFUtaboyZY63NaXVOuqT7JU201u4xxiS0eopaa+0ID+cGAPigsqo6/fHjjZrYP1bnDe/l\ndBwAOKy2rCSPlZRvrS2w1jZIel3S+Qedc7Okp621eyTJWlvm2ZgAAH/w239vUH2jW785f4iMMU7H\nAYDDaktJTpK0rdXt4pZjrWVIyjDGLDLGfGOMmdrqvjBjTHbL8QtOMC8AwEd9talcc1bv0O1T+qlv\nfITTcQDgiI46bnEMz5MuabKkZEkLjTFDrbV7JfWx1m43xvSV9LkxZq21dnPrBxtjbpF0iyT17t3b\nQ5EAAN6irtGlX7y3TmlxXXXbpH5OxwGAo2rLSvJ2SSmtbie3HGutWNIca22jtbZQUp6aS7Ostdtb\n/i6QtEDSyINfwFr7rLU2y1qbFR8ff8xvAgDg3f6+YLOKKmr02wuGKCw40Ok4AHBUbSnJyyWlG2PS\njDEhki6XdPAuFe+peRVZxpg4NY9fFBhjuhljQlsdnygpRwCATmNz+X79c8FmXTCilyb2j3M6DgC0\nyVHHLay1TcaYOyXNkxQoaYa1dr0x5hFJ2dbaOS33nWmMyZHkknSvtbbCGDNB0jPGGLeaC/kfWu+K\nAQDwb7UNLj347lqFBQfowbMznY4DAG1mrLVOZ/ierKwsm52d7XQMAMAJaGhy6/XlW/V/n+ervKpe\nj108VJeN4TMnALyLMWaFtTbrUPd56oN7AADI5bZ699vt+utneSreU6uxad31j6tGKSu1u9PRAOCY\nUJIBACfMWquP1+3Unz/NU37Zfg1NitbvLhyqU9Lj2A8ZgE+iJAMAjpu1Vl/mlevPn+Rp7fZ96p8Q\noX9ePUpnDe5BOQbg0yjJAIDjsrxotx7/OFfLinYruVu4/vyj4bpgZJICAyjHAHwfJRkAcEzWbd+n\nP32SqwW55UqIDNVvzh+sy8b0VkhQW3YVBQDfQEkGALRJftl+PfFpnj5cW6KYLsG6/4cDde34VIWH\ncHEQAP6HkgwAOKJtu2v05PxNemdlscKDA/W/p6XrplPSFBUW7HQ0AGg3lGQAwCGVVdXp6c/zNXvZ\nVhljdMPENP14cj/FRoQ6HQ0A2h0lGQDwPXtrGvTMwgLNXFSoRpfVpVkp+t/T+qtndLjT0QCgw1CS\nAQCSpE2lVXpxcZHeWblddU0unTe8l+4+PUOpcV2djgYAHY6SDACdmMtt9fnGMr24uFCL8isUEhSg\n84b30k2npGlgjyin4wGAYyjJANAJ7atp1JvZ2zTrmyJt212rntFhuvesAbp8TAozxwAgSjIAdCp5\nLSMV767crtpGl8amdtf9PxykMzMTFRTIPscA8B1KMgD4OZfbav6GUr24uEiLN1coNChA54/opekT\nUjW4V7TT8QDAK1GSAcBP7atp1BvZWzVryRYV72keqfjZ1AG6fExvde8a4nQ8APBqlGQA8DO5O1tG\nKr4tVl2jW2PTuuvBaYN0BiMVANBmlGQA8AMut9VnG0r14qIiLSloHqm4YESSpk9IVWYvdqkAgGNF\nSQYAH/dZTqkenrNe2/fWKikmXPdNHajLx6SoGyMVAHDcKMkA4MNmL92qh95bqwE9ovSLcwbp9EGM\nVACAJ1CSAcAHWWv11Px8PfFZniYPiNffrxqlLiH8SAcAT+EnKgD4GJfb6uE56/TKN1t18ahk/eHi\noQpm9RgAPIqSDAA+pK7RpZ+8vkofr9+p2yb1031TB8gY43QsAPA7lGQA8BH7aht1y6xsLS3crV+c\nk6kbT05zOhIA+C1KMgD4gNLKOk2fsUyby/fryctH6PwRSU5HAgC/RkkGAC+3uXy/rn1hmfbWNGjG\ndWN0Snq805EAwO9RkgHAi327dY9ueHG5AozR67eM19DkaKcjAUCnQEkGAC/1RW6Zbn9lpeIjQzXr\nhrFKjevqdCQA6DQoyQDghd5eUaz73l6jjMRIvXjDGCVEhjkdCQA6FUoyAHgRa62eXVig33+0URP6\nxeqZa0YrMizY6VgA0OlQkgHAS7jdVo/O3aAXvi7U2cN66i+XDldoUKDTsQCgU6IkA4AXaGhy6963\nVuv9VTt03YRU/fKcTAUEcJEQAHAKJRkAHLa/vkk/fmWFvtq0S/eeNUC3T+7HVfQAwGGUZABw0K79\n9bp+5nLllFTqj5cM06VZKU5HAgCIkgwAjtlaUaNrZyzVzso6PXvNaJ02KNHpSACAFpRkAHDAuu37\ndN3M5Wpyu/XqTSdpdJ9uTkcCALRCSQaADra0oEI3vpStqLAgvX7LePVPiHQ6EgDgIJRkAOhAX+aV\n69aXs5UUE65XbhqnntHhTkcCABwCJRkAOsjH63bqf15bqfSESL1841jFRoQ6HQkAcBiUZADoAO9+\nW6yf/muNhiVH68Xrxyo6nI8SNuYAACAASURBVKvoAYA3oyQDQDt7dekWPfTeOp2UFqvnp2epayg/\negHA2/GTGgDa0XMLC/To3A36wcAE/f2qUQoL5jLTAOALKMkA0A6stXpy/ib99bNNOntoTz1x2QiF\nBAU4HQsA0EaUZADwMGutfjd3g577qlCXjE7WYxcPU2AAl5kGAF9CSQYAD3K7rR56f51mL92q6eP7\n6OFzByuAggwAPoeSDAAe0uRy69631ujdb7frx5P76WdnDZAxFGQA8EWUZADwgPoml/73tW81b32p\n7j1rgO6Y0t/pSACAE0BJBoATVNvg0q2vrNDCvHI9fG6mrp+Y5nQkAMAJoiQDwAmoqmvUjS9ma/mW\n3frjxcN06ZgUpyMBADyAkgzAr9Q3ufRV3i7NXVui8v31mtAvTpMHxGtgj0iPzwfvrWnQ9BnLtH5H\npZ66fKTOHd7Lo88PAHAOJRmAz/uuGH+4tkSf5ZSqqr5J0eHB6hEVpsc+3qjHPt6oHlFhmpQRr8kD\n4jUxPU5RYSd2Wejyqnpd88JSFeyq1j+vHq3TMxM99G4AAN6AkgzAJ9U1uvTVpuYV49bFeOqQHjp7\nWE9N6BenkKAAlVbW6cvcci3IK9PcdSV6I3ubggKMRvXppskD4jU5I0GDeh7bKvP2vbW6+vml2rmv\nTjOvG6OJ/ePa8Z0CAJxgrLVOZ/ierKwsm52d7XQMAF7ou2L84Zod+mxDmfa3FOOzBidq2tD/FOPD\naXS59e3WvVqQW6YFueXKKamUJCVGhWpSRrymDEg46ipz0a5qXfX8UlXWNmrm9WOUldrd4+8TANAx\njDErrLVZh7yPkgzAm9U1urQwr7x5xfgQxXhi/zgFBx7f5Z5LK+v0ZV65vswt18JN5aqqazriKnNe\naZWuen6pmlxuvXzjOA1JivbkWwUAdDBKMgCfcqRifPawXprQL/a4i/HhNLnc+nbbXn2x8dCrzMNT\nYvSnebkKDgzQqzeNU3pipEdfHwDQ8SjJALxeeVW9Vm7do49aFeOYLsE6K7OHpg3r2S7F+EjKKuu0\noGWV+atN5aqsa1JSTLhm3zxOfWK7dlgOAED7OVJJ5oN7ADqU2221bU+N1u+o1Pod+5Szo1Lrd1Sq\nrKpekhTTJVhnD+3pSDFuLSEqTJdmpejSrBQ1udzKKalUn9iuig4/sV0xAAC+gZIMoN00NLmVX7Zf\n63fs0/odlcrZUakNJZWqqm+SJAUGGKUnROjk/nHK7BWlIUnRGt2nm2PF+HCCAgM0LDnG6RgAgA5E\nSQbgEfvrm7ShpFLrt+9TTknz6vCm0v1qcLklSeHBgRrUM1IXjEzS4F5RyuwVpYzESIUFBzqcHACA\n/0ZJBnDc3lpRrC82lmn9jn0qqqg5cDy2a4gye0XphpPTlNkrSoN7RSk1tqsCAzx7xTsAANoLJRnA\ncflobYl++q/VSooJ17DkaF08KlmDk6I0uFe0EiJDPX4JaAAAOhIlGcAxK62s0/3vrtWw5Gi9/eMJ\nXjdDDADAieI3G4Bj4nZb/fRfq1XX6NITl42gIAMA/BK/3QAck1lLivTVpl166OxM9YuPcDoOAADt\ngpIMoM02lVbp9x9t1A8GJuiqcb2djgMAQLuhJANok4Ymt+56fZUiQoP02MXD+GAeAMCv8cE9AG3y\nl0/zlFNSqeeuzVJ8ZKjTcQAAaFesJAM4qqUFFXpm4WZdPiZFZ2QmOh0HAIB216aSbIyZaozJNcbk\nG2N+fphzLjXG5Bhj1htjZh90X5QxptgY8zdPhAbQcSrrGnXPm6vVu3sX/eKcTKfjAADQIY46bmGM\nCZT0tKQzJBVLWm6MmWOtzWl1Trqk+yVNtNbuMcYkHPQ0v5G00HOxAXSUX72/Xjsr6/Sv28araygT\nWgCAzqEtK8ljJeVbawustQ2SXpd0/kHn3CzpaWvtHkmy1pZ9d4cxZrSkREmfeCYygI7y7zU79M63\n23XnlP4a1bub03EAAOgwbSnJSZK2tbpd3HKstQxJGcaYRcaYb4wxUyXJGBMg6c+SfnqkFzDG3GKM\nyTbGZJeXl7c9PYB2U7KvVg++u07DU2J05w/6Ox0HAIAO5akP7gVJSpc0WdIVkp4zxsRIul3SXGtt\n8ZEebK191lqbZa3Nio+P91AkAMfru6vqNTS59VeuqgcA6ITaMmC4XVJKq9vJLcdaK5a01FrbKKnQ\nGJOn5tI8XtIpxpjbJUVICjHG7LfWHvLDfwC8w8zFRVqUX6HfXThUaXFdnY4DAECHa8vy0HJJ6caY\nNGNMiKTLJc056Jz31LyKLGNMnJrHLwqstVdZa3tba1PVPHIxi4IMeLfcnVV67OONOn1Qgq4Ym3L0\nBwAA4IeOWpKttU2S7pQ0T9IGSW9aa9cbYx4xxpzXcto8SRXGmBxJX0i611pb0V6hAbSP+iaX7nr9\nW0WFBekPXFUPANCJGWut0xm+Jysry2ZnZzsdA+iUfjd3g55dWKAXpmfptEFcNAQA4N+MMSustVmH\nuo9P4wCQJC3ZXKHnvirQleN6U5ABAJ0eJRmA9tU26v+9uUqpsV310NmDnI4DAIDjuHwWAP3y/XUq\nrarX2z+eoC4h/FgAAICVZKCTe3/Vdr2/aofuOi1dI1JinI4DAIBXoCQDndiOvbV66L11Gtk7RrdP\n7ud0HAAAvAYlGeik3G6r//fmarncVn+9bISCuKoeAAAH8FsR6KRe+LpQSwoq9PC5meoTy1X1AABo\njZIMdEIbSir1+LxcnZmZqEuzuKoeAAAHoyQDnUxdo0s/eX2VosKD9fuLhnJVPQAADoG9noBO5k/z\ncpVbWqWZ141RbESo03EAAPBKlGSgk7DW6uN1O/X814W65qQ+mjIwwelIAAB4LUoy4OfqGl16f9V2\nvbh4izaUVCojMUIPTOOqegAAHAklGfBT2/fW6uUlW/T68q3aW9OogT0i9fuLhuqCEUkKDwl0Oh4A\nAF6Nkgz4EWutlhbu1kuLizRv/U5J0hmZibpuQppO6tudD+kBANBGlGTAD9Q2fDdSUaSNO6sU0yVY\nN5/aV9ec1EfJ3bo4HQ8AAJ9DSQZ82KFGKv5w0VCdz0gFAAAnhJIM+Bhrrb4paB6p+CSneaTirME9\nNH1CqsalMVIBAIAnUJIBH1Hb4NJ7q7brpVYjFbdO6qerT+qjpJhwp+MBAOBXKMmAl9u2u0avfLNF\nry/fpn21jRrUM0qPXdw8UhEWzEgFAADtgZIMeCm32+r/Ps/Xk/PzZIzRWYMTNX18qsYyUgEAQLuj\nJANeaH99k+55Y5U+ySnV+SN66WdTBzJSAQBAB6IkA16maFe1bnk5W/ll+/WLczJ1w8RUVo4BAOhg\nlGTAiyzMK9eds1cqIMBo1g3jdHJ6nNORAADolCjJgBew1uq5rwr0h482KiMxUs9ek6XesVwEBAAA\np1CSAYfVNbp039tr9P6qHZo2tIcev2S4uobyryYAAE7iNzHgoO17a3Xry9lav6NSPz0zQ3dM6c/8\nMQAAXoCSDDhkaUGFbn91peqb3HrumiydnpnodCQAANCCkgx0MGutXlm6Vb+es169u3fRs9dmqX9C\nhNOxAABAK5RkoAPVN7n0qznr9dqybZoyIF5/vXykosODnY4FAAAOQkkGOkhZZZ1+/OpKrdiyR3dM\n6ad7zhigwADmjwEA8EaUZKADrNq2V7e+nK3K2ib97cqROmdYL6cjAQCAI6AkA+3srRXFeuDdtUqI\nDNXbP56gzF5RTkcCAABHQUkG2kmTy61H527QzEVFmtAvVn+7cpS6dw1xOhYAAGgDSjLQDvZUN+iO\n2Su1eHOFrp+YqgenDVJQYIDTsQAAQBtRkgEP21BSqZtnZausql6PXzJMP8pKcToSAAA4RpRkwIM+\nXFOin/5rtaLCg/TmreM1IiXG6UgAAOA4UJIBD3C5rf7yaa6e/mKzRvWO0T+vHq2EqDCnYwEAgONE\nSQZOUGVdo37y+ip9vrFMl49J0a/PH6zQoECnYwEAgBNASQZOwOby/bp5Vra2VtToN+cP1tUn9ZEx\nXCAEAABfR0kGjtP8DaX6yeurFBIUoFdvGqdxfWOdjgQAADyEkgwcI2utnv4iX3/+NE+De0XpmWuy\nlBQT7nQsAADgQZRk4BhU1zfp3rdWa+7anTpveC89dvEwhYcwfwwAgL+hJANttG13jW6ela280io9\nMG2gbj6lL/PHAAD4KUoy0AaL8nfpjtkr5XZbzbx+rCZlxDsdCQAAtCNKMnAE1lrNWFSk383doL5x\nXfXctVlKjevqdCwAANDOKMnAYdQ1uvTAu2v1zsrtOjMzUX+5bIQiQvlXBgCAzoDf+MAhlOyr1W0v\nr9Dq4n36yenp+t8fpCsggPljAAA6C0oycJDsot267ZWVqm1o0jPXjNZZg3s4HQkAAHQwSjLQyuyl\nW/XwnHVKignX7JvHKSMx0ulIAADAAZRkQFJDk1u//mC9Xl26Vaekx+lvV4xSdJdgp2MBAACHUJLR\n6ZVX1euOV1dqWdFu3XpqX/1s6kAFMn8MAECnRklGp/fjV1Zo7fZ9evLyETp/RJLTcQAAgBcIcDoA\n4KSVW/coe8se3f/DgRRkAABwACUZndrMRUWKDAvSj7JSnI4CAAC8CCUZnVbJvlrNXVuiy8ekqCsX\nCQEAAK1QktFpzVqyRdZaXTs+1ekoAADAy1CS0SnVNDRp9tKtOmtwD6V07+J0HAAA4GUoyeiU3lm5\nXftqG3XDyWlORwEAAF6IkoxOx+22mrmoUMOSo5XVp5vTcQAAgBeiJKPTWbipXJvLq3XDxDQZw0VD\nAADAf6Mko9OZsahICZGhmja0p9NRAACAl6Iko1PZVFqlhXnlunZ8H4UE8e0PAAAOjZaATmXGoiKF\nBgXoirG9nY4CAAC8GCUZncae6ga9s7JYF45MUmxEqNNxAACAF6Mko9OYvWyr6pvcbPsGAACOipKM\nTqHR5dasJUU6JT1OGYmRTscBAABerk0l2Rgz1RiTa4zJN8b8/DDnXGqMyTHGrDfGzG451scYs9IY\ns6rl+G2eDA+01dy1JSqtrNcNE1lFBgAARxd0tBOMMYGSnpZ0hqRiScuNMXOstTmtzkmXdL+kidba\nPcaYhJa7SiSNt9bWG2MiJK1reewOj78T4DCstZrxdaH6xnXVpIx4p+MAAAAf0JaV5LGS8q21Bdba\nBkmvSzr/oHNulvS0tXaPJFlry1r+brDW1recE9rG1wM8auXWPVpdvE/XT0xVQAAXDwEAAEfXltKa\nJGlbq9vFLcday5CUYYxZZIz5xhgz9bs7jDEpxpg1Lc/x2KFWkY0xtxhjso0x2eXl5cf+LoAjmPF1\nkaLCgnTx6GSnowAAAB/hqZXdIEnpkiZLukLSc8aYGEmy1m6z1g6T1F/SdGNM4sEPttY+a63NstZm\nxcfzn8PhOcV7avTRuhJdMa63uoQcdboIAABAUttK8nZJKa1uJ7cca61Y0hxrbaO1tlBSnppL8wEt\nK8jrJJ1y/HGBY/Pyki0yxuja8alORwEAAD6kLSV5uaR0Y0yaMSZE0uWS5hx0zntqXkWWMSZOzeMX\nBcaYZGNMeMvxbpJOlpTroezAEVXXN+m1ZVs1dUgPJcWEOx0HAAD4kKOWZGttk6Q7Jc2TtEHSm9ba\n9caYR4wx57WcNk9ShTEmR9IXku611lZIGiRpqTFmtaQvJf3JWru2Pd4IcLC3Vxarsq6Jbd8AAMAx\nM9ZapzN8T1ZWls3OznY6Bnyc22112l++VFR4sN67fYKMYVcLAADwfcaYFdbarEPdx5Zs8EsL8spU\nuKtaN56cRkEGAADHjJIMvzTj6yL1iArTD4f0cDoKAADwQZRk+J3cnVX6On+Xrp3QR8GBfIsDAIBj\nR4OA35m5qFBhwQG6Ykxvp6MAAAAfRUmGX6nYX693vt2ui0Ylq1vXEKfjAAAAH0VJhl+ZvXSrGprc\numFiqtNRAACAD6Mkw280NLk165stmpQRr/4JkU7HAQAAPoySDL/x4dodKq+q1w0nc/EQAABwYijJ\n8AvWWr3wdaH6J0To1PQ4p+MAAAAfR0mGX8jeskfrtlfq+ompXDwEAACcMEoy/MILXxUqpkuwLhqZ\n7HQUAADgByjJ8Hnbdtfok5ydunJsb4WHBDodBwAA+AFKMnzeS4uLFGCMrhnfx+koAADAT1CS4dP2\n1zfpjeXbNG1oT/WMDnc6DgAA8BOUZPi0t7K3qaq+iW3fAACAR1GS4bPcbquZi4s0qneMRqTEOB0H\nAAD4EUoyfNb8jWXaUlHDKjIAAPA4SjJ81oyvC9UrOkxTB/dwOgoAAPAzlGT4pJwdlVpSUKHpE1IV\nFMi3MQAA8CzaBXzSzEWFCg8O1OVjejsdBQAA+CFKMnzOrv31en/VDl0yOlnRXYKdjgMAAPwQJRk+\n52+f56vB5dZ1E1OdjgIAAPwUJRk+ZXnRbr20pEjTx/dRv/gIp+MAAAA/RUmGz6hrdOm+t9YoKSZc\nP5s60Ok4AADAjwU5HQBoqyc+y1PBrmq9etM4dQ3lWxcAALQfVpLhE1Zt26vnFhboirEpmtg/zuk4\nAADAz1GS4fXqm1z62VurlRAZpvunDXI6DgAA6AT4b9bwek9/nq+80v2aed0YRYWx5RsAAGh/rCTD\nq63fsU9/X7BZF41K0pSBCU7HAQAAnQQlGV6r0eXWvf9ao5guIfrlOZlOxwEAAJ0I4xbwWs98uVk5\nJZX659WjFdMlxOk4AACgE2ElGV4pr7RKT83P19nDemrqkB5OxwEAAJ0MJRlep8nl1r1vrVFEWJAe\nOW+w03EAAEAnxLgFvM6MRYVavW2vnrpipGIjQp2OAwAAOiFWkuFVCsr368+f5OmMzESdO6yn03EA\nAEAnRUmG13C7re57e41CgwL06AVDZIxxOhIAAOikKMnwGrOWFGl50R798tzBSogKczoOAADoxCjJ\n8ArbdtfosY9zNSkjXhePSnI6DgAA6OQoyXCctc1jFoEBRr+/aChjFgAAwHGUZDjutWXbtHhzhR6Y\nNki9YsKdjgMAAEBJhrN27K3V7+Zu0IR+sbpibIrTcQAAACRRkuEga60eeHetXG6rP1w0jDELAADg\nNSjJcMw7K7drQW65fjZ1gHrHdnE6DgAAwAGUZDiirLJOv/5gvbL6dNP08alOxwEAAPgeSjI6nLVW\nD763TvVNbv3xkmEKCGDMAgAAeBdKMjrcv9eU6NOcUt1zRob6xkc4HQcAAOC/UJLRoSr21+vhOes1\nPDlaN56c5nQcAACAQ6Iko0M9PGe9quoa9fiPhisokG8/AADgnWgp6DAfr9upf68p0f/+IF0ZiZFO\nxwEAADgsSjI6xN6aBv3i/XXK7Bml2yb3czoOAADAEQU5HQD+z1qrRz7I0Z7qBs28boyCGbMAAABe\njpKMdlNd36R3VhbrxcVF2lxerf/5QX8NSYp2OhYAAMBRUZLhcUW7qjVryRb9K3ubquqbNDQpWn/+\n0XBdODLJ6WgAAABtQkmGR7jdVl/n79KLi4v0RW6ZAo3RtKE9NX1Cqkb1jpExXDAEAAD4DkoyTsj+\nViMVBeXViosI0f/8IF1XjeutxKgwp+MBAAAcF0oyjkvRrmq9tKRIb2UXq6q+ScOTo/XEZcM1bWhP\nhQYFOh0PAADghFCS0WZut9XCTeV6aXGRvsgtV3Bg80jFdRNSNbJ3N6fjAQAAeAwlGUdVVdeot1cU\na9aSLSrYVa24iFDddVrzSEUCIxUAAMAPUZJxWIW7qvXS4iK9taJY++ubNCIlRk9ePkI/HNJTIUHs\ndQwAAPwXJRn/pbbBpfveXqM5q3coONDonGG9NH1CqkakxDgdDQAAoENQkvE9e2sadONL2Vq5dY/u\nmNJP0yekKiGSkQoAANC5UJJxwI69tZo+Y5m2VNTo6StHadrQnk5HAgAAcAQlGZKkvNIqTZ+xTPvr\nmvTSDWM1vl+s05EAAAAcQ0mGVmzZrRtezFZIUIDeuHW8MntFOR0JAADAUZTkTu7TnFLdOXulesWE\na9YNY5XSvYvTkQAAABxHSe7E3li+Vfe/s1ZDk6I147oxio0IdToSAACAV2jTZrfGmKnGmFxjTL4x\n5ueHOedSY0yOMWa9MWZ2y7ERxpglLcfWGGMu82R4HB9rrf72+Sbd9/ZanZwer9k3n0RBBgAAaOWo\nK8nGmEBJT0s6Q1KxpOXGmDnW2pxW56RLul/SRGvtHmNMQstdNZKutdZuMsb0krTCGDPPWrvX4+8E\nbeJyW/36g/WatWSLLhyZpD9eMkzBgVwYBAAAoLW2jFuMlZRvrS2QJGPM65LOl5TT6pybJT1trd0j\nSdbaspa/8747wVq7wxhTJileEiXZAXWNLt3z5irNXbtTt5zaVz+fOlABAcbpWAAAAF6nLUuISZK2\ntbpd3HKstQxJGcaYRcaYb4wxUw9+EmPMWEkhkjYf4r5bjDHZxpjs8vLytqdHm1XWNeq6mcs0d+1O\nPThtkB6YNoiCDAAAcBie+uBekKR0SZMlJUtaaIwZ+t1YhTGmp6SXJU231roPfrC19llJz0pSVlaW\n9VAmtCirrNP0mcu1qbRKf71shC4YefD/xwEAAEBrbSnJ2yWltLqd3HKstWJJS621jZIKjTF5ai7N\ny40xUZI+lPSgtfYbD2TGMSgo369rZyzT7uoGvXDdGE3KiHc6EgAAgNdry7jFcknpxpg0Y0yIpMsl\nzTnonPfUvIosY0ycmscvClrOf1fSLGvtWx5LjTZZvW2vLvnnEtU0uPTazSdRkAEAANroqCXZWtsk\n6U5J8yRtkPSmtXa9MeYRY8x5LafNk1RhjMmR9IWke621FZIulXSqpOuMMata/oxol3eC7/kyr1xX\nPPeNuoQE6q3bxmt4SozTkQAAAHyGsda7RoCzsrJsdna20zF82rvfFuvef61RemKkXrp+jBKiwpyO\nBAAA4HWMMSustVmHuo8r7vmZ5xYW6NG5G3RS3+569tosRYUFOx0JAADA51CS/YTbbfX7jzboua8K\nNW1oDz1x2QiFBgU6HQsAAMAnUZL9xN++yNdzXxXq2vF99PC5gxXIHsgAAADHjZLsB3ZXN+iZLzfr\nrMGJ+vV5g2UMBRkAAOBEtGULOHi5ZxZuVk2jS//vzAEUZAAAAA+gJPu4sqo6vbS4SOcN76WMxEin\n4wAAAPgFSrKP+8eCzWp0Wd11WrrTUQAAAPwGJdmHleyr1atLt+qikUnqGx/hdBwA/7+9+4+Wuq7z\nOP5881vgKsgPNfkpgmI/RGQtUxPNX+VmnlpNrd3M8kdqnk2z7OR22tq2zOzHlrn9WMvtWP6qNUrK\n0DQVf4SSSIICCspVBEQuoHDxAu/94451HU0GvHe+c2eej3M4zMz9ztwX932+M6/z4TN3JEl1w5Lc\njV1+2yK2bEnOcxVZkiSpU1mSu6mlz63n2llL+cA/jGTkzv2LjiNJklRXLMnd1Hf+sJCI4NzD9yw6\niiRJUt2xJHdDi599gV/MfopTDhjFbjvtUHQcSZKkumNJ7oa+fcsCevcMzj5sXNFRJEmS6pIluZtZ\nuHwdv5rzNB8+cAzDm/oVHUeSJKkuWZK7mW/dspD+vXty5qGuIkuSJHUVS3I38vDTa7hp7jJOO3gs\nOw/oU3QcSZKkumVJ7ka+OWMhTf168bGD9yg6iiRJUl2zJHcTc5a2cMv85ZxxyB7s1L930XEkSZLq\nmiW5m7hsxgIG9+/NRw4eW3QUSZKkumdJ7gbuX/IcdyxYyZmHjmNg315Fx5EkSap7luRu4LLfL2Do\nwL78y4Gji44iSZLUECzJNe7uRc9yz+OrOHvqOPr3cRVZkiSpGizJNSwzuWzGAnbdsR+nvHVU0XEk\nSZIahiW5hv1xwUoeeGI15x6+J/169yw6jiRJUsOwJNeozOQbMxYwYvAOnDhlZNFxJEmSGooluUbN\nmLech5rXcN7h4+nTyzFJkiRVk+2rBm3Z0r6KPGZIf943efei40iSJDUcS3INmv6XZTzyzDr+9YgJ\n9OrpiCRJkqrNBlZjNm9JvnXLQsYPH8h79n1D0XEkSZIakiW5xkyb8xSLVjzPJ4+cQM8eUXQcSZKk\nhmRJriFtm7fwrVsWMnG3HTnmjbsWHUeSJKlhWZJryC9nN/PEqvWcf+QEeriKLEmSVBhLco3YuGkz\n/3XrIvYdsRNHTBxedBxJkqSGZkmuEdfNWspTLRs4/6i9iHAVWZIkqUiW5BrQ2raZ7962iCmjB/OO\n8UOLjiNJktTwLMk14Or7nmT52o1c4CqyJElSTbAkF2z9i5u44vZFvH3cEA4cN6ToOJIkScKSXLir\n7n6CZ59/kQuOmlB0FEmSJJVYkgu0rrWN79/xGFP3Gsb+o3cuOo4kSZJKLMkFuvKuJbSsb+P8I11F\nliRJqiW9ig5Q7zKTlvVtrFi3kZXrNrJiXSsrS5evnbWUI/fZhbeMGFR0TEmSJHVgSd5OrW2b28vu\n8y+V342l8vu3Erxi3UaefX4jbZvzFffv17sHY4YM4DPH7F1AekmSJL0WS3KFZj+5mv+5czGPPLOW\nles2srZ10yuOiYAhA/owrKkfw5r6sufwJobv2JdhA/syrKkvw5va/x7W1JeBfXv5694kSZJqlCX5\nNWQmMxet4nu3L+Lux1YxqH9vDtxjCAfvObRUevv9tfQOb+rLzgP60Kun27wlSZK6O0vyq9iyJZkx\nfznfu20Rc5rXMLypLxcfO5GTDxjFgL7+yCRJkuqdja+Dts1b+PWcp7ni9sdYuOJ5Rg/pz1fe92be\nN3l3+vbqWXQ8SZIkVYklmfY34V1//1K+f8fjNK/ewN67NvHtkyZx7Jt3c/uEJElSA2rokryutY2r\n73uSH925mGef38jkUYP49+PeyOF7D/dNdZIkSQ2sIUvycy+8yI9nLuaqu5ewtnUTh4wfyjmH7cdb\nx+5sOZYkSVJjleRlazbwwzsW8/M/PUnrps0cvc+unH3YOD/MQ5IkSS/TECV58bMv8N+3P8Yv/9zM\nloTjJ+3Ox6fuwZ7Do4KFBAAAC29JREFUm4qOJkmSpBpU1yX5yVXr+drNjzB97jJ69+zBKQeM4vR3\n7MGIwf2LjiZJkqQaVrcleW1rG/985X2sev5Fzjx0HKcdNJZhTX2LjiVJkqRuoC5Lcmby2V/MpXn1\nBq49421MGbNz0ZEkSZLUjdTlLwH+6b1PcNPcZVx49F4WZEmSJG2zuivJc5vX8B+/mc9hew3jjEP2\nKDqOJEmSuqG6KslrW9s452ezGTKwD984cRI9evg7jyVJkrTt6mZPcmZy0S8e4qmWDVx35tsYPKBP\n0ZEkSZLUTdXNSvL/3vME0+c+w6eP3ov9R7sPWZIkSduvLkryQ80tfPmm+bxz7+Gc7j5kSZIkvU7d\nviSv2dC+D3nowD58/YR93YcsSZKk161b70nOTD5zw0Msa2nl2jMPdB+yJEmSOkW3Xkm+6u4l/O7h\nZ/j0MXux/+jBRceRJElSnei2Jfmh5ha+PH0+R0x0H7IkSZI6V7csyS/tQx7e1I+vn7AvEe5DliRJ\nUufpdnuSM5NP3zCHZS2tXHfWgQzq7z5kSZIkda6KVpIj4piIeDQiFkXERX/nmBMjYl5EPBwRP+tw\n++8ioiUiftMZgX9y9xJufng5F71rbyaPch+yJEmSOt9WV5IjoidwOXAk0AzMiohpmTmvwzHjgc8C\nB2Xm6ogY3uEhLgX6A2e+3rBzlrbwn6V9yB89eOzrfThJkiTpVVWyknwAsCgzH8/MF4FrgPeWHXM6\ncHlmrgbIzBUvfSEzbwXWvd6ga9a7D1mSJEnVUUlJ3h1Y2uF6c+m2jiYAEyJiZkTcGxHHdFZAaN+H\nfOENc3hmTSvfPWU/9yFLkiSpS3XWG/d6AeOBqcAI4I6IeHNmtlRy54g4AzgDYNSoUa/4+o9nLuH3\n85Zz8bET2c99yJIkSepilawkPwWM7HB9ROm2jpqBaZnZlpmLgQW0l+aKZOYPMnNKZk4ZNmzYy772\n4NIWvvLb+RwxcRf3IUuSJKkqKinJs4DxETE2IvoAJwHTyo65kfZVZCJiKO3bLx5/veHWrG/jnKvb\n9yFf5j5kSZIkVclWS3JmbgLOBW4G5gPXZebDEfHFiDiudNjNwKqImAfcBlyYmasAIuJO4HrgnRHR\nHBFHVxIsM/nUDXNYsa6Vyz84mZ369972f50kSZK0HSrak5yZ04HpZbd9vsPlBM4v/Sm/7yHbE+zK\nmUuYMW85//aP+zBp5KDteQhJkiRpu9Tkx1I/uLSFr/52PkftswunHTSm6DiSJElqMDVXkjdvSc65\neja77NiPS//JfciSJEmqvs76FXCdpnn1Bgata+X6s97uPmRJkiQVouZK8trWNi5510T3IUuSJKkw\nNbfdYsTgHfiI+5AlSZJUoJoryYP793EfsiRJkgpVcyVZkiRJKpolWZIkSSpjSZYkSZLKWJIlSZKk\nMpZkSZIkqYwlWZIkSSpjSZYkSZLKWJIlSZKkMpZkSZIkqYwlWZIkSSpjSZYkSZLKWJIlSZKkMpZk\nSZIkqYwlWZIkSSpjSZYkSZLKWJIlSZKkMpZkSZIkqYwlWZIkSSpjSZYkSZLKWJIlSZKkMpGZRWd4\nmYhYBzxadA4BMBR4tugQcg41xFnUBudQO5xFbXAO2290Zg57tS/0qnaSCjyamVOKDiGIiPudRfGc\nQ+1wFrXBOdQOZ1EbnEPXcLuFJEmSVMaSLEmSJJWpxZL8g6ID6K+cRW1wDrXDWdQG51A7nEVtcA5d\noObeuCdJkiQVrRZXkiVJkqRCFVaSI+KYiHg0IhZFxEWv8vXzI2JeRDwUEbdGxOgicjaCCmZxVkTM\njYgHI+KuiNiniJz1bmtz6HDc+yMiI8J3MneRCs6JUyNiZemceDAiPlZEznpXyTkRESeWXisejoif\nVTtjI6jgfPhmh3NhQUS0FJGzEVQwi1ERcVtE/LnUn95dRM56Uch2i4joCSwAjgSagVnAyZk5r8Mx\nhwH3Zeb6iPg4MDUzP1D1sHWuwlnsmJlrS5ePA87OzGOKyFuvKplD6bgm4CagD3BuZt5f7az1rsJz\n4lRgSmaeW0jIBlDhHMYD1wGHZ+bqiBiemSsKCVynKn1u6nD8J4D9MvO06qVsDBWeEz8A/pyZV5QW\ntKZn5pgi8taDolaSDwAWZebjmfkicA3w3o4HZOZtmbm+dPVeYESVMzaKSmaxtsPVAYAb2TvfVudQ\n8iXgEqC1muEaTKWzUNeqZA6nA5dn5moAC3KX2Nbz4WTg51VJ1ngqmUUCO5Yu7wQ8XcV8daeokrw7\nsLTD9ebSbX/PR4HfdmmixlXRLCLinIh4DPgacF6VsjWSrc4hIiYDIzPzpmoGa0CVPj+9v/TfmTdE\nxMjqRGsolcxhAjAhImZGxL0R4f9wdb6KX69L2yLHAn+oQq5GVMksvgB8KCKagenAJ6oTrT7V/Bv3\nIuJDwBTg0qKzNLLMvDwzxwGfAS4uOk+jiYgewDeAC4rOIgB+DYzJzLcAM4CrCs7TqHoB44GptK9g\n/jAiBhWaqLGdBNyQmZuLDtLATgZ+kpkjgHcDPy29fmg7FPWDewrouPIyonTby0TEEcDngOMyc2OV\nsjWaimbRwTXA8V2aqDFtbQ5NwJuA2yNiCfA2YJpv3usSWz0nMnNVh+ekHwH7VylbI6nkuakZmJaZ\nbZm5mPb9muOrlK9RbMtrxEm41aIrVTKLj9K+T5/MvAfoBwytSro6VFRJngWMj4ixEdGH9hNrWscD\nImI/4Pu0F2T3mXWdSmbR8UXnWGBhFfM1itecQ2auycyhmTmm9CaMe2k/N3zjXuer5JzYrcPV44D5\nVczXKLY6B+BG2leRiYihtG+/eLyaIRtAJXMgIvYGBgP3VDlfI6lkFk8C7wSIiIm0l+SVVU1ZR3oV\n8U0zc1NEnAvcDPQErszMhyPii8D9mTmN9u0VA4HrIwLgycw8roi89azCWZxbWtVvA1YDHy4ucX2q\ncA6qggpncV7pN71sAp4DTi0scJ2qcA43A0dFxDxgM3BhZq4qLnX92YbnppOAa9JPKOsyFc7iAtq3\nHX2S9jfxnepMtp+fuCdJkiSVcTO3JEmSVMaSLEmSJJWxJEuSJEllLMmSJElSGUuyJEmSVMaSLElV\nEhGDIuLs0uWpEfGbLvgep0bEd7fxPktKv2e4/PYvRMSnOi+dJHUflmRJqp5BwNnbcoeI6NlFWSRJ\nr8GSLEnV81VgXEQ8SOkDkyLihoh4JCKujtInJ5VWdi+JiNnACRExLiJ+FxEPRMSdpU83IyJOiIi/\nRMSciLijw/d5Q+n4hRHxtZdujIiTI2Ju6T6XvFrAiPhcRCyIiLuAvbrqByFJta6QT9yTpAZ1EfCm\nzJwUEVOBXwFvBJ4GZgIHAXeVjl2VmZMBIuJW4KzMXBgRbwW+BxwOfB44OjOfiohBHb7PJGA/YCPw\naER8h/ZPpLsE2J/2T878fUQcn5k3vnSniNif9k9Om0T768Ns4IHO/zFIUu2zJEtScf6Umc0ApdXl\nMfytJF9bun0g8Hbg+tJCM0Df0t8zgZ9ExHXALzs87q2ZuaZ0/3nAaGAIcHtmrizdfjXwDuDGDvc7\nBPi/zFxfOsaPQ5fUsCzJklScjR0ub+blz8kvlP7uAbRk5qTyO2fmWaWV5WOBB0orwVt7XElSBdyT\nLEnVsw5o2pY7ZOZaYHFEnAAQ7fYtXR6Xmfdl5ueBlcDI13ioPwGHRsTQ0psBTwb+WHbMHcDxEbFD\nRDQB79mWrJJUT1xdkKQqycxVETEzIv4CbACWV3jXDwJXRMTFQG/gGmAOcGlEjAcCuLV02ytWnEvf\ne1lEXATcVjr+psz8VdkxsyPi2tLjrABmbeu/UZLqRWRm0RkkSZKkmuJ2C0mSJKmMJVmSJEkqY0mW\nJEmSyliSJUmSpDKWZEmSJKmMJVmSJEkqY0mWJEmSyliSJUmSpDL/D1zqmQ2+RVuBAAAAAElFTkSu\nQmCC\n",
            "text/plain": [
              "<Figure size 864x648 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNGNGPpuc_O9",
        "colab_type": "text"
      },
      "source": [
        "## ResNet50とVGGの結果比較\n",
        "- ResNet50の方がスコアが良い（より豊かな表現に対応できる？）\n",
        "- 処理速度についてはVGGの方がやや速いぐらい\n"
      ]
    }
  ]
}