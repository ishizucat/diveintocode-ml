{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow入門１　基本的な仕組み\n",
    "\n",
    "以下は、TensorFlow version 1.13.1 eigen_py37hbabb2b2_0　にて作動"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 動作確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "a = tf.constant(5)\n",
    "b = tf.constant(7)\n",
    "add = tf.add(a,b)\n",
    "\n",
    "sess = tf.Session()\n",
    "output = sess.run(add)\n",
    "print(output)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    output = sess.run(add)\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データフロープログラミング\n",
    "\n",
    "TensorFlowの手順は以下のようになっています。\n",
    " - データフローグラフを構築する\n",
    " - データを入力して計算する\n",
    " \n",
    " TensorFlowが値を扱う上で独自の概念として、placeholderとValiableがあります。\n",
    " \n",
    " ### 《placeholder》\n",
    "placeholderはデータフローグラフの構築時には値が決まっていないものに使います。最初は配列の形だけ定義しておいて後から値を入れて使う空箱のような存在です。学習ごとに違う値が入る入力データや正解データなどに用いられます。\n",
    "\n",
    "セッションを実行する際に引数feed_dictを使い、placeholderに入れる値を辞書型で指定します。ここを書き換えることで異なる計算が可能になります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "c = tf.placeholder(tf.int32)\n",
    "d = tf.placeholder(tf.int32)\n",
    "add = tf.add(c, d)\n",
    "\n",
    "sess = tf.Session()\n",
    "output = sess.run(add, feed_dict={c:5, d:7})\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n"
     ]
    }
   ],
   "source": [
    "output = sess.run(add, feed_dict={c:20, d:32})\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 《Valiable》\n",
    "\n",
    "Valiableはplaceholderとは違い、データフローグラフの構築時にも値を持ち、更新を行うものに対して使います。学習するパラメータ（重み、バイアス）に用いられます。\n",
    "\n",
    "### 《constant》\n",
    "確認になりますが、placeholderでもValiableでもないただの値は定数constantとして扱います。\n",
    "\n",
    "### 演算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "add2 = a+b\n",
    "output = sess.run(add2)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n"
     ]
    }
   ],
   "source": [
    "kakeru = a * b\n",
    "output = sess.run(kakeru)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## セッション終了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow入門２ロジスティック回帰実装\n",
    "\n",
    "TensorFlowを使いロジスティック回帰を実装していきます。入門1では単純な足し算でしたが、ここでは学習を伴う計算を行います。ANDゲートを題材に学習していく。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ANDゲート用データの作成\n",
    "import numpy as np\n",
    "x_train = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "y_train = np.array([[0],[0],[0],[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データフローグラフの構築"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#placeholderの用意\n",
    "x = tf.placeholder(tf.float32, [None, 2])\n",
    "t = tf.placeholder(tf.float32, [None, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "第一引数のtf.float32で行列要素の数値のデータ型を指定しています。第二引数の[None,2]で行列の形を指定しています。ここで定義されている2はデータの次元を表しています。Noneの部分はデータ数を表す部分です。任意の数のデータを入れられるように、一般的にNoneを使う。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/ishizucat/.pyenv/versions/anaconda3-5.3.1/envs/term3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "#valiableの用意\n",
    "W = tf.Variable(tf.zeros([2,1]))\n",
    "b = tf.Variable(tf.zeros([1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.Variable()の中でtf.zeros()という関数を呼び出していますが、初期値として0を入れているということ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ロジスティック回帰の仮定関数と目的関数の定義\n",
    "y = tf.sigmoid(tf.matmul(x, W) + b)\n",
    "cross_entropy = tf.reduce_sum(-t * tf.log(y) - (1 - t) * tf.log(1 - y))"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcsAAAB+CAYAAABLcjo1AAAJ42lDQ1BJQ0MgUHJvZmlsZQAASImVlndQFNkWxm93Tw6kGXIa4pBzGEByThIki8owQ4YRhoyYEHEFVhQREVAWcIkKrkqQNSCiGFgEFDCgO8gioKyLARMob4B9G+rV21fvq7rdvz731Fen+/7RHwBENWZiYjwsBEACJ4Xr62xHCwoOoWEnAQQwQADoAxKTlZxo6+3tAfj69/3vej/K7+brnvaK13/u/6OE2RHJLAAgbz6Hs5NZCXw+z2chViI3hc+9fFZKT0lc4Rk+U7n8Afm8tMJRq7wyPaCGr7Hyao+frz2fGQDgSEwmNwoAggO/TktjRfF9CGw+63HYMRw+l/DZihXN5NcI9/mslZCwlc/EldnUwv/iE/U3z/A/PJnMqD947V1WhXOISU6MZ2b+n5/jfyshPpX1l0dSSkRGygrYb03M5MZERafQbPmnEEFz5bB0tGgGevpmAKyc6Vr7W5/Vs4LE+v+spbgDYPkrAMjgn7WQZABO8X3FDf+sqUkAIHoCgE4NVio3ba2GWrmgAQEIAiqQBHJACagBbWAATIAFsAGOwA14AT8QDDYDFogGCYAL0kE22A3yQAE4CI6AclAFakEDOA3Ogg5wEVwFN8AdMAhGwGPAA1PgJZgH78EiBEFYiAxRIElIHlKBNCEDiAFZQY6QB+QLBUNhUBTEgVKhbGgPVAAVQ+VQNdQI/QBdgK5Ct6Ah6CE0Ac1Cb6DPMAKTYCosC6vCujADtoXdYT94ExwFJ8FZcC58AC6Da+BTcDt8Fb4Dj8A8+CW8gACEiIghCog2wkDsES8kBIlEuMgOJB8pRWqQFqQL6UPuITxkDvmEwqAoKBpKG2WBckH5o1ioJNQOVCGqHNWAakf1ou6hJlDzqK9oMloGrYk2R7uig9BR6HR0HroUXYduQ19Hj6Cn0O8xGIwYho4xxbhggjGxmG2YQsxxTCumGzOEmcQsYLFYSawm1hLrhWViU7B52GPYU9gr2GHsFPYjjoiTxxngnHAhOA4uB1eKa8Jdxg3jpnGLeCG8Ct4c74Vn4zPxRfiT+C78XfwUfpEgTKATLAl+hFjCbkIZoYVwnTBOeEskEhWJZkQfYgxxF7GMeIZ4kzhB/EQSIWmQ7EmhpFTSAVI9qZv0kPSWTCarkm3IIeQU8gFyI/ka+Sn5owBFQEfAVYAtsFOgQqBdYFjglSBeUEXQVnCzYJZgqeA5wbuCc0J4IVUheyGm0A6hCqELQmNCC8IUYX1hL+EE4ULhJuFbwjMiWBFVEUcRtkiuSK3INZFJCkJRothTWJQ9lJOU65QpKoZKp7pSY6kF1NPUAeq8qIiokWiAaIZoheglUZ4YIqYq5ioWL1YkdlZsVOyzuKy4rXiE+H7xFvFh8Q8S0hI2EhES+RKtEiMSnyVpko6ScZKHJDskn0ihpDSkfKTSpU5IXZeak6ZKW0izpPOlz0o/koFlNGR8ZbbJ1Mr0yyzIysk6yybKHpO9JjsnJyZnIxcrVyJ3WW5WniJvJR8jXyJ/Rf4FTZRmS4unldF6afMKMgouCqkK1QoDCouKdEV/xRzFVsUnSgQlhlKkUolSj9K8sryyp3K2crPyIxW8CkMlWuWoSp/KB1W6aqDqPtUO1Rm6BN2VnkVvpo+rkdWs1ZLUatTuq2PUGepx6sfVBzVgDWONaI0KjbuasKaJZozmcc0hLbSWmRZHq0ZrTJukbaudpt2sPaEjpuOhk6PTofNKV1k3RPeQbp/uVz1jvXi9k3qP9UX03fRz9Lv03xhoGLAMKgzuG5INnQx3GnYavjbSNIowOmH0wJhi7Gm8z7jH+IuJqQnXpMVk1lTZNMy00nSMQWV4MwoZN83QZnZmO80umn0yNzFPMT9r/puFtkWcRZPFzDr6uoh1J9dNWipaMi2rLXlWNKswq++seNYK1kzrGutnNko2bJs6m2lbddtY21O2r+z07Lh2bXYf7M3tt9t3OyAOzg75DgOOIo7+juWOT50UnaKcmp3mnY2dtzl3u6Bd3F0OuYy5yrqyXBtd591M3ba79bqT3De4l7s/89Dw4Hp0ecKebp6HPcfXq6znrO/wAl6uXoe9nnjTvZO8f/TB+Hj7VPg899X3zfbt20DZsGVD04b3fnZ+RX6P/dX8U/17AgQDQgMaAz4EOgQWB/KCdIO2B90JlgqOCe4MwYYEhNSFLGx03Hhk41SocWhe6Ogm+qaMTbc2S22O33xpi+AW5pZzYeiwwLCmsCWmF7OGuRDuGl4ZPs+yZx1lvWTbsEvYsxGWEcUR05GWkcWRM1GWUYejZqOto0uj52LsY8pjXse6xFbFfojziquPW44PjG9NwCWEJVzgiHDiOL1b5bZmbB1K1EzMS+QlmScdSZrnunPrkqHkTcmdKVT+z7M/VS11b+pEmlVaRdrH9ID0cxnCGZyM/kyNzP2Z01lOWd9vQ21jbevJVsjenT2x3XZ79Q5oR/iOnp1KO3N3Tu1y3tWwm7A7bvdPOXo5xTnv9gTu6cqVzd2VO7nXeW9znkAeN29sn8W+qm9Q38R8M7DfcP+x/V/z2fm3C/QKSguWClmFt7/V/7bs2+UDkQcGikyKThzEHOQcHD1kfaihWLg4q3jysOfh9hJaSX7JuyNbjtwqNSqtOko4mnqUV+ZR1nlM+djBY0vl0eUjFXYVrZUylfsrPxxnHx8+YXOipUq2qqDq83cx3z2odq5ur1GtKa3F1KbVPj8ZcLLve8b3jXVSdQV1X+o59bwG34beRtPGxiaZpqJmuDm1efZU6KnB0w6nO1u0W6pbxVoLzoAzqWde/BD2w+hZ97M95xjnWs6rnK9so7Tlt0Ptme3zHdEdvM7gzqELbhd6uiy62n7U+bH+osLFikuil4ouEy7nXl6+knVloTuxe+5q1NXJni09j68FXbvf69M7cN39+s0bTjeu9dn2XblpefPiLfNbF24zbnfcMbnT3m/c3/aT8U9tAyYD7XdN73YOmg12Da0bujxsPXz1nsO9G/dd798ZWT8yNOo/+mAsdIz3gP1g5mH8w9eP0h4tPt41jh7PfyL0pPSpzNOan9V/buWZ8C5NOEz0P9vw7PEka/LlL8m/LE3lPic/L52Wn26cMZi5OOs0O/hi44upl4kvF+fyfhX+tfKV2qvzv9n81j8fND/1mvt6+U3hW8m39e+M3vUseC88fZ/wfvFD/kfJjw2fGJ/6Pgd+nl5MX8IulX1R/9L11f3r+HLC8nIik8tcjQIIf8GRkQC8qQeAHAwAZZCfizauZa5VQQA2NPydwH/jtVy2KhMAql0ACCQA4L4XgPIJAOgtfN92ALzJAPiZrWWZ39fvSo40NFjzItnxo8nT5eW3qgBgDwPw5eDy8mLN8vKXWv6w4wB0c9ay3oqE9f4pc/0LXwWvx0/MrqEAADDOSURBVHgB7V0FfBRHF39QCBqgUIoUSHCCU0iCQ0txd/fgToDiXqSFtvChLe4OxR1a3AoFigUCFCnW4i795j9hl73LniV7l8vlvd8v2d2xnfnP3L6Z9968ifXk6fP/iIkRYAQYAUaAEWAELCIQ22IMRzACjAAjwAgwAoyARICZJQ8ERoARYAQYAUbABgLMLG0AxNGMACPACDACjAAzSx4DjAAjwAgwAoyADQSYWdoAiKMZAUaAEWAEGAFmljwGGAFGgBFgBBgBGwgws7QBEEczAowAI8AIMALMLHkMMAKMACPACDACNhBgZmkDII5mBBgBRoARYASYWfIYYAQYAUaAEWAEbCAQx0Y8RzMCjEAMQOC///4j/0IF6dNPP6UkSZLQnj17qHjx4vTkyRM6deokXQq9QnHjxo0BSHATGQF9BHhlqY8LhzICMQqBkydPUvESJWjjps3Urn17evPmNS1ctJg2bNxE2bJnZ0YZo0YDN1YPAWaWeqhwGCOgQeD27dvUokUzev36tSbU8m23rl0IzMddqE+f3nT8+HGr1dm2bSt16tRJpjl48CD5+wdQnDhhgie/HH5W82oj3a3t2rrxPSMQGQSYWUYGPc4bLRBo2KAe+eXIRs2aNXG4vi9fvqTGjRpQ48ZN7F5ddejYkZo2bUx///23w+8zOsO4cd/Rs6dPqUCBAiZFL168iOrVrUP9+/Wlli2bi8lAS8qaNZtMc/DAASomRLAKDRk6TLm1eXWnttusLCdgBBxAIBYf0eUAWpw0WiIAfVzaNKmpVatW9M2o0Q614Ycfvicwj6XLljuUb9DAAXT//n2aNHmKQ/mMTHw5NJQKFwmkCxcuUtKkSdWijx49SuXLfUVHjx2nhAkTUuZMvvT78ROULVt2evv2LX2WNg0tW76cSpYspeZx5MYd2u5IfTktI2APAryytAclThOtETh37iw9fvxIMI6iDrdj3ty51DooyOF8rVoH0aJFC+nevXsO5zUqw4IF86lmjZomjBITh969elK9evUpY8aM6mo5VDBW0IkTJ+jlyxdUqJB/hKvhDm2PcOU5IyNgAQFmlhaA4WDPQQA6OFCRIkXo3bt3djfs2LFjFBJyQervzDOB6eBPIe09wsCIYFV68uQfShKnXvXatWTJYvIPCDB579atW+jIkSNUu04dGX7z5g15ffb0mbz+9tuvlD9/frniNMmoeXC3tmuqxreMgNMQYGbpNGi5YHdBAGJUiBvbBLWmYkWLUN68uQmrTVt06OABwfCS0scff2ySdNXKlZQta2bK6ZedZs2aSXXr1JY60T/+MGWMvr6+dOH8eZO8Rj88evSQGtSvRwU/L0Dly5clGNhcunhR6kuvXr1KqIOWNm3cSIkSJ6ZSpUrL4DNnzoRFxyIKat2Kfv5pOsGgCVg9exbGQLX53ant2nrxPSPgbAR4n6WzEebyoxyBg4cOUqzYsWngoMFUsGBBKpA/Hy1auJCGjxhptW4XQkLCMZtdu3bS3LlzpI5v4oQJ1LVLZ5o5azbt3LmD1v6yhvLly6eW6SMY1TkrzBLM6epfV9X0lm6mTZ1OmbNkCRf95MljqlG9GgUWLkyLFi+hgQP608SJE6h9hw50IyRsxejr42uSb8uWzfTi+XPJ3BHx6NEj+uSTT6hmzVpUq1Ztk7TmD0a23bxsfmYE3B0BZpbu3kNcv0ghcOfOHbnSGjduvGSUEFfevXuH4sWLp5b75s0b6typI+XKlVswwWM0e/ZcGffo4UPBLH3UdLjBSnHM2LHk7Z2EsHLLmTOXZDJXrlwR1rbNTdKCUR0+fNgkTPswbfpPJqJcJS5WLLHME4Qr/mILRq9HvYKDhZg4hDZv2SbTYPWcNGkyyp49B128eEmGpc+QQc168+ZNunbtGvUfMJD69x8gw/PlyyMtZZV3qol1boxsu07xHMQIuDUCzCzdunu4cpFFYN/evbKIcuXKyyv0kA8ePKASJUuqRc+aOYMSe3tTl65dKWuWTDI+WbJk5OXlRW/evlHT4aZd+w7q8/79+6isKBeebb7+uq8artwg/0PBcC2Rso/RUryt8B07ttOXZcrIeiLt3n17qWjRopJJennFldePPvpILQbiVRBW1yDoYyGyDQ7uJZ9t/TOy7bbexfGMgLshwMzS3XqE62MoAmAgadKkoUyZM8tyV61aQSlSpJCrqYULF0ir0G++GUm/rF0v48FIseUDzDKHnx+tWrnCpD5YmcHCNWXKlITVZLGixWT8XuEeLlXqVOpeRQRevnyZvJN4m+TXPjRv3pSuijJs0cyZs8OJYWHdi32cgQGBMjv2gx4VhjsQNYNyCEcCWDFfv36dfHzCVseJEiWUccrz3DlzKGOmTBIDGWHjn5Ftt/EqjmYE3A4BZpZu1yVcISMR2L9vn8kG+507dlKVKlVp4YIF0jJ2n2Cmr169Fn+vaP36dVLsmTZtWlkFP8EslS0VSp3g4ODdu/+ofoMGMihX7lxyW8rgwQNp3boNSjJ5vXw51IR5mkSKh7lz55sH2f0MMTD2RT4T+keIlgcNGkgvXrwQ/lxLyDIyCPErDHlQB4U5pk+fQRo6PRWWr9iDOWPGDOHSbhHFjx/frvdGpu2NGzekK2Ly8NuefaRd7dr1Yk7ECLgBAvrKEDeoGFeBEYgsAmAisHqtUKGiWlSlSpVo9+5dhG0VrYPa0I7t24Xe0Y9OHP+d5s+bRyVKlFT1mX5+OaVIVitKDSxcRITdp5UrllPp0l9IXWflShXlig7MSUtYWRYW21WcRZMmTSbspSxapDCtXrWSEif2lts+8D7oIHMIn65aZp8gQQKpr+zZo5vQs9akGTNnUpkyX9ldvci0HXrXt2/f2f0uTsgIuBsC7MHH3XqE62MoAnfv3pUiU22ht27dkqdr4AMOn68w0unT52vp/q2M0AEqujnsJ8ybJxcNHTpc3ZeIcqD7gygXOkcYzUDMa24gA9+w5cuVpRChEwQTM5owEXguVpWJEiWSRYNhw2hp1eo16qvgSSdUrCwXLlyshuHm33//lStMe1eU2szu0HZtffieEXAVAryydBXS/J4oQQC6RXNKnTq1NH5BeDJhPQqx60VhVXpRMLbmwkeqQmCAU8W2DYhYwZgUSpUqlepkHHnNGSXSBQf3EGU1dwqjRPlgjvDtCoIR04ED+6lzly7yWfnXt19/6dB9z57flCB5TZ48ud2iV5OM4sEd2m5eJ35mBFyBADNLV6DM73BbBBo0aEjLly0TexPb6ervcGxVxUqVCT5i7aVly5ZK5+VDhgyzN4vD6cCkQ0MvSYcEMFCaMWMWffllGZNysOqcOmUafd2nj/T5ahLppAdXtN1JVediGQGrCLAY1io8HBkTEHgqTuWASNKS4Qk82QT37CGdoltKo8UpOLgnde/eg9KnT68NNvweolgYJtkSp/744w9UrFhx4bYv4v5e7a28q9pub304HSNgFALMLI1CksthBBgBRoAR8FgEWAzrsV3LDWMEGAFGgBEwCgFmlkYhyeUwAowAI8AIeCwCzCw9tmu5YYwAI8AIMAJGIcDM0igkuRxGgBFgBBgBj0WAmaXHdi03jBFgBBgBRsAoBJhZGoUkl8MIRBME4GAdjt9xwDMTI8AI2IcAM0v7cOJUjIBHIICDqzOkTyf85ZajtevWekSbuBGMgCsQYGbpCpT5HYyAmyBQUjiK37lrF3Xs1NlNasTVYASiBwJ8RFf06CeuJSNgCAI4vxIk3N4yMQKMgAMI8MrSAbA4KSPACDACjEDMRICZZczsd241I8AIMAKMgAMIMLN0ACxOygh4FALivE4mRoARsA8BZpb24cSpGAGPQwCHWzMxAoyAfQgws7QPJ07lwQjcvn2bWrRoRq9fv7bayqVLl9C0qVOspuFIRoAR8EwEmFl6Zr9yq+xE4OXLl9S4UQNq3LgJxY0b12qu2rXr0IoVy2nVypVW00WHyHfv/iOch/n27dvoUF2uIyMQ5Qgws4zyLuAKRCUCU6ZMphQpPqGyZcvZrEacOHHo2+/GU69ePenFixc207tjgiVLFlP+/Hlpwfz58rDrzJl8qW6d2u5YVa4TI+BWCPDhz27VHVwZVyNQIH8+Gvvtt1SuXHm7X12ieFFqHdRGiG5b2p2HEzICjED0RoBXltG7/7j2DiAAsaOWjh07RiEhF8jfP0AbrN5r02vFlf4BgXTs6FE1Hd8wAoyA5yPAzNLz+zjGt/DA/v1UrGhhKX7s3Kkjde/eTWJy6OABSpIkKX388ccmGN2/f58qVihPPhnS0bx5c2ntL79Q+3Zt1TS+vr507vw59ZlvGAFGwPMRYHd3nt/HMbqFR44coQYN6tH8BQupWLHilD9fHvLyiicxuRASQmB85jR+3HeU4pMUFCRErT//NJ1u3bpF+w8cUpP5+vjShfPn1WfzGzDY+fPnmQeHe27SpCk1b94iXDgHMAKMgPshwMzS/fqEa2QQArB0rVWzOlWuXIVKliwlS40b14uKFCki7x89fCiYpU+4t/Xt148SJ/am69ev0+7du2jNL2spZcqUaroMPj70zz//yL8UKVKo4coNmGDDho2UR5NrrFixhF/WD38mkfzACDACbosAM0u37RquWGQROP777wSRaqVKlWVRd+/epQsXzlOv3r3ls5eXF715+ybca8AoL4eGUsuWzWnK1GmUM2cukzReXmFbTB6IsvWYZezYsQl/kaXEiRJEtogoz//k6fMorwNXgBEwAgFmlkagyGW4JQLnBWMEBQQGyuu+vXvlFeJYUA4/P7FncoW81/67KMSzbdsG0cyZsylzliwEUe5HH31En3/+uUx2+fJleU2SNKk2m3o/e/Ysmjtntvps6QYr0KA2H3Sh5umY0Zgjws+MQNQhwMwy6rDnNzsZAX9/f/mGZ0+f0r1792j06FGUPn168hFiVJCfYJahYgWpJaSrWrWyMAbKT4cOH6IdO7bT2LFjaMfO3WqyK5evSDGt3qoSiVq2bCX/1Ax8Q/CSVLRIILVp24769u3HiDAC0Q4BZpbRrsu4wvYiAPHp8BEjqUKFcvTZZ5/R2bNnhLFPQzW7n19OevDgAT0Uusuk71eJ3bp1oQ4dO0nvNh07tJdefSb+b5LQbfqq+UIvh1JAQIAhola1UA+/gUMHbMV5xx6DPLynPbd57JTAc/s2xrfsqVhRJkiQQDK1f//9V24FgQ6yadNmEhs4Es+bJxcNHTqcatepI8Ng+Zo6dWp5j9VQwoQJyNs7iYrlmzdvKDDAnwYOHEQ1a9VSw/mGEWAEPBuByFsheDY+3LpoisDVq1cpU0YfmjVrpmzBmDGjKWOmTELEWk1tEaxSp06dToMHD6Tnz8MMURRGiUSpUqUyYZQIw1aSFy+eU9VqH8pBuDMJDHrvnj3UJqi1M1/DZTMCjIAVBHhlaQUcjoq+CGDbR9UqlYXTAW/hdCC5XCGOHDmKMmXOHK5RvXoFU/Lkyal//wHh4rQB0GcGBhSiZctXUsGCBbVRTrufO3cO9evblx49ekiJEicWur+7dr/ryZPHBGOkPHny2p0nMgmxUscEBKS9j0yZnJcRcBcEmFm6S09wPZyCABye4zQRWLNaomfPnlFwzx40afIUq+nghDyecGjgSvErtrC8fPVSrJCFha1gnI4wS7jzW758KY0Z862lphsWDi9JNWvWoNq1a9OrV69o1OgxJntTDXsRF8QIRBECbOATRcDza12DQPz48W2+KGHChDR12nSb6bTGQTYTG5QAomPQ+wWbQ6VG9HBnGOIojhPsfSH0uwcOHqIBA/pRq1atmVHaCxynizYIsM4y2nQVV5QRcAwBR5kljJvatgkS+0nzUz7hFhCrRRDEubAYNv97/PiRWqHqNWrQHLG/FC4Cv/qqrBrON4yApyDAK0tP6UluByNghoAjzPLcubNUulQpatqsGZ04cZK2bNks95fC1d/iRYvonnDvZ06JEiWirl27Sf1kt65dpNFTYGBhGjZ0CA0ZOsw8OT8zAtEaAWaW0br7uPIxCgFhQGON9u/bR0+fPVWTXDh/gUIvhdK2bVvVMNwULVqMwOi01Pfrr0VYQqpRvQYtWDCfJk6YQN+NGyeTwJGANYKFsLe3NwUH96S7d+7Sho2brCXnOEYgWiLAzDJadhtXOiYiYGuleOrUSencXcHmxo0bwnPRXTpy+LASJK+5c+cxYZZ37tyh7du3UeHChWnTpo30qdgyM3vOHMqVK7dJPksPDRs1kltsBg8ZSq9fv5LejSyl5XBGILoiwMwyuvYc15sRMEOgXfsOJiGHBZNctWoF9R8w0CTc/AGns4BatQ6iRo0am0fbfFacNsSLF4/wx8QIeCICbODjib3KbfI4BN69+0+6i3vrBHdx8JebMWNG6b9VAQ7bZBo1rK888pURiPEI8Moyxg8BBsCdEQDTgveh27duyz2gmTP5kr9/AC1fsdLQag8cNJiGDhksTlg5TDeF+BZ+c/83aYqh7+DCGIHojAA7JYjOvcd1ZwSsIKCIYe11SoD9ldeuXaN06dJZdc5g5ZUcxQh4LALMLD22a7lhMR2B169fExzIw8ctEyPACEQOAWaWkcOPczMCjAAjwAjEAATYwCcGdDI3kRFgBBgBRiByCDCzjBx+nJsRYAQYAUYgBiDAzDIGdDI3kRFgBBgBRiByCDCzjBx+nJsRYAQYAUYgBiDAzNKDOlnrDs3SvQc1l5vCCDACjIDLEGCnBC6D2rkv2rBhPY0Vm9eLFC1Kjx89pkuhl6hs2XJ09coVuhBygYJat6G69eo5txJcOiPACDACHooAryyjqGMvhoRQv35f0/Hjxw2pwd69e6hCxUp0/tx5mjxlqmSUW7duoR8nTKTq1arT7t27DHkPF8IIMAKMQExEgFeWLu7169evU8WK5elyaKh885dfljGkBqNHj6XKlSpSmzZt5Sn3OGmiWbPm0hPLtm3bqF599vNpCNBcCCPACMRIBHhl6eJu/zhZMprx80zDz/x79eqV9OtZrHhx6XB73769VLx4CcJp9rj3yeBDa1avdnFr+XWMACPACHgGAswsXdyPiRInpkBxbmD8+AkMffOZM2coe/bslDJlSrp4MURcPyVfX196+/YdffLJJ7Rs2VIhpq1o6Du5MEaAEWAEYgoCLIb1kJ7Omzcvbd22Q7YmW7bstP/AQXmfTKxkj/1+guLEiUNx48b1kNZyMxgBRoARcC0CzCxdi7fT3hY7dmxKkODDatXSvdMqwAUzAowAI+DBCDCzjOLO1e6HtKcqt27donVrfyHkczSvefl169Wn5MmTmwfzMyPACDACjIAZAswszQBx9aOjDO/58+diy0lfevHihaxqp86d6dNPTY9gUhgpzid8+/YtPXr0kEIvhdKlS5ekPhNhoPsPHlDfvv3kvav+HT16VDJ5f39/k1dCp1q69BeiLZ+ahHvyw+LFi4RldCWCqFxLMRELbfsjcs9YRgQ14/Pgm/PzT9OpXfsOJoU/EN+a9evXUZMmTU3Co9MDG/hEcW85yiwzZsxIo0aNVmt97uw56tkzmIKDe6l/vXr1pt69+9DXX/el/v0HEA7/XbZ8hdBdHqc/z5yTDDJp0mQ0c8bPhDMPXUV///039ezRjXLnzq2+sm2bILp69aoMa9ignrTkVSM9+Gbnzh20ceMGlVHevHmTWrRoJlsMfGISFpHtZsYysggal3/UNyNNJF67du2k0aNHyXG+bdtWOeaNe5trS/IYZnn79m35sbH18V+6dAlNmzrFtSjrvO0/MQMDvX79RifWelDbdu2pSpWqMtGOHdvpxx9/sJ5BE5suXToaOGgw7dt/gBIn9qZf1qxRY4cOGUzNmzelRYsWqmFG3kydMpnatG1noltNkyaNtNbNmTMX5cjh55LtLWBSEyb8aFjT7B172hfiAzJk8FA1KFasWJQnT175rIeFpXHbrWsXOnnypFqOM2+Mxs2ouhqFpVH1MS+nT5/ehjkfMS/bmc+O9vfDhw9p7dq11DqojVotjOvcufPI56FDhtE3I0eYMFO98YuJY6uWLVTpmVLY+PHjqEH9erRgwXwlyKXXaMMsmzZtTIUKfk6ZM/nKv0aNGqhAvXz5khqL58aNm5hYfJ47d5bq1qktVlaj6asyX9AV4fqtdu06tGLFclq1cqWa35U3//zzD+XLl4dQ/0SJElFQUCv5jLo5QlOnTafPPvtMZhk+bChBvOkIYVvJvPnzaeHCBWq2q39dpREjvhF1a6yGGXmzfPkyql//Q79hVT1s+AiJA96D98LrkJYqVChH2bNlEavnHtrgCN+fOnWSBg8aJCZWLdUyIDZCn/jlyEb//vuvGm7PjaWxZy3vpYsXZXSWrFnVZKlTp5aSASXAHAtL47ZDx46E3wZW7c4kPdzevHlDe/fsoTZBrZ35aqtlG4nloYMHKTDAn3JkzxpuHFqthJXIceO+o2dPn1KBAgXUVK7A7cKF81SkcKBsS0Qmv3r9rTbAws2qVSupatWqJt/gUqVKyzBkyZgpE0Gide3aNbUEvfGbNm1aypsvn3CwYjquID1r1rw5YXIaFRRtmOX8+Qtp9pw5EqiWLVuJ1c8SFa8pYsWSIsUn0sWbEohN+g0a1Cd0ltTLiRnOkiWL5RaKb78bT7169Qw3c1HyOvOaIkUK+uOPUxR6+SrdvnNPtOeufAbzcoQ+/vhjmjlzNsEKFqvplkKEBwcEjhBWMqvX/OJIlginxWQAzNHLy0uWgYlMlcqVaOCA/mqZPgKD8+fPqc+4WbVqDWGmmdE3o0l4RB86dexAvXr3Fj/apGoRWO0WK1pMej5y1OBJb+ypBVu42X9gP/n6+KqxWDV++UUpExGVORbY+qM3brEar1a1mpyxqwU64cYct7lz51CG9OkIk5m169Y64Y32FWkkltj/3K17d4KXLazuI0vw0vXdd9/SNxq1iatww/ax4SNGyLbg3lEy72978h/Yv58wbhXCJL5wYIDJRA7fOe1v3NL47datO50QrkAhOXMXijbMEoAdOnRI4gZn4VqaN3euWPoHaYNoqhC1/itWcW3atpXhXnG9VBdzn3/+uVyVgXlGZypeooTUS6INly9fpi5dOrttc27euEG+Qt+qEPqsTt26dO7cB+aIGSXaoaXjv/8umWzhIkW0wRG6P336lCy/Zs1a4fJjbBUu7Pg79MZeuMLNAm4ILKB7BmFlekqIUbNnzyGMr8JWnAjXw8LSuG3VOkiKzu/du4eshpMebiVLlKSdu3ZRx05RO+aMxvLYsWMEVQX+IksQF9asUdNkYuZK3ODyMmHChEJqks+hpuj1tz0FaPvijz/+kCvJp0+fmDJLMe7hv1pLeuMX4tuWrVrThB+NU5do3xmR+2jFLA8eOCBXUgEBAWpbMbhDxKka/v4fwrDS+nbsWLH8r0bx4sWTaW/+fZOeiI5TyD8gkI45KLpU8rrTtW+//lS0WDFZpRXLl9O8eXOjrHqwhLNEGPyJEyVWo0eNHkPLl5mKZbFKfvXqtWQgSsLDRw5LHWf+/PmVIPVqyzjKPH7J4sXiw5FfHRNKQbDUk2IrwZCRxzyfks78qjf2tGm0eGjLBBbw5ATC+OwnjLCg66lTp66aXQ8LROqNWzDeJEmSCN3lH2p+I2/0cINIDasC0RSnkxZH85cZjeXhQwflyT3m78GztXogXtvHeMZk3F/zrUKYK3E7IL6XnxcsKMWituqOuimk199KnPnvQ9tm2Rfvf+Ng0JkyZhLv9iJM8hRKlDAR3b17R3mUV0vjN0B80/EbcxeKXszy4AHy88tJ3t5JVPwOibAkSZISxJIK7d+/jx4+fECVKleWQdhucUWsWLJlzaYkIV9fXzpnJvJTI6PRzUcffUSzZs1R29+7V7CcPLi6CRAlQucHcaLyw9y0aSO1btVSViWHn5/JqhF6C8w+4ydIQBDfgMC0Xr9+ZcLMoEcqVMjfRA9yRYh0mzRpRJ8XyC983qajyZMmmXyooCeC7ilP7pzyZBdFL3tQfAjR7+Z0SITjR79+/XoqVbI4ZfTNIETcM8yThXvWG3tIBOveokUKU9YsmWhA/35CF9lT6kRRL5CfYDLaFfQ6IcbEVhp8XJ8+CZvQ6WGBvKi/3rhF+IXzpjN2pDeCLOFmRNm2yrA1rozE8tmzZ3Tq1CkpktfWC+O4dKkS4qOfX/bjkSNHtNGkN96gQ8Y4QL9EBeE3iHo+evhIjuncufykcYyybcxanSz1N+w8smXNTDn9sotvzkxpD4LfPH7HIPzG8Z1VCLrSBg0bmqgIrly9Qsk032olrd74hUgX3/Go0lEqdVOu0YZZYvDhI2kugr0gjroyH5BbNm+W7evQvp38YMFABEr1L8uUUdotdUbWPi5YoZUtW8bmH3QQUU0QGU2ZOl1W46kwJmjerJnJ6szZ9YPR0pTJk2jS5Cl0WIh+cIYmaPq0aXT//n15j8nMy5cvVEYK3WWGDBmkg4WAwECZBvtAC2hmoQg8KCZDxd6vnPEMfRIYMhzD/378BG3bvkOIonsTpA6gUaO+odXC0GDd+g3CgGkh/W/iRLU+IRcumOhUZAbxT8mLFfqvv+2l1kKs+cP345Voi1e9sYcPbu1aNWnGzJmyDrC6fS305xl9M9LCBWHGVDlz5hT7Xi+p5UJP+vTZU6lDV1acelggA3SdeuMWH5ZzTmKWlnBTG+CkG3vGlZFYHj16RH4nFEkNmoUJTLOmTWjEyG/oxImT1LBhI7mtR2mypfEGaRcI/RUV9Oefp+nJk8eUMFFCOQ6xdQz7HO2xnNbrb2wBwbcOvznslewqVD5Qo9y9e5fW/hJmUY++wDm6CmFc47el/U1j3GtXmkpavfELVQRcdGp1nEr6qLjGiYqXRuSdyuqjhDhJQ0uPhLmyr6+PNkjoNg/KFeiRo2FL+GFDh9Bk8TEPDCyspsvg40P4MeIPRjfmhAGBH4YeQdyg/dNL4+owWKHBUAWWnRDHDR48kMaODVvJRKQuMJD69dfdNrPCkcCxY0epd5+vadOmTYStINBNYnJyQBiyBPfqrZYBYyucq4ljyVKlSkVbtm6VUgElwWYxg2/atJnyKH8k0MNpP17du3WVIszhI0bKPsgqpAUQZe4WdX0kDJywz2vlqtXSuYEi7oHhBujRo0e6Hy8YieAd2JcKwkw2Xrz48l75N3HiBLovLGXhsH7a9J/kSl5v7EHvCAs/GIhgRQKC4wjMvmHxCoIoDo4ilLFXrlx5OTa1RkfmWMiM4p+lcYuPMiYqeuRIX+r5D7aEm/ousSq3RpAiwKDLGiVPnoIKCpGhluwZV0ZiuXfvXrkfENIrECyju3TuRO3EVq0SQkcLwh5YeNHCBxyTd0vj7aFY0UGUnl5MCC2SDdxg4X7/vnXrbNRVT7+6f98++X4YRkLydudOmOgzXjwvtTqYePbv31dYm2cnbyHG79q1m4zT629M0MYI1RakelgxY3zXqlVbYoCjAEFfiG9BZ4EX9niDhg4bTi+EVE+ZAGLifPv2LRVLmej9P73xC6lZuvTphY7zHJUsWUqbPEruow2zxAcNhCOotIQVypu3b7RB8mOH46kU2rhxo1idFFctMRHu5RVXRj8QHajHLDHQ8RdZSpzog7/WiJT15Olzu7ONFnpATCqgoD996rTd+fQSQu8LAwFbFChWhfjYQ4yJ2WYtsTUHEwkcao1VLqxMFYJVYNMmjeXAh3UnfsQK/fXXX7R9+zbavGWbEkR7xLYE/GAChX4ZBOkCtpZ0795DhiMMukYYySDdjh07pEEDGDhon/j4Ibzw+0kSxopijSsTiH/Ie1SIq6A3VAib3MuVr6A8SjyXihXG3n0HpFgZ2yWqVqsmyzIfe3Bojz8Q+gInvsB4B38KoU5jvx1HI4YPk4dzI1zLKPWwUPJaGrdoF/a56ZEjfRk37oc+UcrSw02Jw1Wrt9KGK/eYfNgaS2nEKsKcWdozrozEEuOlSJGicvyi7suEagEqnDp16ylNkWJaPHwU2/p42yuOxcP3A/WzRLZwO3v2DF0TvwtrlEQwLz1miffnyZNHTl6Rf7s40xZjUZkIIKxv3z5Ur259ypUrl9h210hllnr9rfXIAzVXWfGbx8RKmWCiPExcvipbVp5wVE+40kTbFUaJ+GHCOrZbtx6631VL4zdunLj0wMK4RpmuJLdllljyL1u6lJavWCk/gPhAYV+aMjtXQIKcfNXKFcqjvCYUSmTMwEFQEJ8586fYuD9BPiv/FJ1REs0WAiUO19mzZ9HcObO1Qbr3WIEGtWmrG4dAR5idxULsjIgfPz6VKFlSbiVZuGixnbn0k2EPaP8BA/UjdUJxLBhmr+XKlZOx+EFhxVewUCE1Ndy6BffqJVecykxdiQQTnD1nnsyjhOEcTvzgr9+4LlZ1YeJc6GJg5KLQhg0b5HagKlWqUP9+/eT+LMWoCx8MGBooP9gcOXLQ5SuXlazyCiMvMMziYjIFwuoMzKp69erSWAr7QkcMHy62ITWSH1HMju8/CKuL3th7IdwQ/vbbr3ICsWfPb+qqGCtkME8wWRAmGWAgWL2Yb1fRw0JmEv8sjVuEeyfxVpKZXB3tS5PM4kEPN/M01p4LiTGAv4iQPePKCCzlhEIYk8FgbuWKFWKyVE6IFEPleMQYVGjjhvVykz2+RVhtYT+g3niD8ROkK1i9+bz/Fill2HvVSlnszaOkA+NXmDyY8urVq6TBI76HYGKY0P66ezfNEb85TGwfvB/TyK/X35AOYAzjCMArYkWtTILxXU6VOhVBwgPC6nSMcLhhTtDBQ+1St96HiYc2jd74Rb3/Enu/k3jrj2ttflfcR37p5KRa/vDD9/IjidnLunXr5OxeO4tRXusnmGWoGNRayuGXQxpKQJmNfXwtW7YKp+u8cvmK9GCjt6pEWciz+9c9Nv+sMUptnVxxD0MWTBxWrV6julFzxXvxDjAJEMRpEPuhHoWE0QoYuJaw6jNnlIgPEl4/fIXeTUt/nv5TlBFAM2bMoIdCbJlHrNig+7z1902ZDOKg8ePG0YSJ/5NiIRjJPBc6QxBWhxuEwY72XZhVY++blvYJpp5AGBnBahAE3QzekVFY8i1etEh+8LDiTflpSslIoQvKmiWrTKs39rDvslbNGnJ/GD5MuXPllmkHDxoomHYiea/869ylSzhGiTg9LJQ8lsbt5cuhUi+qpDPyqoebUv67d/9JPbQ9hiNKHkeu9o6ryGIJ/KBvxuoWTkwSJEhIpUuXlhMpxVEFJtBgfosXL5FNsDbewBgwSUO5euRM3OCoARNXZQKICQeYXfUaNQheuvDNw2EMuYRIGYxy65bNlOX9mEZd9fob7hex93Ll+4VJrty55L5uqHvSpkmrNhGMeMDAQeqzcoOJMtxyWiK98QtJEvofah13ILdllhDBeIvBBqfh7du1lUDr6RDRsZi1aEVQwcG9pf6snDDQwez/B7NVJYAPFYMYW1CMELW6Q0dCF9hHbLZfsXJ1hGeykWkHHBxUqFCRYFRVvFhRuaI31y87Wj5WqTsEo4I3ka++Kis9/Ywb/z1NFgwJbvlat24pDC9GivsWsmiIitKlSy/EoLnp6z59wlaMYi+qQn4wrDFjlhBZQ4cKMRCovBC/gtnDSAfehbC6TSzGIfSTa8Ts/PHjJ+p2AL2xBwYKvW3Pnj2k/hUTGBiKwUE83hNZsjRuMTM3Yi+qXv30cIPhS/78eWmB8AKFDyQ8a8FbltHkjHGl1FGLJSZHmbNkoV7BwdSocWMprahUqbIcW5UrVaRGDesLBrNWOPFYK8WNKMPaeMPKLYc4jN18vLkCt9OnT0tGDSkTCG2DGqC3kOpgFQ5Gjs3+GdJnoOO/HxOOP1ZJ8alMLP7p9Xeg2IOM1edK4f0ME97OnToScIHrTEVyo+SPyFVv/GJiC3WNdltgRMo2Kk8sISb8z6jCjC4nJOSCHGzwLai4djN/B5bqefPkoqFDh1PtOnXUaIjWHj9+LOX0auD7G4hHsLVgoJgB1awVfoO6eXp3f8Zqp4IQG/308wx5ikVE69uyZXOhVxghf0yOlgEfs7Bow6oMjBuz0D1795u4+XK0TKSHSBTMR2t4gr6FSMh8TMCDkbKtCFs/evboTteu31B1o1jpVa9WhU6dPiPrifIxycLGbW35ELVCtIZwlLNm9WppUQjL2oOHDggXgWEibktjD9s/3r57K9+L8uOY6W7w3oiQpXELC8fy5cpSiFhRwN+v0aSHm9HvsFSes8aVHpYYV7DuNNcBwhArblxTHTvqa2u8DRo4QE7KlfFiqY1Gh2OVDyMd/BYVMv8eYnKDekH6g61Sm7dsFbrLMCmIpf6G7hmrUjAweNXC7xKTgsiSpfELw8yLly4SjJQUgr/as2fPmriGVOKcfXXblSUaDjk4ZvrmH0UtKOisqWLbBMQBUMYrhI8dFNp6BIvRFy+eq/ojvTTRJQyDFqugIUOHRYhRQuwYWcJHo1mzJtLBMVZo338/XhrhaP1hRvQdmAVrGRnKQd+aj4mfpk+jdJ+llR87MKgpkydLUbrWiAgitvoNGtJwYVijEAxrzMvHRwaMEpRM+LKECTtWm9CjDxIzaYUsjT3MtJX3onwjZt54p6VxGxzcg5q3aO4URon36uGGcGeTM8eVHpYYV+aMEm0Eg1D6U2mzPeMN+k8wAuiuXUlY6WsZJd5t/j2Ej1YYVeFoM0jxFEaJtJb6GxbsYJQg/CaMYJQoS2/8XhF60UmT/idWsF2QxC3IrZmlvQjB7VtFITKBntMWYUWCTcTYg6d0vK087hqPjwkYZQPBAKDncpTgQQebi7WEPYGO6p+wmoGYFOJS1Af7FEd+E17Jr32P0ffJk6eQeqauXTrJzdcw0Bj//Q/hXjNciFYxQcBq3B4qK1ZsENdBDwlJBAw3tOTI2NPmc/Te0rjF2Zdw1D1EnOjgTHIUNyPq4qxxZQlLR+psz3iDYdXUKdOkSsDR35QjdYlIWthk9BPWsFi5/6DjUs5V/W1p/KJuMBZStn2hjZAGvHltuvMhIm2PaB63FsM60igo54OFnggb4zGzskTQGcTziudy8StEdiBlNvbu3TsTfan5s6X6K+Gw3gNjgnXajJmz1HKVeFtXrJKwZ3HxkqVS14j03347lnbt3CktQdt36GiriHDx6ANlRRYu0kUB2K6Cj5Q1wv41zPZ79OhpLZkahx8pVpaW2mbv2FMLjMCNpXEL70DYSpNe7EdzNjmKm1H1MXpcWcIyIvW1Z7zhCD1sXYNBkDsR9vqar5i19XNFf+uNX/iYhXRq3LjxJt81OB+BQRIWBtia4mryGGbpauAceR9WgNWrVZVy/on/m0Qzfv5Z3N8Q+xCf0dx584VMfh7tF4YkfwvrrylTp6nMy9o72rVtIy3zcGqIYpxiLX2YGfZf0koUW2LwQwCjDbkYpkS3lpfjGAFGgBGI6Qgws3TBCBg7doywSMsozoocTteFCfeGDZvk/rtiRQuLLTGnpUcYWPrCwObe3XvSmMRatUaKcmDejtUEZobKalVZveKq/EH88+TJY7mfD0p+LXXp2lWcYj5WG8T3jAAjwAgwAjoIhGlrdSI4yDgE4PIJ+/3+EvsCBw8ZarJRHfpGZUvMndt3LIr6lNpA8X1QOBeH+yeFOSpxlq6xYqWRUQpTxQPuFTdVlvJxOCPACDACjEAYAswsXTASYKmKje1Y5ZUvX16+ERvqIZuHtS8I2w3g0xbM1Br5+vrS+g0brSXhOEaAEWAEGAGDEfAIa1iDMXFKcXBsDHPtnMIBMQju4ECKk/ANYv8QvFXgDM4ZP/8k4/gfI8AIMAKMgHsgwMzSRf0AP6U4akrxGASfivAYovi6xbFi+YSfyTti4y/ErM4gbK6GqTaMg5gYAUaAEWAE7EeAmaX9WEUq5Zk//1QPo0ZB2OdXWewNVQjndMIadvCQQTRhwkQl2OZ14sQJ8pw6mwlFAvg63SyO0fr11932JOc0jAAjwAgwAu8RYGtYFw0FbITWehSCP1t4d9Ea3WDlBz+k8LZhL0FkCx+Q2iOgrOXFqRrNmjYWBwWHWEvGcYwAI8AIMAIaBNjARwOGM2+1jBLvgRd+c4JbLUfJnU49cbTunJ4RYAQYgeiCADPL6NJTZvWEMRA8/18V571tEQcmwy+ucpSQWVLp0Qi+HBWyd8uJkp6vjAAjwAjEdASYWUbTEbBAeP2pV78+tWrZQp4nePXqFeGqble41uBQADgKb9O2nRrHzFKFgm8YAUaAEbALAWaWdsHkfokgfh0tTiSvVau2dAiPLSmW9JZavaj7tYRrxAgwAoyA+yPABj7u30cWa5hHnOM5YvhIuvfPPbHtJD+tXrVSNy18xw4dNlycX7eAli5ZQjDyKV+hPA0YMJCyZcuum4cDGQFGgBFgBD4gwMzyAxbR7u6L0iUpU6bM0uuPj49PtKs/V5gRYAQYgeiCADPL6NJTOvXE0UXQR5ofXqyTlIMYAUaAEWAEIoEA6ywjAV5UZ7V0vmJU14vfzwgwAoyApyHAHnw8rUe5PYwAI8AIMAKGI8DM0nBIuUBGgBFgBBgBT0OAmaWn9Si3hxFgBBgBRsBwBJhZGg4pF8gIMAKMACPgaQgws/S0HuX2MAKMACPACBiOADNLwyHlAhkBRoARYAQ8DQFmlp7Wo9weRoARYAQYAcMRYGZpOKRcICPACDACjICnIcDM0tN6lNvDCDACjAAjYDgC/wcmNwM52/0jLwAAAABJRU5ErkJggg=="
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)\n",
    "\n",
    "tf.matmul()はNumPyにおけるnp.dot()に相当するベクトルの内積や、行列積を計算するためのメソッドです。なお、例えば回帰問題で二乗和誤差関数を使用するのであれば、tf.reduce_sum(tf.square(y - t))というように定義できます。\n",
    "\n",
    "ここまでで、入力のための空箱であるplaceholderと学習可能なValiableをメソッドで結ぶことができました。\n",
    "学習を行うために、勾配降下法を用いてパラメータを最適化するためのコードを加えます。目的関数をGradientDescentOptimizerに渡します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_step = tf.train.GradientDescentOptimizer(0.1).minimize(cross_entropy)  #引数は学習率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習後の結果の正解が正しいかどうかの判定と正解率の計算もデータフローグラフとして定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.sign(y - 0.5), tf.sign(t -0.5))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.equal()は引数に指定された2つの値が等しいかどうかを判定してくれます。返り値はBool値です。tf.sign()は引数の値が正なら1、0なら0、負なら-1を返します。yが0.5以上かどうかで結果が決まるので、y-0.5とt-0.5の符号を比較しています。\n",
    "2行目は正解率を計算するためのコードです。tf.reduce_mean()は多次元配列の各成分の平均を計算する関数です。tf.cast()でBool値を0,1に変換しています。つまりここでは正解で1、不正解で0と判定された配列の平均値をとっているので正解率を表していることになります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データを入力して計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#セッションを準備して、パラメータを最適化\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.global_variables_initializer()によって上で定義したtf.Variable()の値(重み・バイアス)を初期化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, accuracy: 0.750000\n",
      "epoch: 100, accuracy: 1.000000\n",
      "epoch: 200, accuracy: 1.000000\n",
      "epoch: 300, accuracy: 1.000000\n",
      "epoch: 400, accuracy: 1.000000\n",
      "epoch: 500, accuracy: 1.000000\n",
      "epoch: 600, accuracy: 1.000000\n",
      "epoch: 700, accuracy: 1.000000\n",
      "epoch: 800, accuracy: 1.000000\n",
      "epoch: 900, accuracy: 1.000000\n"
     ]
    }
   ],
   "source": [
    "#学習\n",
    "for epoch in range(1000):\n",
    "    sess.run(train_step, feed_dict={\n",
    "        x:x_train,\n",
    "        t:y_train\n",
    "    })\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        acc_val = sess.run(\n",
    "            accuracy, feed_dict={\n",
    "                x:x_train,\n",
    "                t:y_train})\n",
    "        print(\"epoch: %d, accuracy: %f\" %(epoch, acc_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]]\n",
      "[[1.9654632e-04]\n",
      " [4.9049824e-02]\n",
      " [4.9049824e-02]\n",
      " [9.3120384e-01]]\n"
     ]
    }
   ],
   "source": [
    "#学習結果が正しいか確認\n",
    "\n",
    "classified = sess.run(correct_prediction, feed_dict={\n",
    "    x:x_train,\n",
    "    t:y_train\n",
    "})\n",
    "\n",
    "#出力yの確認\n",
    "prob = sess.run(y, feed_dict={\n",
    "    x:x_train,\n",
    "    t:y_train\n",
    "})\n",
    "\n",
    "print(classified)\n",
    "print(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W: [[5.5699544]\n",
      " [5.5699544]]\n",
      "b: [-8.534579]\n"
     ]
    }
   ],
   "source": [
    "print(\"W:\", sess.run(W))\n",
    "print(\"b:\", sess.run(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 途中の値が見たい場合（デバッグ）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.       ]\n",
      " [ 5.5699544]\n",
      " [ 5.5699544]\n",
      " [11.139909 ]]\n"
     ]
    }
   ],
   "source": [
    "mat = tf.matmul(x, W)\n",
    "y = tf.sigmoid(mat + b)\n",
    "print(sess.run(mat, feed_dict={\n",
    "    x:x_train,\n",
    "    t:y_train\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ディープラーニングフレームワーク１"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題1】スクラッチを振り返る\n",
    "\n",
    "ディープラーニングを実装するためにはどのようなものが必要だったか\n",
    "\n",
    "- 活性化関数\n",
    "- 勾配の算出\n",
    "- ミニバッチ\n",
    "- 適切なサンプリング\n",
    "- 正規化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題２】スクラッチとTensorFlowの対応を考える\n",
    "\n",
    "Irisデータセットのversicolorとvirginicaを使用する想定で、以下、TensorFlowのコード\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TensorFlowで実装したニューラルネットワークを使いIrisデータセットを2値分類する\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "\n",
    "# データセットの読み込み\n",
    "dataset_path =\"Iris.csv\"\n",
    "df = pd.read_csv(dataset_path)\n",
    "# データフレームから条件抽出\n",
    "df = df[(df[\"Species\"] == \"Iris-versicolor\")|(df[\"Species\"] == \"Iris-virginica\")]\n",
    "y = df[\"Species\"]\n",
    "X = df.loc[:, [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]]\n",
    "y = np.array(y)\n",
    "X = np.array(X)\n",
    "# ラベルを数値に変換\n",
    "y[y=='Iris-versicolor'] = 0\n",
    "y[y=='Iris-virginica'] = 1\n",
    "y = y.astype(np.int)[:, np.newaxis]\n",
    "\n",
    "# trainとtestに分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "# さらにtrainとvalに分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
    "\n",
    "class GetMiniBatch:\n",
    "    \"\"\"\n",
    "    ミニバッチを取得するイテレータ\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      学習データ\n",
    "    y : 次の形のndarray, shape (n_samples, 1)\n",
    "      正解値\n",
    "    batch_size : int\n",
    "      バッチサイズ\n",
    "    seed : int\n",
    "      NumPyの乱数のシード\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y, batch_size = 10, seed=0):\n",
    "        self.batch_size = batch_size\n",
    "        np.random.seed(seed)\n",
    "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
    "        self.X = X[shuffle_index]\n",
    "        self.y = y[shuffle_index]\n",
    "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
    "    def __len__(self):\n",
    "        return self._stop\n",
    "    def __getitem__(self,item):\n",
    "        p0 = item*self.batch_size\n",
    "        p1 = item*self.batch_size + self.batch_size\n",
    "        return self.X[p0:p1], self.y[p0:p1]        \n",
    "    def __iter__(self):\n",
    "        self._counter = 0\n",
    "        return self\n",
    "    def __next__(self):\n",
    "        if self._counter >= self._stop:\n",
    "            raise StopIteration()\n",
    "        p0 = self._counter*self.batch_size\n",
    "        p1 = self._counter*self.batch_size + self.batch_size\n",
    "        self._counter += 1\n",
    "        return self.X[p0:p1], self.y[p0:p1]\n",
    "\n",
    "# ハイパーパラメータの設定\n",
    "learning_rate = 0.01\n",
    "batch_size = 10\n",
    "num_epochs = 10\n",
    "\n",
    "n_hidden1 = 50\n",
    "n_hidden2 = 100\n",
    "n_input = X_train.shape[1]      #4\n",
    "n_samples = X_train.shape[0]  #64\n",
    "n_classes = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/ishizucat/.pyenv/versions/anaconda3-5.3.1/envs/term3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Epoch 0, loss : 0.0000, val_loss : 0.5087, acc : 1.000, val_acc : 0.875\n",
      "Epoch 1, loss : 0.0000, val_loss : 3.1327, acc : 1.000, val_acc : 0.875\n",
      "Epoch 2, loss : 0.0010, val_loss : 4.0351, acc : 1.000, val_acc : 0.688\n",
      "Epoch 3, loss : 0.0000, val_loss : 5.0135, acc : 1.000, val_acc : 0.875\n",
      "Epoch 4, loss : 1.5999, val_loss : 11.4190, acc : 0.750, val_acc : 0.500\n",
      "Epoch 5, loss : 0.0000, val_loss : 4.1432, acc : 1.000, val_acc : 0.875\n",
      "Epoch 6, loss : 0.0000, val_loss : 4.3073, acc : 1.000, val_acc : 0.812\n",
      "Epoch 7, loss : 0.0000, val_loss : 0.2717, acc : 1.000, val_acc : 0.875\n",
      "Epoch 8, loss : 0.0000, val_loss : 0.0039, acc : 1.000, val_acc : 1.000\n",
      "Epoch 9, loss : 0.0000, val_loss : 0.0000, acc : 1.000, val_acc : 1.000\n",
      "test_acc : 0.900\n"
     ]
    }
   ],
   "source": [
    "# 計算グラフに渡す引数の形を決める\n",
    "X = tf.placeholder(\"float\", [None, n_input])    #4\n",
    "Y = tf.placeholder(\"float\", [None, n_classes]) #64\n",
    "\n",
    "# trainのミニバッチイテレータ\n",
    "get_mini_batch_train = GetMiniBatch(X_train, y_train, batch_size=batch_size)\n",
    "\n",
    "def example_net(x):\n",
    "    \"\"\"\n",
    "    単純な3層ニューラルネットワーク\n",
    "    \"\"\"\n",
    "\n",
    "    # 重みとバイアスの宣言\n",
    "    weights = {\n",
    "        'w1': tf.Variable(tf.random_normal([n_input, n_hidden1])),         #(4, 50)\n",
    "        'w2': tf.Variable(tf.random_normal([n_hidden1, n_hidden2])),    #(50, 100)\n",
    "        'w3': tf.Variable(tf.random_normal([n_hidden2, n_classes]))      #(100, 1)\n",
    "    }\n",
    "    biases = {\n",
    "        'b1': tf.Variable(tf.random_normal([n_hidden1])),   #50\n",
    "        'b2': tf.Variable(tf.random_normal([n_hidden2])),   #100\n",
    "        'b3': tf.Variable(tf.random_normal([n_classes]))     #1\n",
    "    }\n",
    "\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['w1']), biases['b1'])\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['w2']), biases['b2'])\n",
    "    layer_2 = tf.nn.relu(layer_2)\n",
    "    layer_output = tf.matmul(layer_2, weights['w3']) + biases['b3'] # tf.addと+は等価である\n",
    "    return layer_output\n",
    "\n",
    "# ネットワーク構造の読み込み                               \n",
    "logits = example_net(X)\n",
    "\n",
    "# 目的関数\n",
    "loss_op = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=Y, logits=logits))\n",
    "\n",
    "# 最適化手法\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "# 推定結果\n",
    "correct_pred = tf.equal(tf.sign(Y - 0.5), tf.sign(tf.sigmoid(logits) - 0.5))\n",
    "# 指標値計算\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# variableの初期化\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "\n",
    "# 計算グラフの実行\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(num_epochs):\n",
    "        # エポックごとにループ\n",
    "        total_batch = np.ceil(X_train.shape[0]/batch_size).astype(np.int)   #サンプル数をバッチで割った値を切り上げ\n",
    "        total_loss = 0\n",
    "        total_acc = 0\n",
    "        for i, (mini_batch_x, mini_batch_y) in enumerate(get_mini_batch_train):\n",
    "            # ミニバッチごとにループ\n",
    "            \n",
    "            #最適化インスタンスを呼び出しして学習\n",
    "            sess.run(train_op, feed_dict={X: mini_batch_x, Y: mini_batch_y})\n",
    "            \n",
    "            #ミニバッチで学習したモデルからlossとスコアを計算して加算\n",
    "            loss, acc = sess.run([loss_op, accuracy], feed_dict={X: mini_batch_x, Y: mini_batch_y})\n",
    "            total_loss += loss\n",
    "            total_acc += acc\n",
    "            \n",
    "        #全バッチの学習後にサンプル方向に平均取る\n",
    "        total_loss /= n_samples\n",
    "        total_acc /= n_samples\n",
    "        \n",
    "        #検証データのloss、スコアを取得\n",
    "        val_loss, val_acc = sess.run([loss_op, accuracy], feed_dict={X: X_val, Y: y_val})\n",
    "        \n",
    "        print(\"Epoch {}, loss : {:.4f}, val_loss : {:.4f}, acc : {:.3f}, val_acc : {:.3f}\".format(epoch, loss, val_loss, acc, val_acc))\n",
    "    \n",
    "    #全エポック後にテスト\n",
    "    test_acc = sess.run(accuracy, feed_dict={X: X_test, Y: y_test})\n",
    "    print(\"test_acc : {:.3f}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 考察\n",
    "\n",
    "- ミニバッチの箇所はスクラッチと同様の処理。唯一の違いはセッションの中に入れる\n",
    "- 重み、バイアス、活性化関数はネットワーク構造の中で記述\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題３】Iris３種類全てを使用したモデルを作成\n",
    "\n",
    "https://qiita.com/woowig/items/c6715d3c1557c62ab33a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.read_csv(dataset_path)\n",
    "y = df3[\"Species\"]\n",
    "X = df3.loc[:, [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]]\n",
    "y = np.array(y)\n",
    "X = np.array(X)\n",
    "\n",
    "# ラベルを数値に変換\n",
    "y[y=='Iris-versicolor'] = 0\n",
    "y[y=='Iris-virginica'] = 1\n",
    "y[y=='Iris-setosa'] = 2\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y_one_hot = enc.fit_transform(y[:, np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train (96, 4)\n",
      "y_train (96, 3)\n",
      "X_val (24, 4)\n",
      "y_val (24, 3)\n",
      "X_test (30, 4)\n",
      "y_test (30, 3)\n"
     ]
    }
   ],
   "source": [
    "# trainとtestに分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_one_hot, test_size=0.2, random_state=0)\n",
    "# さらにtrainとvalに分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
    "\n",
    "print(\"X_train\", X_train.shape)\n",
    "print(\"y_train\", y_train.shape)\n",
    "print(\"X_val\", X_val.shape)\n",
    "print(\"y_val\", y_val.shape)\n",
    "print(\"X_test\", X_test.shape)\n",
    "print(\"y_test\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ハイパーパラメータの設定\n",
    "learning_rate = 0.01\n",
    "batch_size = 10\n",
    "num_epochs = 10\n",
    "\n",
    "n_hidden1 = 50\n",
    "n_hidden2 = 100\n",
    "n_input = X_train.shape[1]      #4\n",
    "n_samples = X_train.shape[0]  #96\n",
    "n_classes = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss : 7.6030, val_loss : 19.7495, acc : 0.833, val_acc : 0.625\n",
      "Epoch 1, loss : 0.0000, val_loss : 0.3797, acc : 1.000, val_acc : 0.917\n",
      "Epoch 2, loss : 0.0006, val_loss : 2.7315, acc : 1.000, val_acc : 0.833\n",
      "Epoch 3, loss : 0.0000, val_loss : 0.9871, acc : 1.000, val_acc : 0.917\n",
      "Epoch 4, loss : 0.0000, val_loss : 1.4025, acc : 1.000, val_acc : 0.833\n",
      "Epoch 5, loss : 0.0000, val_loss : 0.7036, acc : 1.000, val_acc : 0.917\n",
      "Epoch 6, loss : 0.0000, val_loss : 0.9538, acc : 1.000, val_acc : 0.917\n",
      "Epoch 7, loss : 0.0000, val_loss : 0.4306, acc : 1.000, val_acc : 0.958\n",
      "Epoch 8, loss : 0.0000, val_loss : 1.7862, acc : 1.000, val_acc : 0.833\n",
      "Epoch 9, loss : 0.0000, val_loss : 0.4973, acc : 1.000, val_acc : 0.833\n",
      "test_acc : 0.900\n"
     ]
    }
   ],
   "source": [
    "# 計算グラフに渡す引数の形を決める\n",
    "X = tf.placeholder(\"float\", [None, n_input])    #4\n",
    "Y = tf.placeholder(\"float\", [None, n_classes]) #3\n",
    "\n",
    "# trainのミニバッチイテレータ\n",
    "get_mini_batch_train = GetMiniBatch(X_train, y_train, batch_size=batch_size)\n",
    "\n",
    "def example_net(x):\n",
    "    \"\"\"\n",
    "    単純な3層ニューラルネットワーク\n",
    "    \"\"\"\n",
    "\n",
    "    # 重みとバイアスの宣言\n",
    "    weights = {\n",
    "        'w1': tf.Variable(tf.random_normal([n_input, n_hidden1])),         #(4, 50)\n",
    "        'w2': tf.Variable(tf.random_normal([n_hidden1, n_hidden2])),    #(50, 100)\n",
    "        'w3': tf.Variable(tf.random_normal([n_hidden2, n_classes]))      #(100, 3)\n",
    "    }\n",
    "    biases = {\n",
    "        'b1': tf.Variable(tf.random_normal([n_hidden1])),   #50\n",
    "        'b2': tf.Variable(tf.random_normal([n_hidden2])),   #100\n",
    "        'b3': tf.Variable(tf.random_normal([n_classes]))     #3\n",
    "    }\n",
    "\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['w1']), biases['b1'])\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['w2']), biases['b2'])\n",
    "    layer_2 = tf.nn.relu(layer_2)\n",
    "    layer_output = tf.add(tf.matmul(layer_2, weights['w3']), biases['b3'])\n",
    "    #layer_output = ft.nn.softmax(layer_3)  TensorFlowの関数で計算するので必要ない\n",
    "    return layer_output\n",
    "\n",
    "# ネットワーク構造の読み込み                               \n",
    "logits = example_net(X)\n",
    "\n",
    "# 目的関数\n",
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=Y, logits=logits))\n",
    "\n",
    "# 最適化手法\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "# 推定結果\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
    "# 指標値計算\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# variableの初期化\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "\n",
    "# 計算グラフの実行\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(num_epochs):\n",
    "        # エポックごとにループ\n",
    "        total_batch = np.ceil(X_train.shape[0]/batch_size).astype(np.int)   #サンプル数をバッチで割った値を切り上げ\n",
    "        total_loss = 0\n",
    "        total_acc = 0\n",
    "        for i, (mini_batch_x, mini_batch_y) in enumerate(get_mini_batch_train):\n",
    "            # ミニバッチごとにループ\n",
    "            \n",
    "            #最適化インスタンスを呼び出しして学習\n",
    "            #print(sess.run(logits , feed_dict={X: mini_batch_x, Y: mini_batch_y}))  デバッグ用\n",
    "            sess.run(train_op, feed_dict={X: mini_batch_x, Y: mini_batch_y})\n",
    "            \n",
    "            #ミニバッチで学習したモデルからlossとスコアを計算して加算\n",
    "            loss, acc = sess.run([loss_op, accuracy], feed_dict={X: mini_batch_x, Y: mini_batch_y})\n",
    "            total_loss += loss\n",
    "            total_acc += acc\n",
    "            \n",
    "        #全バッチの学習後にサンプル方向に平均取る\n",
    "        total_loss /= n_samples\n",
    "        total_acc /= n_samples\n",
    "        \n",
    "        #検証データのloss、スコアを取得\n",
    "        val_loss, val_acc = sess.run([loss_op, accuracy], feed_dict={X: X_val, Y: y_val})\n",
    "        \n",
    "        print(\"Epoch {}, loss : {:.4f}, val_loss : {:.4f}, acc : {:.3f}, val_acc : {:.3f}\".format(epoch, loss, val_loss, acc, val_acc))\n",
    "    \n",
    "    #全エポック後にテスト\n",
    "    test_acc = sess.run(accuracy, feed_dict={X: X_test, Y: y_test})\n",
    "    print(\"test_acc : {:.3f}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題４】House Priceのモデルを作成（回帰）\n",
    "\n",
    "**参考**\n",
    "\n",
    "https://codeday.me/jp/qa/20190704/1168140.html\n",
    "\n",
    "https://qiita.com/MahoTakara/items/0d7284774c2adf1f05ec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1460 entries, 1 to 1460\n",
      "Data columns (total 3 columns):\n",
      "SalePrice    1460 non-null int64\n",
      "GrLivArea    1460 non-null int64\n",
      "YearBuilt    1460 non-null int64\n",
      "dtypes: int64(3)\n",
      "memory usage: 45.6 KB\n"
     ]
    }
   ],
   "source": [
    "#データ\n",
    "df_0 = pd.read_csv('train.csv', index_col=0)\n",
    "df = df_0.loc[:,[\"SalePrice\", \"GrLivArea\", \"YearBuilt\"]]\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train (876, 2)\n",
      "y_train (876, 1)\n",
      "X_val (219, 2)\n",
      "y_val (219, 1)\n",
      "X_test (365, 2)\n",
      "y_test (365, 1)\n"
     ]
    }
   ],
   "source": [
    "X = df.iloc[:,[1,2]].values\n",
    "y = df[\"SalePrice\"].values.reshape(-1,1)\n",
    "\n",
    "(X_train, X_test, y_train, y_test) = train_test_split(X, y, test_size=0.25, random_state=0,)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
    "\n",
    "print(\"X_train\", X_train.shape)\n",
    "print(\"y_train\", y_train.shape)\n",
    "print(\"X_val\", X_val.shape)\n",
    "print(\"y_val\", y_val.shape)\n",
    "print(\"X_test\", X_test.shape)\n",
    "print(\"y_test\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ハイパーパラメータの設定\n",
    "learning_rate = 0.01\n",
    "batch_size = 10\n",
    "num_epochs = 10\n",
    "\n",
    "n_input = X_train.shape[1]      #2\n",
    "n_samples = X_train.shape[0]  #876\n",
    "n_classes = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss : 23090337792.0000, val_loss : 44029878272.0000, acc : 23090337792.000, val_acc : 44029878272.000\n",
      "Epoch 1, loss : 23090337792.0000, val_loss : 44029878272.0000, acc : 23090337792.000, val_acc : 44029878272.000\n",
      "Epoch 2, loss : 23090337792.0000, val_loss : 44029878272.0000, acc : 23090337792.000, val_acc : 44029878272.000\n",
      "Epoch 3, loss : 23090337792.0000, val_loss : 44029878272.0000, acc : 23090337792.000, val_acc : 44029878272.000\n",
      "Epoch 4, loss : 23090337792.0000, val_loss : 44029878272.0000, acc : 23090337792.000, val_acc : 44029878272.000\n",
      "Epoch 5, loss : 23090337792.0000, val_loss : 44029878272.0000, acc : 23090337792.000, val_acc : 44029878272.000\n",
      "Epoch 6, loss : 23090337792.0000, val_loss : 44029878272.0000, acc : 23090337792.000, val_acc : 44029878272.000\n",
      "Epoch 7, loss : 23090337792.0000, val_loss : 44029878272.0000, acc : 23090337792.000, val_acc : 44029878272.000\n",
      "Epoch 8, loss : 23090337792.0000, val_loss : 44029878272.0000, acc : 23090337792.000, val_acc : 44029878272.000\n",
      "Epoch 9, loss : 23090337792.0000, val_loss : 44029878272.0000, acc : 23090337792.000, val_acc : 44029878272.000\n",
      "test_acc : 39538843648.000\n"
     ]
    }
   ],
   "source": [
    "# 計算グラフに渡す引数の形を決める\n",
    "X = tf.placeholder(\"float\", [None, n_input], name = \"X\")    #2\n",
    "Y = tf.placeholder(\"float\", [None, n_classes], name = \"Y\") #1\n",
    "\n",
    "# trainのミニバッチイテレータ\n",
    "get_mini_batch_train = GetMiniBatch(X_train, y_train, batch_size=batch_size)\n",
    "\n",
    "# input-to-hidden layer1\n",
    "W1 = tf.Variable(tf.truncated_normal([n_input,300], stddev = 0.03), name = 'W1')\n",
    "b1 = tf.Variable(tf.truncated_normal([300]), name = 'b1')  \n",
    "\n",
    "# hidden layer1-to-output\n",
    "W2 = tf.Variable(tf.truncated_normal([300,1], stddev = 0.03), name=  'W2')    \n",
    "b2 = tf.Variable(tf.truncated_normal([1]), name = 'b2')   \n",
    "\n",
    "# output hidden layer 1\n",
    "hidden_out = tf.nn.relu(tf.add(tf.matmul(X, W1), b1))   \n",
    "\n",
    "# total output\n",
    "y_ = tf.nn.relu(tf.add(tf.matmul(hidden_out, W2), b2)) \n",
    "\n",
    "# 目的関数\n",
    "loss_op = tf.losses.mean_squared_error(Y, y_)\n",
    "\n",
    "# 最適化手法\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = learning_rate) \n",
    "train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "# 推定結果\n",
    "#correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
    "# 指標値計算\n",
    "accuracy =  tf.reduce_mean(tf.square(tf.subtract(Y, y_)))\n",
    "\n",
    "# variableの初期化\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "\n",
    "# 計算グラフの実行\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(num_epochs):\n",
    "        # エポックごとにループ\n",
    "        total_batch = np.ceil(X_train.shape[0]/batch_size).astype(np.int)   #サンプル数をバッチで割った値を切り上げ\n",
    "        total_loss = 0\n",
    "        total_acc = 0\n",
    "        for i, (mini_batch_x, mini_batch_y) in enumerate(get_mini_batch_train):\n",
    "            # ミニバッチごとにループ\n",
    "            \n",
    "            #最適化インスタンスを呼び出しして学習\n",
    "            #print(sess.run(logits , feed_dict={X: mini_batch_x, Y: mini_batch_y}))  デバッグ用\n",
    "            sess.run(train_op, feed_dict={X: mini_batch_x, Y: mini_batch_y})\n",
    "            \n",
    "            #ミニバッチで学習したモデルからlossとスコアを計算して加算\n",
    "            loss, acc = sess.run([loss_op, accuracy], feed_dict={X: mini_batch_x, Y: mini_batch_y})\n",
    "            total_loss += loss\n",
    "            total_acc += acc\n",
    "            \n",
    "        #全バッチの学習後にサンプル方向に平均取る\n",
    "        total_loss /= n_samples\n",
    "        total_acc /= n_samples\n",
    "        \n",
    "        #検証データのloss、スコアを取得\n",
    "        val_loss, val_acc = sess.run([loss_op, accuracy], feed_dict={X: X_val, Y: y_val})\n",
    "        \n",
    "        print(\"Epoch {}, loss : {:.4f}, val_loss : {:.4f}, acc : {:.3f}, val_acc : {:.3f}\".format(epoch, loss, val_loss, acc, val_acc))\n",
    "    \n",
    "    #全エポック後にテスト\n",
    "    test_acc = sess.run(accuracy, feed_dict={X: X_test, Y: y_test})\n",
    "    print(\"test_acc : {:.3f}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題５】MNISTのモデルを作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 784)\n",
      "(12000, 784)\n",
      "(48000, 10)\n",
      "(12000, 10)\n",
      "(10000, 784)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "#MNISTデータセット\n",
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "#平滑化\n",
    "X_train_f = X_train.reshape(-1, 784)\n",
    "X_test_f = X_test.reshape(-1, 784)\n",
    "\n",
    "#前処理\n",
    "X_train_ff = X_train_f.astype(np.float)\n",
    "X_test_ff = X_test_f.astype(np.float)\n",
    "X_train_ff /= 255\n",
    "X_test_ff /= 255\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
    "y_test_one_hot = enc.transform(y_test[:, np.newaxis])\n",
    "\n",
    "Xt_train, Xt_val, yt_train, yt_val = train_test_split(X_train_ff, y_train_one_hot, test_size=0.2)\n",
    "print(Xt_train.shape) # (48000, 784)\n",
    "print(Xt_val.shape) # (12000, 784)\n",
    "print(yt_train.shape)\n",
    "print(yt_val.shape)\n",
    "print(X_test_ff.shape)\n",
    "print(y_test_one_hot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ハイパーパラメータの設定\n",
    "learning_rate = 0.01\n",
    "batch_size = 20\n",
    "num_epochs = 8\n",
    "\n",
    "n_hidden1 = 200\n",
    "n_hidden2 = 100\n",
    "n_input = Xt_train.shape[1]      #784\n",
    "n_samples = Xt_train.shape[0]  #48000\n",
    "n_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss : 0.6016, val_loss : 0.9966, acc : 0.900, val_acc : 0.705\n",
      "Epoch 1, loss : 1.0624, val_loss : 0.5881, acc : 0.800, val_acc : 0.853\n",
      "Epoch 2, loss : 0.6716, val_loss : 0.4857, acc : 0.950, val_acc : 0.901\n",
      "Epoch 3, loss : 0.4260, val_loss : 0.4405, acc : 0.850, val_acc : 0.892\n",
      "Epoch 4, loss : 0.1005, val_loss : 0.4503, acc : 0.950, val_acc : 0.920\n",
      "Epoch 5, loss : 0.1012, val_loss : 0.3477, acc : 1.000, val_acc : 0.936\n",
      "Epoch 6, loss : 0.4846, val_loss : 0.4663, acc : 0.850, val_acc : 0.928\n",
      "Epoch 7, loss : 0.1115, val_loss : 0.3099, acc : 1.000, val_acc : 0.929\n",
      "test_acc : 0.929\n"
     ]
    }
   ],
   "source": [
    "# 計算グラフに渡す引数の形を決める\n",
    "X = tf.placeholder(\"float\", [None, n_input])    #4\n",
    "Y = tf.placeholder(\"float\", [None, n_classes]) #10\n",
    "\n",
    "# trainのミニバッチイテレータ\n",
    "get_mini_batch_train = GetMiniBatch(Xt_train, yt_train, batch_size=batch_size)\n",
    "\n",
    "def example_net(x):\n",
    "    \"\"\"\n",
    "    単純な3層ニューラルネットワーク\n",
    "    \"\"\"\n",
    "\n",
    "    # 重みとバイアスの宣言\n",
    "    weights = {\n",
    "        'w1': tf.Variable(tf.random_normal([n_input, n_hidden1])),         #(4, 50)\n",
    "        'w2': tf.Variable(tf.random_normal([n_hidden1, n_hidden2])),    #(50, 100)\n",
    "        'w3': tf.Variable(tf.random_normal([n_hidden2, n_classes]))      #(100, 3)\n",
    "    }\n",
    "    biases = {\n",
    "        'b1': tf.Variable(tf.random_normal([n_hidden1])),   #50\n",
    "        'b2': tf.Variable(tf.random_normal([n_hidden2])),   #100\n",
    "        'b3': tf.Variable(tf.random_normal([n_classes]))     #3\n",
    "    }\n",
    "\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['w1']), biases['b1'])\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['w2']), biases['b2'])\n",
    "    layer_2 = tf.nn.relu(layer_2)\n",
    "    layer_output = tf.add(tf.matmul(layer_2, weights['w3']), biases['b3'])\n",
    "    #layer_output = ft.nn.softmax(layer_3)  TensorFlowの関数で計算するので必要ない\n",
    "    return layer_output\n",
    "\n",
    "# ネットワーク構造の読み込み                               \n",
    "logits = example_net(X)\n",
    "\n",
    "# 目的関数\n",
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=Y, logits=logits))\n",
    "\n",
    "# 最適化手法\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "# 推定結果\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
    "# 指標値計算\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# variableの初期化\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "\n",
    "# 計算グラフの実行\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(num_epochs):\n",
    "        # エポックごとにループ\n",
    "        total_batch = np.ceil(Xt_train.shape[0]/batch_size).astype(np.int)   #サンプル数をバッチで割った値を切り上げ\n",
    "        total_loss = 0\n",
    "        total_acc = 0\n",
    "        for i, (mini_batch_x, mini_batch_y) in enumerate(get_mini_batch_train):\n",
    "            # ミニバッチごとにループ\n",
    "            \n",
    "            #最適化インスタンスを呼び出しして学習\n",
    "            #print(sess.run(logits , feed_dict={X: mini_batch_x, Y: mini_batch_y}))  デバッグ用\n",
    "            sess.run(train_op, feed_dict={X: mini_batch_x, Y: mini_batch_y})\n",
    "            \n",
    "            #ミニバッチで学習したモデルからlossとスコアを計算して加算\n",
    "            loss, acc = sess.run([loss_op, accuracy], feed_dict={X: mini_batch_x, Y: mini_batch_y})\n",
    "            total_loss += loss\n",
    "            total_acc += acc\n",
    "            \n",
    "        #全バッチの学習後にサンプル方向に平均取る\n",
    "        total_loss /= n_samples\n",
    "        total_acc /= n_samples\n",
    "        \n",
    "        #検証データのloss、スコアを取得\n",
    "        val_loss, val_acc = sess.run([loss_op, accuracy], feed_dict={X: Xt_val, Y: yt_val})\n",
    "        \n",
    "        print(\"Epoch {}, loss : {:.4f}, val_loss : {:.4f}, acc : {:.3f}, val_acc : {:.3f}\".format(epoch, loss, val_loss, acc, val_acc))\n",
    "    \n",
    "    #全エポック後にテスト\n",
    "    test_acc = sess.run(accuracy, feed_dict={X: X_test_ff, Y: y_test_one_hot})\n",
    "    print(\"test_acc : {:.3f}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "430px",
    "left": "6px",
    "right": "20px",
    "top": "206px",
    "width": "250px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
